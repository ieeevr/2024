id,authors,title,abstract,url,location,booth
P1003,Chen Li: The Hong Kong Polytechnic University ; Yixin Dai: The Hong Kong Polytechnic University; Honglin Li: The Hong Kong Polytechnic University; Pui Yin Yip: The Hong Kong Polytechnic University,Remote art therapy in collaborative virtual environment: a pilot study on feasibility and usability,The uniqueness of the collaborative virtual environment (CVE) makes it a perfect medium for delivering art therapy sessions remotely during the global pandemic. This pilot study investigates the feasibility and usability of delivering remote art therapy in a customised CVE. Four young adults as clients and two registered expressive arts therapists participated in the study. The quantitative and qualitative results suggested that the CVE-enabled approach was feasible and the system's usability was high. The approach was well received by both the clients and the therapists. Possible improvements to the CVE were identified and will be addressed in our future work.,,Session/Server 1,
P1006,Yu Han: Beijing Engineering Research Center of Mixed Reality and Advanced Display; Jie Hao: Beijing Institute of Technology; Yu Miao: Beijing Engineering Research Center of Mixed Reality and Advanced Display; Yue Liu: Beijing Institute of Technology,Exploring Influences of Design and Environmental Factors on Recognizing Teacher’s Facial Expressions in Educational VR,"Teachers’ facial expressions significantly influence students’ willingness to learn. However, insufficient resolution of current consumer head-mounted displays leads to difficulties in capturing nuances of virtual teachers in VR, which may be solved by scaling up the heads of virtual teachers. In this paper, we explore the effects of design and environmental factors on the ideal head scales for recognizing the virtual teacher’s facial expressions. Our results show that the facial visualization style and the distance from the user to the virtual teacher are important factors affecting facial expression recognition, which could contribute to the design and optimization of educational VR.",,Session/Server 1,
P1007,"Bernardo Marques: Universidade de Aveiro; André Santos: University of Aveiro; Nuno Martins: IETA, University of Aveiro; Samuel Silva: Universidade de Aveiro; Paulo Dias: University of Aveiro; Beatriz Sousa Santos: University of Aveiro",Exploring Situated Instructions for Mixed Reality (MR) Remote Collaboration: Comparing Embedded and Non-Embedded Annotations,"Mixed Reality (MR) remote collaboration enable off-site experts to assist on-site collaborators needing guidance. Different visualizations have been proposed for sharing situated information, e.g., embedded, non-embedded, etc. However, the effectiveness of these visualizations have not been compared. This work describes a user study with 16 participants, aimed at comparing two conditions: C1) Embedded and C2) Non-Embedded annotations during a real-life remote maintenance. Two devices were used: Hand-Held Device (HHD) and Head-Mounted Display (HMD). This last using Embedded annotations was considered the better alternative, while HHD using Non-Embedded annotations were rated lower from all conditions.",,Session/Server 1,
P1014-2,Yan Zhang: Shanghai Jiao Tong University; Xiaodan Hu: NAIST; Kiyoshi Kiyokawa: Nara Institute of Science and Technology; Xubo Yang: SHANGHAI JIAO TONG UNIVERSITY,Add-on Occlusion: Turning Off-the-Shelf Optical See-through Head-mounted Displays Occlusion-capable,"The occlusion-capable optical see-through head-mounted display (OC-OSTHMD) is actively developed in recent years. Virtual contents are demonstrated to have a higher quality when displayed with occlusion patterns. However, implementing occlusion with the specific type of OSTHMDs prevents the appealing feature from the wide application. In this paper, a novel approach of realizing occlusion for common OSTHMDs is proposed. A wearable device with per-pixel occlusion capability is designed. OSTHMDs are upgraded to be occlusion-capable by attaching the device before optical combiners. A prototype with HoloLens 1 is built. The proposed system is expected to realize a universal implementation of the occlusion function in augmented reality (AR).",,Session/Server 1,
P1014,"yohei hanaoka: KDDI Research, Inc.; Kohei Matsuzaki: KDDI Research, Inc.; Satoshi Komorita: KDDI Research, Inc.",Coarse to Fine Recursive Image-based Localization on a 3D Mesh Map,"Image-based localization is appropriate for augmented/virtual reality (AR/VR) services due to its high accuracy. However, it generally needs dedicated 3D map generation, which is costly. Thus, some methods have tried to utilize 3D mesh maps instead. However, the significant visual difference between the query image of the camera to be localized and a 3D mesh map results in low accuracy. This paper proposes to improve accuracy by dynamically controlling the comparison threshold and selecting the best localization result in a recursive estimation process. The results show that it improves the accuracy by 15% compared to the baseline method.",,Session/Server 1,
P1016,Ping-Hsuan Han: National Taipei University of Technology; Tzu-Hua Wang: National Taipei University of Technology; Chien-Hsing Chou: National Taipei University of Education,GroundFlow: Liquid-based Haptics for Simulating Fluid on the Ground in Virtual Reality,"Most haptic devices simulate feedback in dry environments such as the living room, prairie, or city. However, water-related environments are thus less explored, for example, rivers, beaches, and swimming pools. In this paper, we present GroundFlow, a liquid-based haptic floor system for simulating fluid on the ground in VR. We discuss design considerations and propose a system architecture and interaction design. We conduct two user studies to assist in designing a multiple-flow feedback mechanism, develop three applications to explore the potential uses of the mechanism, and consider the limitations and challenges thereof to inform VR developers and haptic practitioners.",,Session/Server 1,
P1022,"Liangchen Song: University at Buffalo; Anpei Chen: ETH Zürich; Zhong Li: InnoPeak Technology; Zhang Chen: InnoPeak Technology; Lele Chen: InnoPeak Technology, Inc.; Junsong Yuan: University at Buffalo; Yi Xu: InnoPeak Technology, Inc.; Andreas Geiger: University of Tübingen",NeRFPlayer: A Streamable Dynamic Scene Representation with Decomposed Neural Radiance Fields,"An efficient framework, named NeRFPlayer, has been developed for fast reconstruction, compact modeling, and streamable rendering of 4D spatiotemporal space in VR. The framework decomposes the 4D space into three categories: static, deforming, and new areas, each represented by a separate neural field. A hybrid representations based feature streaming scheme is used for efficiently modeling the neural fields. Our method is evaluated on dynamic scenes captured by single hand-held cameras and multi-camera arrays, achieving comparable or superior rendering performance in terms of quality and speed, with reconstruction taking 10 seconds per frame.",,Session/Server 1,
P1025,Kai Wang: China Unicom; Shiguo Lian: China Unicom; Haiyan Sang: China Unicom; Wen Liu: China Unicom; Zhaoxiang Liu: China Unicom; Fuyuan Shi: China Unicom; Hui Deng: China Unicom; Zeming Sun: China Unicom; Zezhou Chen: China Unicom,Multimodal Activity Detection for Natural Interaction with Virtual Human,"Natural face-to-face human-robot conversation is one of the most important features for virtual human in virtual reality and metaverse. However, the unintended wake-up of robot is often activated with only Voice Activity Detection (VAD). To address this issue, we propose a Multimodal Activity Detection (MAD) scheme, which considers not only voice but also gaze, lip-movement and talking content to decide whether the person is activating the robot. A dataset for large screen-based virtual human conversation is collected from various challenging cases. The experimental results show that the proposed MAD greatly outperforms VAD-only method.",,Session/Server 1,
P1026,"hui zeng: Center for Brain-Inspired Computing Research (CBICR), Beijing Advanced Innovation Center for Integrated Circuits, Optical Memory National Engineering Research Center, & Department of Precision Instrument, Tsinghua University, 100084; rong zhao: Center for Brain-Inspired Computing Research (CBICR), Beijing Advanced Innovation Center for Integrated Circuits, Optical Memory National Engineering Research Center, & Department of Precision Instrument, Tsinghua University, 100084",Perceptually-guided dual-mode virtual reality system for motion-adaptive display,"The development of high-quality virtual reality (VR) devices brings great challenges for display panel fabrication, real-time rendering, and data transfer. To address this issue, we introduce a dual-mode virtual reality system based on the spatio-temporal perception characteristics of human vision. The proposed VR system has a novel optical architecture. It can switch display modes according to the user's perceptual requirements for different display scenes to adaptively adjust the display spatial and temporal resolution based on a given display budget, thus providing users with the optimal visual perception quality.",,Session/Server 1,
P1028,Ruoxi Guo: University College London; Lisa Izzouzi: University College London; Anthony Steed: University College London,User Motion Accentuation in Social Pointing Scenario,"Few existing methods produce full-body user motion in Virtual Environments from only one consumer-level Head-Mounted-Display. This preliminary project generates full-body motions from the user’s hands and head positions through data-based motion accentuation. The method is evaluated in a simple collaborative scenario with one Pointer, represented by an avatar, pointing at targets while an Observer interprets the Pointer’s movements. The Pointer’s motion is modified by our motion accentuation algorithm SocialMoves. Comparisons on the Pointer’s motion are made between SocialMoves, the Final IK, and Ground Truth. Our method showed the same level of user experience as the Ground Truth method.",,Session/Server 1,
P1029,Weiwei Jiang: Anhui Normal University; Difeng Yu: University of Melbourne; Andrew Irlitti: University of Melbourne; Jorge Goncalves: University of Melbourne; Vassilis Kostakos: University of Melbourne; Xin He: Anhui Normal University,Knock the Reality: Virtual Interface Registration in Mixed Reality,"We present Knock the Reality, an interaction technique for virtual interface registration in mixed reality (MR). When a user knocks on a physical object, our technique identifies the object based on a knocking sound and registers a customizable virtual interface onto the object. Unlike computer vision-based methods, our approach does not require continuously processing image information. Instead, we utilize audio features which are less computationally expensive. This work presents our implementation and demonstrates an interaction scenario where a user works in MR. Overall, our method offers a simple and intuitive way to register MR interfaces.",,Session/Server 1,
P1032,Yamato Miyashita: Japan Broadcasting Corporation; Masamitsu Harasawa Ph.D.: Japan Broadcasting Corporation; Kazuhiro Hara: Japan Broadcasting Corporation; Yasuhito Sawahata: Japan Broadcasting Corporation; Kazuteru Komine: Japan Broadcasting Corporation,Estimation of Required Horizontal FoV for Ideal HMD Utilizing Vignetting under Practical Range of Eye Displacement,"This study presents the required horizontal FoV for ideal HMDs that bring an indistinguishable experience from the state of not wearing them. We investigated the threshold of the horizontally visible range relative to the head, when the size of the eye displacement is equivalent to that in real life. We confirmed that the required FoV was smaller than that in a previous study, in which the participants' eye displacement was at its maximum. We found that the required FoV was approximately 229° when the peripheral luminance gradually decreased, as in vignetting.",,Session/Server 1,
P1032-2,Yuqi Zhou: Purdue University; Voicu Popescu: Purdue University,Dynamic Redirection for VR Haptics with a Handheld Stick,"This paper proposes a general handheld stick haptic redirection method that allows the user to experience complex shapes with haptic feedback through both tapping and extended contact, such as in contour tracing. As the user extends the stick to make contact with a virtual object, the contact point with the virtual object and the targeted contact point with the physical object are continually updated, and the virtual stick is redirected to synchronize the virtual and real contacts. Redirection is applied either just to the virtual stick, or to both the virtual stick and hand. A user study (N = 26) confirms the effectiveness of the proposed redirection method.",,Session/Server 1,
P1034,Masaki Takeuchi: Osaka University; Daisuke Iwai: Osaka University; Kosuke Sato: Osaka University,Projection Mapping in the Light: A Preliminary Attempt to Substitute Projectors for Room Lights,"Projection mapping (PM) in a bright room creates the problem of reducing the contrast of the projected texture because ambient lighting elevates the black level of the projection target. In this paper, we developed a pseudo-ambient lighting technique that turns off the original ambient lighting and reproduces its illumination from the projectors on surfaces other than the target. We confirmed that the proposed technique could reproduce a bright room while suppressing the contrast reduction of the projected texture on the target, which helped to improve the viewing experience.",,Session/Server 1,
P1035,Yuri Mikawa: The University of Tokyo; Christian Eichhorn: Technical University of Munich; Gudrun Klinker: Technical University of Munich,Multi-color LED Marker for Dynamic Target Tracking in Wide Area,"To present augmented reality in dynamic scenes like sports, a wide tracking range is required as well as accuracy and speed. Conventional tracking markers had a complicated shape, which resulted in being weak against image blur and low image resolution, leading to a narrow tracking range. This paper proposes multi-color LED markers for tracking a dynamic object in a wide area. They can emit consistent light and express a unique ID by a few color pixels, which are efficiently extracted using a camera’s short exposure time. This marker was tested at various distances and fast rotation, where the high identification accuracy was evaluated.",,Session/Server 1,
P1037,Piaopiao Yu: Department of Computer Science and Technology; Jie Guo: Nanjing University; Fan Huang: Department of Computer Science and Technology; Zhenyu Chen: Nanjing Univetsity; Chen Wang: Department of Computer Science and Technology; Yan Zhang: Nanjing University; Yanwen Guo: Nanjing University,ShadowMover: Automatically Projecting Real Shadows onto Virtual Object,"Inserting 3D virtual objects into real-world images has many applications in photo editing and augmented reality. We present the first end-to-end solution to fully automatically project real shadows onto virtual objects for outdoor scenes. In our method, we introduce the Shifted Shadow Map, a new shadow representation that encodes the binary mask of shifted real shadows after inserting virtual objects in an image. Based on the shifted shadow map, we propose a CNN-based shadow generation model named ShadowMover which first predicts the shifted shadow map for an input image and then automatically generates plausible shadows on any inserted virtual object.",,Session/Server 1,
P1039,Tim Weissker: RWTH Aachen University; Pauline Bimberg: University of Trier; Aalok Shashidhar Gokhale: Bauhaus-Universität Weimar; Torsten Wolfgang Kuhlen: RWTH Aachen University; Bernd Froehlich: Bauhaus-Universität Weimar,Gaining the High Ground: Teleportation to Mid-Air Targets in Immersive Virtual Environments,"We present three teleportation techniques that enable the user to travel not only to ground-based but also to mid-air targets. The techniques differ in the extent to which elevation changes are integrated into the conventional target selection process. Elevation can be specified either simultaneously, as a connected second step, or separately from horizontal movements. A user study indicated a trade-off between the simultaneous method with the highest accuracy and the two-step method with the lowest task load. The separate method was least suitable on its own. Based on our findings, we define initial design guidelines for mid-air navigation techniques.",,Session/Server 1,
P1042,Koray Kavaklı: Koç University; Yuta Itoh: The University of Tokyo; Hakan Urey: Koc University; Kaan Akşit: University College London,Realistic Defocus Blur for Multiplane Computer-Generated Holography,"This paper introduces a new multiplane CGH computation method to reconstruct artifact-free high-quality holograms with natural-looking defocus blur. We introduce a new targeting scheme and a new loss function. While the targeting scheme accounts for defocused parts of the scene at each depth plane, the new loss function analyzes focused and defocused parts separately in reconstructed images. Our method support phase-only CGH calculations using various iterative and non-iterative CGH techniques. We achieve our best image quality using a modified gradient descent-based optimization recipe where we introduce a constraint inspired by the double phase method. We validate our method experimentally using our proof-of-concept holographic display.",,Session/Server 1,
P1046,"xinkang zhang: Academy for engineering & technology, Fudan University; xinhan di: bloo company; Xiaokun Dai: Academy for engineering & technology, Fudan University; Xinrong Chen: Academy for engineering & technology, Fudan University",An Attention-Based Signed Distance Field Estimation Method for Hand-Object Reconstruction,"Joint reconstruction of hands and objects from monocular RGB images is a challenging task. In this work, we present a novel hybrid model for joint reconstruction of hands and objects. The model proposed consists of three key modules. Among them, multi-scale attention feature extractor is designed to enhance cross-scale information extraction. Attention-based graph encoder can encode the graph information of the hands. Interacting attention module is applied to fuse information between hands and object. Test results on ObMan dataset indicate that our method has better joint reconstruction results compared to the state-of-the-art methods.",,Session/Server 1,
P1047,Muhannad Ismael: luxembourg institute of science and technology ; Roderick McCall: Luxembourg Institute of Science and Technology (LIST); Maël Cornil: Luxembourg Institute of Science and Technology; Mike Griffin: Luxembourg Institute of Science and Technology (LIST); Joan Baixauli: Luxembourg Institute of Science and Technology (LIST),Radiological Incident System using Augmented Reality (RISAR),"This paper presents an Augmented Reality (AR) solution called RISAR that allows for the real-time visualisation of  Radiological hazards based on sensor data captured from detectors as well as Unmanned Aerial  and Ground Vehicles. RISAR improves safety for first responders during radiological events by enhancing their situation awareness. This lowers the risk of harm, and with it any health impacts and costs.",,Session/Server 1,
P1049,James Jonathan Pinkl: University of Aizu; Michael Cohen: University of Aizu,Concurrent Feedback VR Rhythmic Coordination Training,"Action Observation VR tools have had observable success in teaching a wide variety of skills. The authors’ previous development includes a first-person VR tool designed for users to learn drumming exercises and improve rhythm via HMD. This contribution is an extension that implements concurrent feedback and multimodal cues to further immerse users in a coherent experience. Another virtual scene is included to help users improve their polyrhythms, a historically challenging musical concept to learn through traditional methods. The aim of this work is to use synchronized multimodal techniques with realtime feedback capabilities to develop a new drumming practice tool and to devise a potentially more effective, method to practice polyrhythms.",,Session/Server 1,
P1050,Taylor A Doty: Iowa State University; Jonathan Kelly: Iowa State University; Michael Dorneich Dorneich: Iowa State University; Stephen B. Gilbert: Iowa State University,Does interpupillary distance (IPD) relate to immediate cybersickness?,"Widespread adoption of virtual reality (VR) will likely be limited by the common occurrence of cybersickness. Cybersickness susceptibility varies across individuals, and previous research reported that interpupillary distance (IPD) may be a factor. However, that work emphasized cybersickness recovery rather than cybersickness immediately after exposure. The current study (N=178) examined if the mismatch between the user's IPD and the VR headset's IPD setting contributes to immediate cybersickness. Multiple linear regression indicated that gender and prior sickness due to screens were significant predictors of immediate cybersickness. However, no relationship between IPD mismatch and immediate cybersickness was observed.",,Session/Server 1,
P1053-2,Daniel Martin: Universidad de Zaragoza; Xin Sun: Adobe Research; Diego Gutierrez: Universidad de Zaragoza; Belen Masia: Universidad de Zaragoza,A Study of Change Blindness in Immersive Environments,"Human performance is poor at detecting certain changes in a scene, a phenomenon known as change blindness. Although the exact reasons of this effect are not yet completely understood, there is a consensus that it is due to our constrained attention and memory capacity. In this work, we present a study of change blindness using immersive 3D environments. We devise two experiments; first, we focus on analyzing how different change properties may affect change blindness. We then further explore its relation with the capacity of our visual working memory and analyze the influence of the number of changes.",,Session/Server 1,
P1053,Luhui Wang: Beijing Institute of Technology; Wei Liang: Beijing Institute of Technology; Xiangyuan Li: Beijing Forestry University,Scene-aware Motion Redirection in Telecommunication,"We propose a motion redirection system for virtual reality and augmented reality, automatically detecting a person's action in a source scene and redirecting it to a new target scene. The redirected motion is augmented in the target scene based on the understanding of the target scene's semantics and layout. The results show that the system may facilitate telecommunication across scenes, improving user interaction experiences.",,Session/Server 1,
P1055,Portia Wang: Stanford University; Mark Roman Miller: Stanford University; Jeremy Bailenson: Stanford University,The Belated Guest: Exploring the Design Space for Transforming Asynchronous Social Interactions in Virtual Reality,"Social meetings in Virtual Reality (VR) are fundamentally different from videoconferencing because the VR tracking data can be used to render scenes as if they were in real-time, enabling people to go back in time and experience discussions that they may have not attended. Moreover, the tracking data allows people to visit the meeting from any location in the room, as opposed to the single camera angle used for video conferences. The current paper describes the methodology of transforming tracking data around proxemics and head orientations of recorded avatars to nonverbally assimilate new users into a recorded scene.",,Session/Server 1,
P1057,Kazushi Kinjo: Osaka University; Daisuke Iwai: Osaka University; Kosuke Sato: Osaka University,A High-Dynamic-Range Mesh Screen VR Display by Combining Frontal Projection and Retinal Projection,"We proposed a high-dynamic-range virtual reality (VR) display that can represent a glossy material by combining a conventional frontal projection mapping and a retinal projection light passing through a screen of a microporous plate. 
In the prototype system, the retinal projection could be superimposed on the frontal projection and increase the luminance of only the specular highlight in the image. This paper also reports approximately six hundred times brighter presentation of the retinal projection than that of the frontal projection.",,Session/Server 1,
P1057-2,"Elodie Bouzbib: INRIA, Université de Rennes, CNRS, IRISA; Claudio Pacchierotti: CNRS; Anatole Lécuyer: Inria",When Tangibles become Deformable: Studying Pseudo-Stiffness Perceptual Thresholds in a VR Grasping Task,"Pseudo-Haptic techniques leverage user's visual dominance over haptics to alter users' perception, but are limited to perceptual thresholds. In this paper, we estimate thresholds for pseudo-stiffness in a VR grasping task. We conducted a user study (n = 15) to estimate if compliance can be induced on non-compressible objects and to what extent. Our results show that (1) compliance can be induced in rigid objects and that (2) pseudo-haptics can simulate beyond 24 N/cm stiffness (from gummy bears up to rigid objects). Pseudo-stiffness efficiency is (3) enhanced by objects' scales and (4) correlated to input force. Our results show novel opportunities to simplify the design of haptic interfaces, and extend the haptic properties of props in VR.",,Session/Server 1,
P1059,Mitsuki Manabe: the university of electro-communications; Keigo Ushiyama: The University of Electro-Communications; Akifumi Takahashi: University of Chicago; Hiroyuki Kajimoto: The University of Electro-Communications,Energy Efficient Wearable Vibrotactile Transducer Utilizing the Leakage Magnetic Flux of Repelling Magnets,"We propose a novel energy-efficient wearable vibrotactile transducer that features two characteristics. Firstly, it uses two repulsive magnets attached to one other to create a concentrated leakage of magnetic flux on the side surface. Secondly, the magnets and coil are directly attached to the skin. A prototype of the device was fabricated and tested, demonstrating that it can produce stronger and wider frequency vibrations than existing methods, providing a more accurate representation of rough textures.",,Session/Server 1,
P1066-2,Hai Li: Zhejiang University; Hongjia Zhai: Zhejiang University; Xingrui Yang: University of Bristol; Zhirong Wu: College of Computer Science and Technology; Yihao Zheng: College of Computer Science and Technology; Haofan Wang: College of Computer Science and Technology; Jianchao Wu: Taizhou stamotology hospital; Hujun Bao: Zhejiang University; Guofeng Zhang: Computer Science College,ImTooth: Neural Implicit Tooth for Dental Augmented Reality,"We propose a simple and accurate neural-implicit model-driven dental AR system, named ImTooth, and adapted for HoloLens 2. Based on the modeling capabilities and differentiable optimization properties of state-of-the-art neural implicit representations, our system fuses reconstruction and registration in a single network, greatly simplifying existing dental AR solutions and enabling reconstruction, registration, and interaction.
Experiments show that our method can reconstruct high-precision models and accomplish accurate registration. It is also robust to weak, repeating, and inconsistent textures.We also show that our system can be easily integrated into dental diagnostic and therapeutic procedures, such as bracket placement guidance.",,Session/Server 1,
P1066,"Patrick Gebhardt: University of Stuttgart; Maximilian Weiß: University of Stuttgart; Pascal Huszár: University of Stuttgart; Xingyao Yu: VISUS; Alexander Achberger: Mercedes-Benz AG; Xiaobing Zhang: China Mobile (Jiangxi) Virtual Reality Technology Co., Ltd; Michael Sedlmair: University of Stuttgart",Auxiliary Means to Improve Motion Guidance Memorability in Extended Reality,"VR-based motion guidance systems can provide 3D movement instructions and real-time feedback for practicing movement without a live instructor. However, the precise visualization of movement paths or postures may be insufficient to learn a new motor skill, as they might make users too dependent and lead to poor performance when there is no guidance. In this paper, we propose to use enhanced error visualization, asymptotic path, increasing transparency, and haptic constraint to improve the memorability of motion guidance. Our study results indicated that adding an enhanced error feedback visualization helped the users with short-term retention.",,Session/Server 1,
P1069,Melanie Derksen: TU Dortmund University; Tim Weissker: RWTH Aachen University; Torsten Wolfgang Kuhlen: RWTH Aachen University; Mario Botsch: TU Dortmund University,Towards Discovering Meaningful Historical Relationships in Virtual Reality,"Traditional digital tools for exploring historical data mostly rely on conventional 2D visualizations, which often cannot reveal all relevant interrelationships between historical fragments. We are working on a novel interactive exploration tool for historical data in virtual reality, which arranges fragments in a 3D environment based on their temporal, spatial and categorical proximity to a reference fragment. In this poster, we report on an initial expert review of our approach, giving us valuable insights into the use cases and requirements that inform our further developments.",,Session/Server 1,
P1071,Jin Li: Beihang university; Hanchen Deng: Beihang University; Yang Gao: Beihang University; Anqi CHEN: State Key Laboratory of Virtual Reality Technology and Systems，beihang university; Zilong Song: Beihang University; Aimin Hao: Beihang University,Real-time Physics-based Interaction in Augmented Reality,"We propose a unified AR-based framework that combines the real-time physical multi-material simulation model and the efficient free-hand gesture interaction method. First, we employ a simple RGBD camera to quickly acquire 3D environmental data to build the static boundary conditions. The real-time gestures are then detached and used as dynamic objects that interact with physical simulations. Finally, the calculated lighting parameters are used for real-time rendering and virtual-reality fusion. Our framework enables users to interact with various physical simulations in AR scenes, which considerably expands the applications of the fusion of AR and physical simulations.",,Session/Server 1,
P1072,Zhiqiang Luo: Foshan University; Tek Yong Lim: Multimedia University,Development of a Data-driven Self-adaptive Upper Limb Virtual Rehabilitation System for Post Stroke Elderly,The study aims to develop a virtual rehabilitation system to assist upper limb motor training for older post-stroke patients. The system contains data-driven virtual exergames simulating the task-oriented training; receives the rehabilitation prescription and the online data collected from the multi-mode hand controller and the depth camera; assesses online patient’s performance which in turn updates the data of virtual exergames to adapt to the patient’s training progress. Its innovation is providing precision rehabilitation via gaining the personalized learning experience to improve the adherence to and effectiveness of virtual rehabilitation.,,Session/Server 1,
P1073,Jesper Gaarsdal: SynergyXR ApS; Sune Wolff: SynergyXR ApS; Claus B. Madsen: Aalborg University,Real-Time Exploded View Animation Authoring in VR Based on Simplified Assembly Sequence Planning,"In this paper, we present an animation authoring tool, capable of automatically generating an exploded view of assemblies in real-time. 3D user interfaces in virtual reality are used for controlling the explosion distance of parts, as well as other metrics affecting the explosion direction and order. The methods used are based on assembly sequence planning and employ an assembly-by-disassembly approach, requiring no additional information about parts other than their geometry and position in the assembled state. The computation times for five assemblies of different complexities are presented, tested on a standalone virtual reality device.",,Session/Server 1,
P1076,Jong-In Lee: Simon Fraser University; Paul Asente: (retired); Wolfgang Stuerzlinger: Simon Fraser University,Designing Viewpoint Transition Techniques in Multiscale Virtual Environments,"Viewpoint transitions have been shown to improve users' spatial orientation and help them build a cognitive map when navigating an unfamiliar virtual environment.  Previous work has investigated transitions in single-scale virtual environments, focusing on trajectories and continuity. We extend previous work on simple transitions to an in-depth investigation of transition techniques in multiscale virtual environments (MVEs). We identify challenges in navigating MVEs with nested structures and assess how different transition techniques affect spatial understanding and usability. Through two user studies, we investigated transition trajectories, interactive control of transition movement, and speed modulation in a nested MVE.",,Session/Server 1,
P1078,"Haoyang Du: Goldsmiths, University of London; Songkai Jia: Goldsmiths, University of London; Joel Gautschi: Zurich University of Applied Science; Julia Quehenberger: Zurich University of Applied Science ; David Lätsch: ZHAW Zurich University of Applied Sciences; Xueni Pan: Goldsmiths",Towards more child safety-oriented decisions through VR?,"Witnessing intimate partner violence (IPV) could have long-term negative impacts on children. Such exposure is, however, often overlooked by professionals. We developed a VR scenario which allowed participants to witness IPV from a child’s perspective. In this pilot study, we found that they made more child-protective decisions and showed higher levels of empathy towards the child after VR exposure. When comparing the impact between the child’s perspective and third-person perspective, no statistically significant differences were found in empathy and decision-making, even though those with the child’s perspective had significantly higher levels of presence.",,Session/Server 1,
P1079,Anthony Steed: University College London; Vit Drga: University College London,Tomato Presence: Virtual Hand Ownership with a Disappearing Hand,"Tomato presence is a term coined by Owlchemy Labs to refer to the observation that players of their game Job Simulator can experience `hand presence' over an object that is not their hand. When playing the game, if a player grabs an object, their virtual hand disappears leaving the grabbed object. It seems that this should be a conflict with current theories of how users might react to visual/proprioceptive mismatch of their embodiment. We run a hand ownership experiment where we implement standard object grasp and the disappearing hand grasp. We show that on a body-ownership questionnaire there is evidence that users feel ownership over a disappearing virtual hand. We also confirm that most users do not report that their hand disappeared.",,Session/Server 1,
P1079-2,Florian Weidner: Ilmenau University of Technology; Gerd Boettcher: Ilmenau University of Technology; Chenyao Dao: TU Ilmenau; Luljeta Sinani: Ilmenau University of Technology; Stephanie Arevalo Arboleda: TU Ilmenau; Christian Kunert: Ilmenau University of Technology; Christoph Gerhardt: Ilmenau University of Technology; Wolfgang Broll: Ilmenau University of Technology; Alexander Raake: TU Ilmenau,A Systematic Review on the Visualization of Avatars and Agents in AR & VR displayed using Head-Mounted Displays,"Augmented Reality (AR) and Virtual Reality (VR) are pushing from the labs towards consumers, especially with social applications. 
These applications require visual representations of humans and intelligent entities. 
Our work investigates the effects of rendering style and visible body parts in AR and VR by adopting a systematic literature review. 
We analyzed 72 papers that compare various avatar representations.
We discuss and synthesize our results within the context of today's AR and VR ecosystem, provide guidelines for practitioners, and finally identify and present promising research opportunities to encourage future research of avatars and agents in AR/VR environments.",,Session/Server 1,
P1081,"Seonjeong Park: Goldsmiths, University of London; Damaris D E Carlisle: LASALLE College of the Arts; Marco Gillies: Goldsmiths, University of London; Xueni Pan: Goldsmiths",Reducing Foreign Language Anxiety with Virtual Reality,"An immersive VR experience was developed to examine the relationship between foreign language anxiety (FLA), virtual audience characteristics, and learners' perceptions of the virtual audience. Seven students studying English as a second language selected their avatars and practised their presentations in front of a virtual audience in a realistic classroom. Results indicated that participants' FLA levels increased when presenting to larger audiences, but decreased after repeated presentations. They were also able to identify the surroundings more readily when presenting in front of smaller audiences, as well as in front of audiences of diverse ethnicity.",,Session/Server 1,
P1084,Sarker Monojit Asish: University of Louisiana at Lafayette; Arun K Kulshreshth: University of Louisiana at Lafayette; Christoph W Borst: University of Louisiana at Lafayette,Detecting Distracted Students in an Educational VR Environment Utilizing Machine Learning on EEG and Eye-Gaze Data,"Virtual Reality (VR) is frequently used in various educational contexts since it could improve knowledge retention compared to traditional learning methods. However, distraction is an unavoidable problem in the educational VR environment due to stress, mind-wandering, unwanted noise/sounds, irrelevant stimuli, etc. We explored the combination of EEG and eye gaze data to detect student distractions in an educational VR environment. We designed an educational VR environment and trained three machine learning models (CNN-LSTM, Random Forest and SVM) to detect distracted students. Our preliminary study results show that Random Forest and CNN-LSTM provide better accuracy (98%) compared to SVM.",,Session/Server 1,
P1086,Atiyeh Alinaghi: University of Southampton; Luca Remaggi: NA; Hansung Kim: University of Southampton,Analysis and Synthesis of Spatial Audio for VR Applications: Comparing SIRR and RSAO as Two Main Parametric Approaches,"In order to have a natural experience in a virtual reality environment,
it is crucial to make the sound aligned with the surrounding room
acoustics. The room acoustics are usually captured by room impulse
responses (RIRs) which can be employed to regenerate the same
audio perception. In this paper, we applied and compared two main
parametric approaches, Spatial Impulse Response Rendering (SIRR)
and Reverberant Spatial Audio Object (RSAO) to encode and render
the RIRs. We showed that SIRR synthesizes the early reflections
more precisely whereas RSAO is more accurate to render the late
reverberation.",,Session/Server 1,
P1087,"Yuwen Heng: School of Electronics and Computer Science, University of Southampton; Srinandan Dasmahapatra: University of Southampton; Hansung Kim: University of Southampton",Material Recognition for Immersive Interactions in Virtual/Augmented Reality,"To provide an immersive experience in a mirrored virtual world such as spatially synchronised audio, visualisation of reproduced real-world scenes and haptic sensing, it is necessary to know the materials of the object surface which provides the optical and acoustic properties for the rendering engine. We focus on identifying materials from real-world images to reproduce more realistic and plausible virtual environments. To cope with considerable variation in material, we propose the DPT architecture which dynamically decides the dependency on different patch resolutions. We evaluate the benefits of learning from multiple patch resolutions on LMD and OpenSurfaces datasets.",,Session/Server 1,
P1088,Seoyoung Kang: KAIST; Sungwoo Jeon: KAIST; Woontack Woo: KAIST ,IPS : Integrating Pose with Speech for enhancement of body pose estimation in VR remote collaboration,"We propose a Speech-Pose integration method to overcome the limitation of existing body pose estimation. Unlike previous Speech-based gesture generation method, our proposal reflects the user’s actual pose using a vision-based system and speech as a subsidiary. When the system detects the camera out of sight, we carry out a context-aware method analyzing the speech. The system determines the target pose and connects it with the last pose captured by the camera using the bounding box. Our system can be a robust solution for avatar-mediated remote collaboration which requires accurate gesture delivery such as VR remote yoga training.",,Session/Server 1,
P1090,Matthias Albrecht: University of Konstanz; Lorenz Assländer: University of Konstanz; Harald Reiterer: University of Konstanz; Stephan Streuber: Coburg University of Applied Sciences and Arts,MoPeDT: A Modular Head-Mounted Display Toolkit to Conduct Peripheral Vision Research,"We introduce MoPeDT: Modular Peripheral Display Toolkit, a freely available, flexible, reconfigurable, and extendable headset to conduct peripheral vision research. MoPeDT can be built with a 3D printer and off-the-shelf components. It features multiple spatially configurable near-eye display modules and full 3D tracking inside and outside the lab. With our system, researchers and designers may easily develop and prototype novel peripheral vision interaction and visualization techniques. We demonstrate the versatility of our headset with several possible applications for spatial awareness, balance, interaction, feedback, and notifications.",,Session/Server 1,
P1092,Ayman Mukhaimar: Victoria University; Yuan Miao: Victoria University; Zora Vrcelj: Victoria University; Bruce Gu: Victoria University; Ang Yang: Victoria University; Jun Zhao: Victoria University; Malindu Sandanayake: Victoria University; Melissa Chan: Victoria University,Multi-person tracking for virtual reality surrounding awareness,"Virtual reality devices are designed to cover our vision so we are unaware of our surroundings and completely emerged into a different world. This limits VR user's ability to move freely in crowded areas, such as classrooms, which limits the user interactions in VR. We present a framework that enables VR users to see other people around them inside the VR environment with the help of an external 3D depth camera. The proposed framework enables multi-VR users to use one tracking camera and provides a cost-effective solution. The proposed framework can also help in performing collaborative activities.",,Session/Server 1,
P1093-2,Muhammad Abu Bakar: Yuan Ze University; Yu-Ting Tsai: Yuan Ze University; Hao-Han Hsueh: Yuan Ze University; Elena Carolina Li: University of Taipei,CrowbarLimbs: A Fatigue-Reducing Virtual Reality Text Entry Metaphor,"We present ”CrowbarLimbs,” a novel virtual reality text entry metaphor with two deformable extended virtual limbs. CrowbarLimbs can assist a user in placing their hands and arms in a comfortable posture, thus effectively reducing the physical fatigue in the hands, wrists, and elbows. It can also achieve comparable text entry speed, accuracy, and system usability to those of previous selection-based methods. We found that the shapes of CrowbarLimbs have significant effects on fatigue ratings and text entry speed. Furthermore, placing the virtual keyboard near the user and at half their height significantly affects text entry speed.",,Session/Server 1,
P1093,Jintao Sun: Beijing Institute of Technology; Gangyi Ding: Beijing Institute of Technology,HandAttNet: Attention 3D Hand Mesh Estimation Network,"Hand pose estimation and reconstruction become increasingly compelling in the metaverse era. But in reality hands are often heavily occluded, which makes the estimation of occluded 3D hand meshes challenging. Previous work tends to ignore the information of the occluded regions, we believe that the occluded regions hand information can be highly utilized, Therefore, in this study, we propose hand
mesh estimation network, HandAttNet. We design the cross-attention mechanism module and the DUO-FIT module to inject hand information into the occluded region. Finally, we use the self-attention regression module for 3D hand mesh estimation. Our HandAttNet achieves SOTA performance.",,Session/Server 1,
P1094,Patrizia Ring: University Duisburg-Essen; Maic Masuch: University of Duisburg-Essen,Measuring Collision Anxiety in XR Exergames,"Extended Reality (XR) applications have become increasingly relevant due to technical advances, but also have their own challenges regarding the user’s real-world orientation. We propose a novel definition and a not yet validated questionnaire for the feeling of disorientation and fear of colliding with real objects in XR, called Collision Anxiety (CA). Participants (N = 37) played an AR and VR version of a game with results suggesting that while an AR game can provide a similar player experience compared to its VR equivalent, differences regarding CA exist.",,Session/Server 1,
P1095,Zhengchang Yang: NAIST; Naoya Isoyama: Nara Institute of Science and Technology; Nobuchika Sakata: Ryukoku University; Kiyoshi Kiyokawa: Nara Institute of Science and Technology,A Palm-Through Interaction Technique for Controlling IoT Devices,"In this study, we propose a palm-through interaction technique to control smart devices by using an augmented reality head-mounted display. The contributions are as follows: 1) The proposed method is intuitive to aim at and touch the remote object of concern, 2) natural haptic feedback is generated. The user study suggests that the palm-through interface is more intuitive because the user interface is similar to that of a smartphone, and brings users haptic confidence. This showed us how smart devices can greatly benefit from an AR implementation, motivating us to further explore this approach for more scenarios.",,Session/Server 1,
P1096,"Alexandre Gordo: Instituto Superior Técnico, Universidade de Lisboa; Ivo Roupa: Instituto Superior Técnico, Universidade de Lisboa; Hugo Nicolau: Universidade de Lisboa; Daniel S. Lopes: INESC ID, Instituto Superior Técnico, Universidade de Lisboa",Feasibility and Expert Acceptance of a Virtual Reality Gait Rehabilitation Tool,"We present LocomotiVR, a Virtual Reality tool designed with physiotherapists to improve the gait rehabilitation in clinical practice. The tool features two interfaces: a VR environment to immerse the patient in the therapy activity; and a desktop tool operated by a physiotherapist to customize exercises and follow the patient's performance. Results revealed that LocomotiVR presented promising acceptability, usage, and engagement scores. These results were supported by qualitative data collected from participating experts, which discussed high levels of satisfaction, motivation, and acceptance to incorporate the LocomotiVR in daily therapy practices. Concerns were related to patient safety and lack of legal regulation.",,Session/Server 1,
P1098,Yobbahim J. Vite: University of Calgary; Yaoping Hu: University of Calgary,The role of attention and cognitive workload in measuring levels of task complexity within virtual environments,"This paper studied the role of attention and cognitive workload (CWL) in measuring levels of task complexity. Within a virtual environment (VE), participants undertook a task with a baseline and 3 levels of the complexity. The baseline and levels were defined as those in an existing work. A well-known ratio of attention, AR, was computed from recorded brainwaves of the participants during the task. Their CWL was derived from a de-facto questionnaire of the NASA task load index.  The study’s outcomes indicated that, while the role of the AR in the measurement remained unclear, the CWL could serve the measurement.",,Session/Server 1,
P1099,Vanessa Kern: Friedrich-Alexander-Universität Erlangen-Nürnberg; Constantin Kleinbeck: Friedrich-Alexander Universität Erlangen-Nürnberg; Kevin Yu: Technical University of Munich; Alejandro Martin-Gomez: Johns Hopkins University; Alexander Winkler: Technical University of Munich; Nassir Navab: Technische Universität München; Daniel Roth: Friedrich-Alexander-Universität Erlangen-Nürnberg,Magnifying Augmented Mirrors for Accurate Alignment Tasks,"Limited mobility in augmented reality applications restricts spatial understanding along with augmentation placement and visibility. Systems can counteract by providing perspectives by tracking and augmenting mirrors without requiring user movement. However, the decreased visual size of mirrored objects reduces accuracy for precision tasks. We propose Magnifying Augmented Mirrors: digitally zoomed mirror images mapped back onto their surface, producing magnified reflections. In a user study (N = 14) conducted in virtual reality, we evaluated our method on a precision alignment task. Although participants needed time for acclimatization, they achieved the most accurate results using a magnified mirror.",,Session/Server 1,
P1100,Yitoshee Rahman: University of Louisiana at Lafayette; Arun K Kulshreshth: University of Louisiana at Lafayette; Christoph W. Borst: University of Louisiana at Lafayette,Exploring the Usefulness of Visual Indicators for Monitoring Students in a VR-based Teaching Interface,"Teaching remotely using immersive Virtual Reality (VR) technology is becoming more popular as well as imperative with the ever-changing educational delivery methods. However, it is not easy for a teacher to monitor students in VR since only student avatars are visible. We designed and tested two educational VR teaching interfaces to help a teacher monitor students. Our comparative analysis using a preliminary study with 5 participants showed that the teaching interface with centrally-arranged emoticon-like indicators, displaying a summary of student information, performed better than the interface with avatar-located indicators in terms of teaching duration, and classroom management.",,Session/Server 1,
P1105,Xian Xu: The Hong Kong University of Science and Technology; Wai Tong: The Hong Kong University of Science and Technology; Zheng Wei: The Hong Kong University of Science and Technology; Meng Xia: Carnegie Mellon University; Lik-Hang Lee: Korea Advanced Institute of Science & Technology; Huamin Qu: The Hong Kong University of Science and Technology,Cinematography in the Metaverse: Exploring the Lighting Education on a Soundstage,"Lighting education is a foundational component of cinematography education. However, there is still a lack of knowledge on the design of a VR system for teaching cinematography. In this work, we present our VR soundstage system for instructors and learners to emulate cinematography lighting in virtual scenarios and then evaluate it from five aspects in the user study. Qualitative and quantitative feedback in our user study shows promising results. We further discuss the benefits of the approach and opportunities for future research.",,Session/Server 1,
P1106,Yuhui Wu: Beijing Institute of Technology; Yue Liu: Beijing Institute of Technology; Jiajun Wang: Beijing Institute of Technology,Real-time Hand-object Occlusion for Augmented Reality Using Hand Segmentation and Depth Correction,"Hand-object occlusion is crucial to enhance the realism of Augmented Reality, especially for egocentric hand-object interaction scenes. In this paper, a hand segmentation-based depth correction approach is proposed, which can help to realize real-time hand-object occlusion. We introduce a lightweight convolutional neural network to quickly obtain real hand segmentation mask. Based on the hand mask, different strategies are adopted to correct the depth data of hand and non-hand regions, which can implement hand-object occlusion and object-object occlusion simultaneously to deal with complex hand situations during interaction. The experimental results demonstrate the feasibility of our approach presenting visually appealing occlusion effects.",,Session/Server 1,
P1108,"Radosław Sterna: Institute of Psychology, Faculty of Philosophy, Jagiellonian University in Krakow; Artur Cybulski: Jagiellonian University in Krakow; Magdalena Igrs-Cybulska: AGH University of Science and Technology; Joanna Pilarczyk: Institute of Psychology, Faculty of Philosophy, Jagiellonian University in Krakow; Michał Kuniecki: Institute of Psychology, Faculty of Philosophy, Jagiellonian University in Krakow",Does realism of a virtual character influence arousal? Exploratory study with pupil size measurement.,"In this poster we discuss exploratory analyses seeking to test whether realism of a virtual character can influence arousal measured by pupil diameter change in response to viewing a virtual character. To do this we conducted a study in which 180 virtual characters were presented to 45 participants in a free-viewing procedure, while their physiological responses were recorded. We manipulated the realism of these characters in terms of their appearance, behavior and intractability. Results suggest that appearance and intractability can influence arousal of the participants.",,Session/Server 1,
P1109,Ben J. Congdon: University College London; Anthony Steed: University College London,Monte-Carlo Redirected Walking: Gain Selection Through Simulated Walks,"We present Monte-Carlo Redirected Walking (MCRDW), a gain selection algorithm for redirected walking. MCRDW applies the Monte-Carlo method to redirected walking by simulating a large number of simple virtual walks, then inversely applying redirection to the virtual paths. Different gain levels and directions are applied, producing differing physical paths. Each physical path is scored and the results used to select the best gain level and direction. We provide a simple example implementation and a simulation-based study for validation. In our study, when compared with the next best technique, MCRDW reduced incidence of boundary collisions by over 50% while reducing total rotation and position gain.",,Session/Server 1,
P1112,"Suibi Che-Chuan Weng: University of Colorado; Torin Hopkins: University of Colorado; Rishi Vanukuru: University of Colorado Boulder; Chad Tobin: University of Colorado; Amy Banic: University of Wyoming; Daniel Leithinger: University of Colorado, Boulder; Ellen Yi-Luen Do: University of Colorado, Boulder",How Field of View Affects Awareness of an Avatar During a Musical Task in Augmented Reality,"To investigate how field of view (FOV) affects how players notice the communicative gestures of their partner's avatar in a musical task, we conducted an experiment that compares several AR technologies with varying FOV. We measured response time to communicative gestures, co-presence score, and task enjoyment in three different AR scenarios: holograms, AR headset, and an AR headset with a notification of the avatar's intention to gesture. Results suggest that the hologram setup had the fastest response time and highest ratings for sense of co-presence and task enjoyment. Notification tasks slowed response time, but noticeably improved co-presence with the avatar.",,Session/Server 1,
P1113,Yuetong Zhao: Beihang University; Shuo Yan: Beihang University; Xuanmiao Zhang: Beihang University; Xukun Shen: Beihang University,A Comparison of Gesture-based Interaction and Controller-based  Interaction for External Users in Co-located Asymmetric Virtual Reality,"Head-mounted displays (HMDs) create a highly immersive experience, while limit VR users’ awareness of external users that co-located in the same environment. In our work, we designed a wearable gesture-based interface for external users in two main asymmetric VR scenarios: (1) Object Transition, (2) Collaborative Game. We conducted a hybrid user study with twenty participants to compare the gesture-based interaction and controller-based interaction to investigate the effects on VR experience, social presence, and collaborative efficiency for external users.",,Session/Server 1,
P1117,Jingbo Zhao: China Agricultural University; Mingjun Shao: China Agricultural University; Yaojun Wang: China Agricultural University; Ruolin Xu: Duke University,Real-Time Recognition of In-Place Body Actions and Head Gestures using Only a Head-Mounted Display,"We present a unified two-stream 1-D convolutional neural network (CNN) for recognition of body actions when a user performs walking-in-place (WIP) and for recognition of head gestures when a user stands still wearing only an HMD. The present method does not require specialized hardware and/or additional tracking devices other than an HMD and can recognize a significantly larger number of body actions and head gestures than other existing methods. The utility of the method is demonstrated through a virtual locomotion task, which shows that the present body action interface is reliable in recognizing actions for virtual locomotion.",,Session/Server 1,
P1121,Maximilian Rettinger: Technical University of Munich ; Sebastian Berndt: Alexion Pharma Germany GmbH; Gerhard Rigoll: Technical University of Munich; Christoph Schmaderer: Technical University of Munich,Collaborative VR: Conveying a Complex Disease and Its Treatment,"In medical research, there are constantly new findings that lead to new insights and novel treatments. Hence, physicians always need to stay up-to-date to provide high-quality patient care. Virtual reality is unique among the available learning methods as it offers the opportunity to collaboratively explore the inside of the human body to experience and understand the complex workings of medical interventions. We realized such a VR-Learning-System and assessed its potential with medical experts (n=9). Initial results indicate that experts prefer the new system, and according to their subjective assessment, they achieved a higher learning outcome compared to conventional methods.",,Session/Server 1,
P1122,Jialin Wang: Xi'an Jiaotong-Liverpool University; Rongkai Shi: Xi'an Jiaotong-Liverpool University; Wenxuan Zheng: Xi'an Jiaotong-Liverpool University; Weijie Xie: Xi'an Jiaotong-Liverpool University; Dominic Kao: Purdue University; Hai-Ning Liang: Xi'an Jiaotong-Liverpool University,"Effect of Frame Rate on User Experience, Performance, and Simulator Sickness in Virtual Reality","This work fills a gap in the effect of the frame rate of virtual reality (VR) head-mounted displays (HMDs) on users' experience, performance, and simulator sickness (SS) symptoms. We report the findings of a study with two VR applications that compared four specific frame rates (60, 90, 120, and 180 frames per second (fps)). Our results show that 120fps is an important threshold. After 120fps, users tend to feel lower SS symptoms without a significant negative effect on their experience and performance. Higher frame rates (e.g., 120 and 180fps) can ensure better user performance than lower rates.",,Session/Server 1,
P1125,Jan Philipp Gründling: Trier University; Nathalie Schauffel: Trier University; Sebastian Pape: RWTH; Simon Oehrl: RWTH Aachen University; Torsten Wolfgang Kuhlen: RWTH Aachen University; Thomas Ellwart: Trier University; Benjamin Weyers: Trier University,Example Process for Designing a Hybrid User Interface for a Multi-Robot System,"Interaction with semi-autonomous multi-robot systems requires the integration of technical, task-related, and user-oriented details. 
While basic design principles for user interfaces already exist, they are not yet tailored to the specific case of multi-robot systems. 
This work shows how a design process tailored to multi-robot systems can be based on basic design principles and where it needs more specific methods. 
In doing so, it is indicated that virtual reality (VR) can be used as an instrument for conveying situational awareness.",,Session/Server 1,
P1129,Junyi Wang: BeiHang University; Yue Qi: BUAA,Simultaneous Scene-independent Camera Localization and Category-level Object Pose Estimation via Multi-level Feature Fusion,"In this paper, we focus on simultaneous scene-independent camera localization and category-level object pose estimation with a unified learning framework, consisting of a localization branch called SLO-LocNet, a pose estimation branch called SLO-ObjNet, a feature fusion module for feature sharing between two tasks, and two decoders. Three feature modules, covering an image fusion module in SLO-LocNet, a geometry fusion module in SLO-ObjNet, and a task fusion module between SLO-LocNet and SLO-ObjNet, are designed to promote feature sharing in two tasks. Experiments on both scene-independent localization and category-level pose estimation datasets demonstrate superior performance to other existing methods.",,Session/Server 1,
P1130,Jing Hou: Beijing Institute of Technology; Zhihe Zhao: Beijing Institute of Technology; Dongdong Weng: Beijing Institute of Technology,UI Binding Transfer for Bone-driven Facial Rigs,"We propose an automatic method to transfer the UI binding from a rigged model to a new target mesh. We use feed forward neural networks to find the mapping functions between bones and controllers of source model. The learned mapping networks then become the initial weights of an auto-encoder. Then the auto-encoder is retrained using target controllers-bones pairs obtained by the mesh transfer and bones decoupling method. Our system only requires neutral expression of the target person but allows artists to customize other basic expressions, and is evaluated by the semantic reproducibility of basic expressions and the semantic similarity.",,Session/Server 1,
P1134,Bing Ning: Beijing Institute of Fashion Technology; Mingtao Pei: Beijing Institute of Technology; Yixuan Wang: Beijing Institute of Fashion Technology; Ying Jiang: Beijing Institute of Fashion Technology; Li Liu: Beijing Institute of Fashion Technology,A VR Enabled Visualization System for Race Suits Design,"We propose a VR techniques enabled visualization system for race suits design, allowing designers to observe the design work from a near-real perspective of users. The system first constructs a virtual competition venue according to the real field settings automatically. A digital avatar that is scanned from an athlete is dressed up with a designed race suit. Then the avatar is given a sequence of preset sports motions to act in the virtual competition venue. The system can synthesize the traditional user’s views for designers to observe via VR devices and improve the efficiency of the race suit design workflow.",,Session/Server 1,
P1136,Isabella Mika Taninaka: Osaka University; Daisuke Iwai: Osaka University; Kosuke Sato: Osaka University; Parinya Punpongsanon: Osaka University,Development of Training Systems using Spatial Augmented Hand,"Training to execute procedural tasks is often a burden for novice workers. Different systems have been developed to improve users' experience and, consequentially, their performance at a task. However, systems for tasks requiring hand operation lack fine details regarding a specialist choice of hand movements or positions. This study proposes a projection-based hand visualization system that  guides the user's physical hand through a task.",,Session/Server 1,
P1146,Kwame Agyemang Baffour: Graduate Center; Oyewole Oyekoya: City University of New York - Hunter College,Effect of Look-Alike Avatars on Students' Perceptions of Teaching Effectiveness,"This paper presents a study investigating the influence of look-alike avatars on students' perceptions of teaching effectiveness in three-dimensional virtual and augmented reality environments. This study investigated three avatar representations: i) look-alike avatar of the instructor; ii) stick avatar; and iii) video recording of the instructor. Eighteen participants were asked to rank the three avatar representations, as well as the immersion experience of the teaching simulation on the virtual and augmented reality displays. The result of this study suggests that look-alike avatars can be used to represent an instructor in virtual environments.",,Session/Server 1,
P1148,Jin Qi Yeo: Singapore Institute of Technology; Xinxing Xia: Shanghai University; Kan Chen: Singapore Institute of Technology; Malcolm Yoke Hean Low: Singapore Institute of Technology; Alvin Chan: Singapore Institute of Technology; Dongyu Qiu: Singapore Institute of Technology; Frank Guan: Singapore Institute of Technology,SPAT-VR: A Holistic and Extensible Framework for VR Project Management,"With the increasing availability of VR content and affordability of consumer VR hardware systems, VR has been applied in various domains. However, to our knowledge, at present there are no existing frameworks that are applicable to the project management of the entire life cycle of building VR applications. In this paper, we present SPAT-VR: a holistic and extensible framework for VR project management. The proposed framework has been deployed to successfully complete a number of VR projects. A user survey has been conducted with all positive results received on the proposed framework.",,Session/Server 2,
P1152,Rawan Alghofaili: George Mason University; Cuong Nguyen: Adobe Research; Vojtěch Krs: Adobe Research; Nathan Carr: Adobe Research; Radomir Mech: Adobe Research; Lap-Fai Yu: George Mason University,Warpy: Contextual and Multi-view Indirect 3D Curve Sketching in Augmented Reality,"We propose Warpy, an environment-aware 3D curve drawing tool for mobile AR. Our system enables users to draw freeform curves from a distance in AR by combining 2D-to-3D sketch inference with geometric proxies. Geometric Proxies can be obtained via 3D scanning or from a list of pre-defined primitives. Warpy also provides a multi-view mode to enable users to sketch a curve from multiple viewpoints, which is useful if the target curve cannot fit within the camera’s field of view. We conducted two user studies and found that Warpy can be a viable tool to help users create complex and large curves in AR.",,Session/Server 2,
P1155-2,Renan Guarese: Royal Melbourne Institute of Technology; Emma Pretty: RMIT; Haytham Fayek: RMIT University; Fabio Zambetta: RMIT University; Ron van Schyndel: RMIT University,Evoking empathy with visually impaired people through an augmented reality embodiment experience,"To promote empathy with people that have disabilities, we propose a multi-sensory interactive experience that allows sighted users to embody having a visual impairment whilst using assistive technologies. The experiment involves blindfolded sighted participants interacting with sonification methods in order to locate targets in a real kitchen. We enquired about the perceived benefits of increasing said empathy from the blind community. We gathered sighted people’s self-reported and perceived empathy with the BVI community from sighted and blind people respectively. We re-tested sighted people's empathy after the experiment and found that their empathetic responses significantly increased.",,Session/Server 2,
P1155,Ryota Kondo: Keio University; Maki Sugimoto: Keio Univ,Investigating the Minimal Condition  of the Dynamic Invisible Body Illusion ,"Visual-tactile synchronization or visual-motor synchronization makes a non-innate body feel like one's own body (illusory body ownership). A recent study has shown that body ownership is induced to an empty space between the hands and feet from the motion of only hands and feet (dynamic invisible body illusion). However, it is unclear whether both hands and feet are necessary to induce the illusion. In this study, we investigated the minimal condition for the dynamic invisible body illusion by manipulating the presentation of hands and feet. Our results suggest that both hands and feet are necessary for the illusion.",,Session/Server 2,
P1156,Xuehuai Shi: Beihang University; Lili Wang: Beihang University; Jian Wu: Beihang University; Wei Ke: Macao Polytechnic University; Chan-Tong Lam: Macao Polytechnic University,Locomotion-aware Foveated Rendering,"We collect and analyze the viewing motion of different locomotion methods, and describe the effects of these viewing motions on HVS's sensitivity, as well as the advantages of these effects that may bring to foveated rendering. Then we propose the locomotion-aware foveated rendering method (LaFR) to further accelerate foveated rendering by leveraging the advantages. LaFR achieves similar perceptual visual quality as the conventional foveated rendering while achieving up to 1.6x speedup.",,Session/Server 2,
P1157,Johannes Hoster:  Berlin University of Applied Sciences and Technology; Dennis Ritter: Berlin University of Applied Sciences and Technology; Kristian Hildebrand: Berlin University of Applied Sciences and Technology,Style-aware Augmented Virtuality Embeddings (SAVE),"We present an augmented virtuality (AV) pipeline that enables the user to interact with real-world objects through stylised representations which match the VR scene and thereby preserve immersion. It consists of three stages: First, the object of interest is reconstructed from images and corresponding camera poses recorded with the VR headset, or alternatively a retrieval model finds a fitting mesh from the ShapeNet dataset. Second, a style transfer technique adapts the mesh to the VR game scene in order to preserve consistent immersion. Third, the stylised mesh is superimposed on the real object in real time to ensure interactivity even if the real object is moved. Our pipeline serves as proof of concept for style-aware AV embeddings.",,Session/Server 2,
P1159,Nicha Vanichvoranun: Korea Advanced Institute of Science and Technology(KAIST); Bowon Kim: KAIST; Dooyoung Kim: KAIST; Woontack Woo: KAIST ; Jeongmi Lee: KAIST; Sang Ho Yoon: KAIST,Stretchy: Enhancing Object Sensation Through Multi-sensory Feedback and Muscle Input,"Current works on 3D interaction methods mainly focus on rigid object manipulation and selection, while very few have been done on elastic object interaction. Therefore, we suggest a novel interaction method to observe and manipulate virtual fabric in a VR environment. We use multi-sensory pseudo-haptic feedback (a combination of tactile and visual feedback) and muscle strength data (EMG) to perceive the stiffness of the virtual fabric and flexible objects. For demonstration, we make fabric patches with various stiffness, and the stiffness difference can be distinguished. Our system can be
implemented in a virtual cloth store to give consumers information about product stiffness and texture.",,Session/Server 2,
P1160,Maho Otsuka: Nara Institute of Science and Technology; Monica Perusquia-Hernandez: Nara Institute of Science and Technolgy; Naoya Isoyama: Nara Institute of Science and Technology; Hideaki Uchiyama: Nara Institute of Science and Technology; Kiyoshi Kiyokawa: Nara Institute of Science and Technology,An AR Visualization System for 3D Carbon Dioxide Concentration Measurement Using Fixed and Mobile Sensors,"Recently, the use of CO2 concentration monitors as a guide for ventilation is increasing in spaces where many people gather, such as offices.However, 2D map-based visualizations are not enough to understand the progression of indoor air pollution.Therefore, we propose a three-dimensional (3D) visualization of CO2 concentration using a head-mounted display (HMD).A 3D distribution of CO2 concentration is automatically calculated using the position coordinates and measured values of fixed and mobile sensors.The results of the preliminary user evaluation suggested that AR visualization may be a more effective way to inform the need for ventilation than conventional methods.",,Session/Server 2,
P1161,Qiao Jin: University of Minnesota; Yu Liu: University of Minnesota; Puqi Zhou: George Mason University; Bo Han: George Mason University; Svetlana Yarosh: University of Minnesota; Feng Qian: University of Minnesota,Volumivive: An Authoring System for Adding Interactivity to Volumetric Video,"Volumetric video is a medium that captures the three-dimensional (3D) shape and movement of real-life objects or people. However, pre-recorded volumetric video is limited in terms of interactivity. We introduce a novel authoring system called Volumivive, which enables the creation of interactive experiences using volumetric video, enhancing the dynamic capabilities and interactivity of the medium. We provide four interaction methods that allow users to manipulate and engage with digital objects within the volumetric video. These interactive experiences can be used in both augmented reality (AR) and virtual reality (VR) settings, providing users with a more immersive and interactive experience.",,Session/Server 2,
P1162,Kyungeun Jung: KAIST ; Seungjae Oh: Kyung Hee University; Sang Ho Yoon: KAIST,Mo2Hap: Rendering performer's Motion Flow to Upper-body Vibrotactile Haptic Feedback for VR performance,"We present a novel haptic rendering method that translates the virtual performer's motions into real-time vibrotactile feedback. Our method characterizes salient motion points from proposing system Motion Salient Triangle to generate haptic parameters to highlight the performer's motions. 
Here, we employ an entire upper-body haptic system that provides vibrotactile feedback on the torso, back, and shoulders. We enable immersive virtual reality performance experiences by accommodating the performer's motions on top of motion-to-haptic feedback.",,Session/Server 2,
P1164,Douglas Zytko: Oakland University; Jonathan Chan: Oakland University,The Dating Metaverse: Why We Need to Design for Consent in Social VR,We present a participatory design study about how consent to interpersonal behavior can be designed in social VR to prevent harm. VR dating applications are used as the context of study. Through design workshops with potential VR daters (n=18) we elucidate nonconsensual experiences that should be prevented and designs for exchanging consent in VR. We position consent as a valuable lens for designing preventative solutions to harm in social VR by reframing harm as unwanted experiences that happen because of the absence of mechanics to support users in giving and denying agreement to a virtual experience before it occurs.,,Session/Server 2,
P1165,Seungwoo Son: Korea University; Yechan Yang: Korea University; Jaeyoon Lee: Korea University; Gerard Jounghyun Kim: Korea University,FakeBand: Virtual Band Music Performance with Balanced Interface for Individual Score/Rhythm Play and Inter-player Expression Coordination,"In this poster, we feature a two-user immersive VR music performance system called the ""FakeBand"". It resembles the rhythm game for a guitar play-along, but extended in its interaction model and interface design, focusing on the band performance experience in terms of coordination and collective musical expression. Coordinating timings for the tempo/accent change begins by the leader and the follower exchanging glances and using bodily gestures - nodding for tempo and large arm motion for accents. The interaction model and separated interface between the rhythm/chord play and music coordination were important in bringing about the active and frustration-free musical experience.",,Session/Server 2,
P1166,Yoshiaki Makita: Osaka university; Daisuke Iwai: Osaka University; Kosuke Sato: Osaka University,Optical See-through Scope for Observing the Global Component of a Scene,"The reflected light on a physical object can be separated into a direct illumination component and a global illumination component. Observing only the global component provides a better understanding of the reflectance property of the surface. In conventional methods, the components are separated using computer vision techniques. In this study, we developed a see-through optical scope that allows a user to selectively observe the global component using high spatial frequency pattern projection and a high spatial frequency mask with a liquid crystal panel. We confirmed that only the global component could be observed with the naked eye through the scope.",,Session/Server 2,
P1168,Yang Gao: Beihang university; Hongming Bai: Beihang University; Ziyi Pei: Beihang University; wenfeng song: Beijing information science and technology university; Aimin Hao: Beihang University,VR-based Vector Watercolor Painting System,"We develope a VR-based watercolor painting system. The system generates paintings in the form of vector graphics, which remain clear under free scaling and panoramic projection in VR space. Meanwhile,  in order to create a better operation experience and more convenient user interaction in the VR environment, we optimize the system to enable a variety of realistic watercolor effects and provide users with a number of optional painting settings such as color, size, effect, etc. After a short period of study, users can easily use the system to complete the VR painting experience.",,Session/Server 2,
P1169,Haoran Yun: Universitat Politècnica de Catalunya; Jose Luis Ponton: Universitat Politècnica de Catalunya; Carlos Andujar: Universitat Politècnica de Catalunya; Nuria Pelechano: Universitat Politècnica de Catalunya,Animation Fidelity in Self-Avatars: Impact on User Performance and Sense of Agency,"In this paper, we study the impact of the avatar's animation fidelity on different tasks. We compare three animation techniques: two of them using Inverse Kinematics to reconstruct the pose from six trackers, and a third one using a motion capture system with 17 inertial sensors. Our results show that the animation quality affects the Sense of Embodiment. Inertial-based MoCap performs significantly better in mimicking body poses. Surprisingly, IK-based solutions using fewer sensors outperformed MoCap in tasks requiring accurate positioning, which we attribute to the higher latency and the positional drift of the end-effectors.",,Session/Server 2,
P1175,"Yang Zhang: School of Mechanical,Electrical & Information Engineering; Tangjun Qu: Shandong University; Dingming Tan: Shandong University; Yulong Bian: Shandong University; Juan Liu: College of computer science and technology; Zelu Liu: Shandong University; Weiying Liu: School of Mechanical,Electrical&Information Engineering; Chao Zhou: Tsinghua University",Breaking the Ice with Group Flow:A Collaborative VR Serious Game for Relationship Enhancement ,"It is usually hard for unfamiliar people to rapidly “break the ice” in the early stage of relationship establishment, which hinders the development of relationship and team productivity. Therefore, we propose a collaborative serious game for icebreaking by combining immersive virtual reality (VR) with brain-computer interface. We design a COVID-19 themed collaboration task and propose an approach to improve empathy between team members by sharing their mental state in VR world. Moreover, we propose an EEG-based method for dynamic evaluation and enhancement of group flow to achieve better teamwork. Then, we developed a prototype system. Results of user study show that our method is beneficial to the enhancement of relationship enhancement.",,Session/Server 2,
P1176,Yoshikazu Onuki: Digital Hollywood University; Kosei Kudo: Tokyo Institute of Technology; Itsuo Kumazawa: Tokyo Institute of Technology,Enhanced Removal of the Light Reflection of Eyeglass Using Multi-Channel CycleGAN with Difference Image Equivalency Loss,"Gaze estimation is commonly used by equipping infrared light (IR) sources and cameras inside of head mount displays (HMDs). Some HMDs enable users to wear with spectacles on, and, in this case, IR light reflections of the eyeglass often causes serious obstruction to detect those of the corneal. In a previous study, we proposed multi-channel CycleGAN to generate eye images with no eyeglass from those with eyeglass. In this study, we additionally applied the difference image equivalency loss and late fusion of channels to improve removal performance and reduce mixing actions across channels, which achieved enhanced removal of eyeglass reflections.",,Session/Server 2,
P1177,"Zechen Bai: Institute of Software, Chinese Academy of Sciences; Naiming Yao: Institute of Software, Chinese Academy of Sciences; Lu Liu: Institute of Software, Chinese Academy of Sciences; Hui Chen: Institute of Software, Chinese Academy of Sciences; Hongan Wang: Institute of Software, Chinese Academy of Sciences",A Simple Approach to Animating Virtual Characters by Facial Expressions Reenactment,"Animating virtual characters is one of the core problems in virtual reality. Facial animations are able to intuitively express emotion and attitudes of virtual characters. However, creating facial animations is a non-trivial task. It depends on either expensive motion capture devices or human designers' time and effort to tune the animation parameters. In this work, we propose a learning-based approach to animate virtual characters by facial expression reenactment from abundant image data. This approach is simple yet effective, and is generalizable to various 3D characters. Preliminary evaluation results demonstrate its effectiveness and its potential to accelerate the development of VR applications.",,Session/Server 2,
P1180,Shuqi Liao: Purdue University; Yuqi Zhou: Purdue University; Voicu Popescu: Purdue University,AR Interfaces for Disocclusion--A Comparative Study,"An important application of augmented reality (AR) is the design of interfaces that reveal parts of the real world to which the user does not have line of sight. The design space for such interfaces is vast, with many options for integrating the visualization of the occluded parts of the scene into the user's main view. This paper compares four AR interfaces for disocclusion: X-ray, Cutaway, Picture-in-picture, and Multiperspective. The interfaces are compared in a within-subjects study (N = 33) over four tasks: counting dynamic spheres, pointing to the direction of an occluded person, finding the closest object to a given object, and finding pairs of matching numbers.",,Session/Server 2,
P1182,Yizhong Zhang: Microsoft Research Asia; Zhiqi Li: College of Computer Science and Technology; Sicheng Xu: Microsoft Research Asia; Chong Li: Microsoft Research Asia; Jiaolong Yang: Microsoft Research Asia; Xin Tong: Microsoft Research Asia; Baining Guo: Microsoft Research Asia,RemoteTouch: Enhancing Immersive 3D Video Communication with Hand Touch,"We present a method to enhance the immersive experience of 3D video communication by adding the hand touch capability. The participants can reach their hands out to the screen and perform hand clapping as if they were only separated by a virtual glass. The key challenge is that the hand is invisible to cameras when close to the screen. We present a dual representation of the user’s hand and a distance-based fusion method for realistic hand rendering, so that the hand is visible to the remote user throughout the touching process. Our experiments demonstrate that our method provides consistent hand contact experience between remote users and improves the immersive experience of 3D video communication.",,Session/Server 2,
P1184,Jina Kim: KAIST; Minyung Kim: KAIST; woo suk lee: Microsoft Corporation; Sang Ho Yoon: KAIST,VibAware: Context-Aware Tap and Swipe Gestures Using Bio-Acoustic Sensing,"We present VibAware, context-aware tap and swipe gesture detection using bio-acoustic sensing. We employ both active and passive sensing methods to recognize microgestures and classify inherent interaction contexts. Here, the interaction contexts refer to interaction spaces, graspable interfaces, and surface materials. With a context-aware approach, we could support adaptive input controls to enable rich and affordable interactions in Augmented Reality and Mixed Reality for graspable, material-based interfaces. Through an investigation and preliminary study, we confirmed the feasibility of tap and swipe gesture recognition while classifying associated contexts.",,Session/Server 2,
P1185,Somaiieh Rokhsaritalemi: Sejong University; Beom-Seok Ko: Sejong University; Abolghasem Sadeghi-Niaraki: Sejong University; Soo-Mi Choi: Sejong University,Geospatial Augmented Reality Tourist System ,"Most existing intelligent AR tourist systems focus on recommending or presenting information related to points of interest (POI)s that do not consider user-generated datasets and the user's preference leading to user dissatisfaction. This paper aims to develop an intelligent AR system applying tourist behavior recognition and user-generated content using volunteer geospatial information (VGI). For POIs recommendation, user-generated content have been modeled with the VIKOR and optimized with the behavior recognition method. For POIs information presentation in HoloLens, sentiment analysis was utilized for VGI data generation as well as a deep learning method was performed for POIs object detection and visualization.",,Session/Server 2,
P1187,"Carolin Stellmacher: University of Bremen; André Zenner: Saarland University, Saarland Informatics Campus; Oscar Javier Ariza Nunez: Universität Hamburg; Ernst Kruijff: Bonn-Rhein-Sieg University of Applied Sciences ; Johannes Schöning: University of St. Gallen",Continuous VR Weight Illusion by Combining Adaptive Trigger Resistance and Control-Display Ratio Manipulation,"We studied a novel combination of a hardware-based technique and a software-based pseudo-haptic approach to achieve a continuous VR weight illusion. While a modified VR controller renders adaptive trigger resistance during grasping, a manipulation of the control-display ratio (C/D~ratio) induces a sense of weight during lifting. In a psychophysical study, we tested our combined approach against the individual rendering techniques. Our findings show that participants were significantly more sensitive towards smaller weight differences in the combined weight simulations and determined weight differences faster. Our work demonstrates the meaningful benefit of combining physical and virtual methods for virtual weight perception.",,Session/Server 2,
P1189,Akshith Ullal: Vanderbilt University; Nilanjan Sarkar: Vanderbilt University School of Engineering,A Piecewise Approach to Mapping Interactions between Room-scale Environments in Remote Mixed/Augmented Reality,"Naturalistic interactions from remote settings require the user to have the ability to move and interact with their environment. However, a direct mapping of the interactions onto their photorealistic avatars will cause errors, primarily due to the different spatial configurations between the environments. Hence, the interactions need to be redirected, naturalistically. This redirection is a computationally intensive process and current techniques can only be used for localized spaces. We propose a piecewise approach, where the interaction mapping is split into a 2D locomotion and a 3D gesture redirection mechanism, reducing the computational requirement and making it applicable to room-scale environments.",,Session/Server 2,
P1193,Mark Roman Miller: Stanford University; Cyan DeVeaux: Stanford University; Eugy Han: Stanford University; Nilam Ram: Stanford University; Jeremy N. Bailenson: Stanford University,A Large-Scale Study of Proxemics and Gaze in Groups,"Scholars who study nonverbal behavior have focused an incredible amount of work on proxemics and mutual gaze. However, to date, these studies in VR have largely been reporting behavior of a small number of participants for short periods of time. In this experimental field study, we analyze the proxemics and gaze of 232 participants over two experimental studies who each contributed up to about 240 minutes of tracking data during eight weekly 30-minute social virtual reality sessions.  Participants' non-verbal behaviors changed in conjunction with manipulations of the environment and over time, and showed a range of individual and pair differences.",,Session/Server 2,
P1194,"Tristan King: University of Maryland, Baltimore County; Kyle R Davis: University of Maryland, Baltimore County; Bradley Saunders: University of Maryland, Baltimore County; James Zuber: University of Maryland, Baltimore County; Damaruka Priya Rajasagi: University of Maryland -Baltimore County; Christina Lukaszczyk: University of Maryland, Baltimore County; Anita Komlodi: University of Maryland, Baltimore County; Lee Boot: University of Maryland, Baltimore County",Immersive Visualization of Open Geospatial Data in Unreal Engine,"Immersive geospatial data visualizations are a growing area of interest for research and commercial efforts. However, access to the necessary technologies is often limited by the expense of proprietary solutions. Furthermore, available solutions do not offer the ability to select and render only portions of global maps, creating significant and unnecessary inefficiencies. We developed a pipeline for efficient generation, rendering, and interaction of open-source geospatial vector features in Unreal Engine™ Virtual Reality (VR) at almost any scale, and a user interface for interacting with these vector map features and georegistered data visualizations (as game objects) in VR applications.",,Session/Server 2,
P1198,Anil Ufuk Batmaz: Concordia University; Moaaz Hudhud Mughrabi: Kadir Has University; Mine Sarac: Kadir Has University; Mayra Donaji Barrera Machuca: Dalhousie University; Wolfgang Stuerzlinger: Simon Fraser University,Measuring the Effect of Stereo Deficiencies on Peripersonal Space Pointing,"State-of-the-art Virtual Reality (VR) and Augmented Reality (AR) headsets rely on singlefocal stereo displays. For objects away from the focal plane, such displays create a vergence-accommodation conflict (VAC), potentially degrading user interaction performance. In this paper, we study how the VAC affects pointing at targets within arm's reach with virtual hand and raycasting interaction in current stereo display systems. We conducted a user study with eighteen participants and the results indicate that participants were faster and had higher throughput in the constant VAC condition. We hope that our results enable designers to choose more efficient interaction methods in virtual environments.",,Session/Server 2,
P1204,Davide Guzzetti: Auburn University,The Case Study of a Computational Model for Immersive Human-Process Interactions within Design Optimization,"Virtual reality enables incorporating new cues and affordances into design optimization interfaces. Designers visually interact with optimization algorithms to examine solutions, define the search space, and present tradeoffs or outcomes. We hypothesize that additional dimensions of the human-process interface yield a higher probability of discovering the global optimal solution. To test this hypothesis, this work develops a computational model for visual-based process interactions in design optimization. The model is inspired by the Van Wijk model for visual analytics. Initial numerical results support the hypothesis.",,Session/Server 2,
P1205,Carlos Alfredo Tirado Cortes: University of New South Wales; Chin-Teng Lin: Australian AI Institute; Tien-Thong Nguyen Do: Australian AI Institute; Hsiang-Ting Chen: University of Adelaide,An EEG-based Experiment on VR Sickness and Postural Instability While Walking in Virtual Environments,"This paper studies VR sickness and postural instability while the user walks in an immersive virtual environment using an electroencephalogram (EEG) headset and a full-body motion capture system. The experiment induced VR sickness by gradually increasing the translation gain beyond the user’s detection threshold. The participants with VR sickness showed a reduction of alpha power, a phenomenon previously linked to a higher workload and efforts to maintain postural control. In contrast, those without VR sickness exhibited brain activities previously linked to fine cognitive-motor control. The EEG result suggests that participants with VR sickness could maintain their postural stability at the cost of a higher cognitive workload.",,Session/Server 2,
P1206,Daiki Kodama: Kuzuoka Amemiya Narumi Lab; Takato Mizuho: The University of Tokyo; Yuji Hatada: The University of Tokyo; Takuji Narumi: the University of Tokyo; Michitaka Hirose: The University of Tokyo,Effects of Collaborative Training Using Virtual Co-embodiment on Motor Skill Learning,"Many VR systems, which enable users to observe and follow a teacher’s movements from a first-person perspective, reported their usefulness for motor skill learning. However, learners using these methods feel weak agency because they need to be aware of following the teacher's movements, preventing motor skill retention. To address this problem, we propose applying virtual co-embodiment, in which two users are immersed in the same virtual avatar, as a method that arises strong agency in motor skill learning. The experiment showed that learning in virtual co-embodiment with the teacher improves learning efficiency compared with sharing the teacher’s perspective or alone.",,Session/Server 2,
P1208,Jingya Li: Beijing Jiaotong University,Real-Time Augmented Reality Visual-Captions for  Deaf and Hard-of-Hearing Children in Classrooms,"Deaf and hard-of-hearing (DHH) children experience difficulties in mainstream classrooms since they cannot access audio information effectively. Although tools like captions are developed specifically to assist DHH individuals, primary school children have trouble to read or understand the text. To address this challenge, this paper develops an AR-based visual-captions, which will transfer the speech to text and images in real-time and display the information around the teacher in classrooms. The AR visual-captions aims to help DHH children better receive information and enhance their classroom experience. We describe the concept, design and implementation of our prototype, and discuss future research directions.",,Session/Server 2,
P1213,Panagiotis Kourtesis: Inria; Rayaan Amir: University of Edinburgh; Josie Linnell: University of Edinburgh; Ferran Argelaguet Sanz: Inria; Sarah MacPherson: University of Edinburgh,"Cybersickness, Cognition, & Motor Skills: The Effects of Music, Gender, and Gaming Experience","This paper examines the effects of cybersickness on the cognitive, motor, and reading performance in VR, as well as evaluates the mitigating effects of music on cybersickness, the role of gender, and the computing, VR, and gaming experience of the user. Joyful and Calming music substantially decreased the intensity of nausea-related symptoms. Only Joyful music significantly reduced the overall cybersickness intensity. Cybersickness decreased verbal working memory performance and pupil size, decelerating reaction time, and reading speed. The gaming experience was negatively correlated with cybersickness. Cybersickness’s intensity was not different between female and male participants with comparable gaming experience.",,Session/Server 2,
P1214,Hui Fang: Beijing Institute of Technology; Dongdong Weng: Beijing Institute of Technology; Zeyu Tian: Beijing Institute of Technology; Zhen Song: The Central Academy of Drama,Audio to Deep Visual: Speaking Mouth Generation Based on 3D Sparse Landmarks,"Having a system to automatically generate a talking mouth in sync with input speech would enhance speech communication and enable many novel applications. This article presents a new model that can generate 3D talking mouth landmarks from Chinese speech. We use sparse 3D landmarks to model the mouth motion, which are easy to capture and provide sufficient lip accuracy. The 4D mouth motion dataset was collected by our self-developed facial capture device, filling the gap in the Chinese speech-driven lip dataset. The experimental results show that the generated talking landmarks achieve accurate, smooth, and natural 3D mouth movements.",,Session/Server 2,
P1219,David Michael Broussard: University of Louisiana at Lafayette; Christoph W Borst: University of Louisiana at Lafayette,Heat Metaphor for Attention Estimation for Educational VR,"We prototype a technique, for educational VR applications, to estimate each student's level of attention in real time. Our system attaches scores to both students and objects, which change in response to eye-tracked gaze intersections. Compared to a simple angle-based approach, our system provides a dynamic and granular representation of object importance and frees the lesson designer from having to fully define objects of interest and timings. Our system takes into account simultaneous behaviors of multiple students and filters out brief behavioral deviations of attentive students. The results may help a teacher or a virtual agent better guide students.",,Session/Server 2,
P1221,David Michael Broussard: University of Louisiana at Lafayette; Christoph W Borst: University of Louisiana at Lafayette,Tether-Handle Interaction for Retrieving Out-of-Range Objects in VR,"Many VR applications allow users to grab and manipulate virtual objects, whether it be with a motion-tracked controller or a hand-tracked gestural input system. However, when objects move out-of-reach, standard grabbing interactions become less useful. Techniques for retrieving distant objects often use separate interaction metaphors from the main grabbing technique, such as pointing or hand extension. However, to avoid such metaphor switching, and to avoid cluttering a controller or gestural interface with multiple functions, we created a novel object retrieval technique that dynamically presents a grabbable handle tethered to a distant object.",,Session/Server 2,
P1226,Chenxin Wu: Xi’an Jiaotong-Liverpool University; Wenxin Sun: Xi’an Jiaotong-Liverpool University; Mengjie Huang: Xi’an Jiaotong-Liverpool University; Rui Yang: Xi’an Jiaotong-Liverpool University,Feeling of Control for Virtual Object Manipulation in Handheld AR,"One essential feature of handheld augmented reality (AR) is the ability to manipulate virtual objects employing different interaction techniques, such as touch-based, mid-air and tangible interactions. A critical factor for user experience evaluation of AR systems is users’ feeling of control. However, little was known in literature about feeling of control for virtual object manipulation in handheld AR. This study explores users’ feeling of control among three interaction techniques via self-report and task performance. The findings reveal that users perceived a stronger feeling of control when applying tangible interaction technique to manipulate virtual objects than other techniques in handheld AR.",,Session/Server 2,
P1228,Mingfei Yu: Computer Science of Technology; Lei Zhang: Beijing Institute of Technology; Wufan Wang: Beijing Institute of Technology; Jiahui Wang: Beijing Institute of Technology,SCP-SLAM: Accelerating DynaSLAM with Static Confidence Propagation,"This paper proposes SCP-SLAM, which accelerates DynaSLAM by running the CNN only on keyframes and propagating static confidence through other frames in parallel. The proposed static confidence characterizes the moving object features by the residual defined by inter-frame geometry transformation, which can be computed quickly. Our method combines the effectiveness of a CNN with the efficiency of static confidence in a tightly coupled manner. Extensive experiments on the publicly available TUM and Bonn RGB-D dynamic benchmark datasets demonstrate the efficacy of the method. Compared with DynaSLAM, it enables acceleration by a factor often on average, but retains comparable localization accuracy.",,Session/Server 2,
P1231,Kaan Akşit: University College London; Yuta Itoh: The University of Tokyo,HoloBeam: Paper-Thin Near-Eye Displays,"Our work, HoloBeam, introduces a new milestone for near-eye displays. In our design, a custom holographic projector populates a micro-volume located at some distance (1-2 meters) with multiple planes of images. Users view magnified copies of these images from this small volume with the help of an eyepiece that is either a Holographic Optical Element (HOE) or a set of lenses. Our HoloBeam prototypes demonstrate the thinnest AR glasses to date with a submillimeter thickness (e.g., 120 um thick). In addition, HoloBeam prototypes demonstrate near retinal resolutions (24 cycles per degree) with a 70 degrees-wide field of view.",,Session/Server 2,
P1232,Eunhwa Song: KAIST; Minju Baeck: KAIST; Jihyeon Lee:  Korea Advanced Institute of Science and Technology; Seo Young Oh: KAIST; Dooyoung Kim: KAIST; Woontack Woo: KAIST ; Jeongmi Lee: KAIST; Sang Ho Yoon: KAIST,"Memo:me, an AR Sticky Note With Priority-Based Color Transition and On-Time Reminder","We propose Memo:me, an AR sticky note with priority-based color transition and on-time reminders in smartphones. For the priority-based color transition, the user can choose by himself among three different colors, or the system changes the color automatically 10
minutes before the entered time. For the on-time reminder, Memo:me provides a visual notification and a sound at the designated time. We enabled users to create virtual notes on planes, or carry daily objects with the virtual notes attached. We expect that our system would benefit users to manage their tasks in a time-appropriate manner.",,Session/Server 2,
P1235,Ruiqi Chen: Duke Kunshan University; Shuhe Wang: Duke Kunshan University; Xuhai Xu: University of Washington; Lan Wei: Duke Kunshan University; Yuling Sun: East China Normal University; Xin Tong: Duke Kunshan University,Design and Evaluation of a VR Therapy for Patients with Mild Cognitive Impairment and Dementia: Perspectives from Patients and Stakeholders,"Immersive virtual reality (VR) technology has shown great promise in intervening in Mild Cognitive Impairment (MCI) and Mild Dementia (MD) patients' cognitive therapies. However, current VR applications mainly focus on task performances, ignoring the significant values of other stakeholders (caregivers and therapists) and their roles in MCI/MD patients' therapies. We designed a VR way-finding cognitive task and evaluated its usability and effectiveness by interviewing both MCI/MD patients and stakeholders. Findings suggest that the interventions of stakeholders can improve the performance of the participants. Besides, we identified several significant factors in designing VR cognitive tasks for patients with MCI/MD.",,Session/Server 2,
P1236,Nicha Vanichvoranun: Korea Advanced Institute of Science and Technology(KAIST); Sang Ho Yoon: KAIST,A Lightweight Wearable Multi-joint Force Feedback for High Definition Grasping in VR,Various research develops kinesthetic gloves that only render force on the distal interphalangeal joints (DIP) and often require a complex mechanism. Our research proposes a novel design of a wearable haptic device enabling kinesthetic feedback to all finger joints to promote precise grasping in VR. We employ electrostatic-based force feedback to form a clutch mechanism that we extend to all finger joints. Using the electrostatic-based clutch allows us to maintain a thin and light form factor for devising the prototype. Our proposed method supports a blocking force of up to 30N per joint.,,Session/Server 2,
P1238,Graham Wilson: University of Glasgow; Mark McGill: University of Glasgow; Daniel Medeiros: University of Glasgow; Stephen Anthony Brewster: University of Glasgow,A Lack of Restraint: Comparing Virtual Reality Interaction Techniques for Constrained Transport Seating,"Standalone Virtual Reality (VR) headsets can now be used in cars, trains and planes. However, the spaces around transport seating are constrained by other seats, walls and passengers, leaving users with little space in which to interact safely and acceptably. Therefore, they cannot use most commercial VR applications, as they are designed for unobstructed 1-2m2 home environments. In this paper, we conducted a gamified user study to test whether three at-a-distance interaction techniques from the literature could be adapted to support common VR movement inputs identified from commercial games, and so equalise the interaction capabilities of at-home and constrained users.",,Session/Server 2,
P1243,Masatoshi Iuchi: Graduate School of Science and Technology; Yuito Hirohashi: Faculty of Science and Engineering; Hiromasa Oku: Faculty of Informatics,Proposal for an aerial display using dynamic projection mapping on a distant flying screen,"In this study, we propose a method for an aerial display.
The method uses a high-speed gaze control system and a laser display to perform projection mapping on a screen at a distance, which is suspended from a flying drone.
A prototype system was developed, and performance evaluation and application experiments were conducted.
In the performance evaluation, it was confirmed that the system was capable of controlling the gaze over a wide range and of performing dynamic projection mapping on a distant object 200 m away.
In application experiments, dynamic projection mapping was successfully performed on a screen attached to a drone in flight at a distance of approximately 36 m, demonstrating the effectiveness of the proposed method.",,Session/Server 2,
P1250,Junjie Chen: East China Normal University; Chenhui Li: East China Normal University; Sicheng Song: East China Normal University; Changbo Wang: East China Normal University,"iARVis: Mobile AR Based Declarative Information Visualization Authoring, Exploring and Sharing","We present iARVis, a proof-of-concept toolkit for creating, experiencing, and sharing mobile AR-based information visualization environments, which frequently necessitate low-level programming expertise and lengthy hand encodings to construct. We present a declarative approach for defining the AR environment, including how information is automatically positioned, laid out, and interacted with to improve construction efficiency. We also present advanced features such as hot-reload, persistence and continuity, etc., to ensure convenient creation for designers and seamless experiences for users. To demonstrate the viability and extensibility, we evaluate iARVis using different use cases along with performance evaluation and expert reviews.",,Session/Server 2,
P1255,Jinghuai Lin: University of Würzburg; Johrine Cronjé: University of Würzburg; Ivo Käthner: University of Würzburg; Paul Pauli: University of Würzburg; Marc Erich Latoschik: University of Würzburg,Measuring Interpersonal Trust towards Virtual Humans with a Virtual Maze Paradigm,"This work proposes a validated behavioural tool to measure interpersonal trust towards a specific virtual social interaction partner in social VR. The task of the users (the trustors) is to navigate through a maze in virtual reality, where they can interact with a virtual human (the trustee). In the validation study, participants interacting with a trustworthy avatar asked for advice more often than those interacting with an untrustworthy avatar, indicating that the paradigm is sensitive to the differences in interpersonal trust and can be used to measure trust towards virtual humans.",,Session/Server 2,
P1265,Qiang Qu: The University of Sydney; Xiaoming Chen: Beijing Technology and Business University; Yuk Ying Chung: The University of Sydney; Weidong Cai: The University of Sydney,LFACon: Introducing Anglewise Attentions to Light Field Space in No-reference Quality Assessment,"Compared to 2D image assessment, light field image quality assessment (LFIQA) needs to consider not only the image quality in spatial domain but also the quality consistency in angular domain. In this paper, we propose a novel concept of “anglewise attention” by introducing a multihead self-attention mechanism to the angular domain of a light field image (LFI). This mechanism better reflects the LFI quality. Based on the proposed anglewise attention, we further propose our light field attentional convolutional neural network (LFACon) as an LFIQA metric. Our experimental results show that the proposed LFACon metric significantly outperforms the state-of-the-art LFIQA metrics.",,Session/Server 2,
P1270,Ajoy Savio Fernandes: Meta; T. Scott Murdison: Meta; Michael J Proulx: Reality Labs Research,Leveling the Playing Field: A Comparative Reevaluation of Unmodified Eye-Tracking as an Input and Interaction Modality for VR,"Here we establish a much-needed baseline for evaluating eye tracking interactions for AR/VR targeting and selecting tasks, including both traditional standards and those more aligned with AR/VR interactions today. In a targeting and button press selection task, we compare completely unadjusted, cursor-less, eye tracking to controller and head tracking, which both had cursors. Unmodified eye tracking, without any form of a cursor, or feedback, outperformed the head and performed comparably to the controller in throughput and in subjective ratings. Eye tracking, with even minor sensible interaction design modifications, has tremendous potential in reshaping interactions in next-generation AR/VR head mounted displays.",,Session/Server 2,
P1271,"Kenichi Ito: The University of Tokyo; Juro Hosoi: The University of Tokyo; Yuki Ban: The University of Tokyo; Takayuki Kikuchi: Technology and Innovation Center, Daikin Industries, Ltd.; Kyosuke Nakagawa: Technology and Innovation Center, Daikin Industries, Ltd.; Hanako Kitagawa: Technology and Innovation Center, Daikin Industries, Ltd.; Chizuru Murakami: Technology and Innovation Center, Daikin Industries, Ltd.; Yosuke Imai: Technology and Innovation Center, Daikin Industries, Ltd.; Shinichi Warisawa: The University of Tokyo",Wind comfort and emotion can be changed by the cross-modal presentation of audio-visual stimuli of indoor and outdoor environments,"Previous research on wind stimuli for relaxation has overlooked the impact of multisensory stimuli on wind comfort. Our study aimed to investigate whether audio-visual stimuli in virtual environments can alter the effects of wind on comfort and emotions. We measured wind comfort and emotion when participants experienced outdoor and indoor virtual environments through virtual reality. Results indicate that the virtual environment of an outdoor meadow and natural wind sound significantly improved wind comfort, openness of wind, and emotional state. Simulated natural wind also reduced mental stress compared to a condition without wind, as shown by questionnaires and biometric data.",,Session/Server 2,
P1278,Carlos Quijano-Chavez: Federal University of Rio Grande do Sul; Carla M. Dal Sasso Freitas: Federal University of Rio Grande do Sul; Luciana Nedel: Federal University of Rio Grande do Sul (UFRGS),Comparing Scatterplot Variants for Temporal Trends Visualization in Immersive Virtual Environments,"Trends are changes in variables or attributes over time. Interpreting tendencies require observing the lines or points behavior regarding increments, decrements, or reversals. Previous work assessed variants of scatterplots like Animation, Small Multiples, and Overlaid Trails to compare the effectiveness of trends representation using large and small displays. In this work, we study how best to enable the analyst to explore and perform temporal trend tasks with these same techniques in immersive virtual environments. Results show that Overlaid Trails are the fastest overall, followed by Animation and Small Multiples, while accuracy is task-dependent. We also report results from interaction measures and questionnaires.",,Session/Server 2,
P1286,"Kanglei Zhou: Beihang University; Ruizhi Cai: Beihang University; Yue Ma: Beihang University; Qingqing Tan: Capital Institute of Pediatrics; Xinning Wang: Capital Institute of Pediatrics; Jianguo Li: Capital Institute of Pediatrics; Hubert P. H. Shum: Durham University; Frederick W. B. Li: University of Durham; Song Jin: Beijing Weilai high tech technology Co., Ltd; Xiaohui Liang: Beihang University",A Video-Based Augmented Reality System for Human-in-the-Loop Muscle Strength Assessment of Juvenile Dermatomyositis,"JDM is characterized by skin rashes and muscle weakness. The CMAS is commonly used to measure the degree of muscle involvement for diagnosis. However, humans are subject to personal bias, and automatic AQA algorithms cannot guarantee 100% accuracy. Therefore, we propose a video-based augmented reality system for human-in-the-loop muscle strength assessment of children with JDM. Our core insight is to visualize the AQA results as a virtual character facilitated by a 3D animation dataset, so that users can compare the real-world patient and the virtual character to verify the AQA results. The experimental results verify the effectiveness of our system.",,Session/Server 2,
P1289,Florian Weidner: Ilmenau University of Technology; Jana Elena Maier janamaier: Ilmenau University of Technology; Wolfgang Broll: Ilmenau University of Technology,"Eat, Smell, See: Investigating Cross-Modal Correspondence when Eating in VR","Integrating taste in AR/VR applications has various promising use cases - from social eating to the treatment of disorders. We present the results of a user study in which participants were confronted with congruent and incongruent visual and olfactory stimuli while eating a tasteless food product in VR. With our results, we highlight challenges that arise when trying to influence perception, show that vision does not always dominate or guide perception, and emphasize that tri-modal incongruency hampers perception enormously. We discuss our data within the context of multisensory integration, AR/VR human-food interaction, and basic human perception.",,Session/Server 2,
P1297,"Tianyang Dong: Zhejiang University of Technology; Tieqi Gao:  College of Computer Science and Technology, Zhejiang University of Technology; Yinyan Dong: Zhejiang University of Technology; Liming Wang: Zhejiang University of Technology; Kefan Hu: Zhejiang University of Technology; Jing Fan: Zhejiang University of Technology",FREE-RDW: A Multi-user Redirected Walking Method for Supporting Non-forward Steps,"Redirected walking (RDW) algorithms for non-forward steps can enrich the movement direction of users' virtual roaming. In addition, the non-forward motions have a greater curvature gain, which can be used to reduce resets in RDW. This paper presents a new method of multi-user RDW for supporting non-forward steps, which adds the options of sideward and backward steps to extend the virtual reality (VR) locomotion. Our method adopts a user collision avoidance strategy based on optimal reciprocal collision avoidance (ORCA) and optimizes it into a linear programming problem to obtain the optimal velocity for users. The experiments show that our method performs well in virtual scenes withå forward and non-forward steps.",,Session/Server 2,
P1310,Shiwei Cheng: Zhejiang University of Technology; Jieming Tian: Zhejiang University of Technology,A Haptic Stimulation-Based Training Method to Improve the Quality of Motor Imagery EEG Signal in VR,"With the emergence of brain-computer interaction interface (BCI) technology and virtual reality (VR), how to improve the quality of motor imagery (MI) electroencephalogram (EEG) signal has become a key issue for MI BCI applications under VR. In this paper, we proposed to enhance the quality of MI EEG signal by using haptic stimulation training. We designed a first-person perspective and a third-person perspective scene under VR, and the experimental results showed that the left- and right-hand MI EEG quality of the participants improved compared with that before training. We implemented a VR-BCI application system, in which the average classification accuracy by the participants after training increased.",,Session/Server 2,
P1319,Chun Wei Ooi: trinity college Dublin; Yuichi Hiroi: The University of Tokyo; Yuta Itoh: The University of Tokyo,A compact photochromic occlusion capable see-through display with holographic lenses.,"This paper presents a compact photochromic occlusion-capable OST design using multilayer, wavelength-dependent holographic optical lenses (HOLs). Our approach employs a single digital micromirror display (DMD) to form both the occlusion mask with UV light and a virtual image with visible light in a time-multiplexed manner. We demonstrate our proof-of-concept system on a bench-top setup and assess the appearance and contrasts of the displayed image. We also suggest potential improvements for current prototypes to encourage the community to explore this occlusion approach.",,Session/Server 2,
P1320,Mykola Maslych: University of Central Florida; Yahya Hmaiti: University of Central Florida; Ryan Ghamandi: University of Central Florida; Paige Leber: University of Central Florida; Ravi Kiran Kattoju: University of Central Florida; Jacob Belga: University of Central Florida; Joseph LaViola: University of Central Florida,Toward Intuitive Acquisition of Occluded VR Objects Through an Interactive Disocclusion Mini-map,"Standard selection techniques such as ray casting fail when virtual objects are partially or fully occluded. In this paper, we present two novel approaches that combine cone-casting, world-in-miniature, and grasping metaphors to disocclude objects in the representation local to the user. Through a within-subject study where we compared 4 selection techniques across 3 levels of object occlusion, we found that our techniques outperformed an alternative one that also focuses on maintaining the spatial relationships between objects. We discuss application scenarios and future research directions for these types of selection techniques.",,Session/Server 2,
P1322,Brendan David-John: Virginia Tech; Kevin Butler: University of Florida; Eakta Jain: University of Florida,Privacy-preserving datasets of eye-tracking samples with applications in XR,"XR technology has advanced significantly in recent years and will enable the future of work, education, socialization, and entertainment. Eye-tracking data supports XR interaction, animating virtual avatars, and rendering optimizations. While eye tracking enables beneficial applications, it also introduces a privacy risk by enabling re-identification of users. We applied privacy definitions of k-anonymity and plausible deniability (PD) to eye-tracking sample datasets and evaluated them against differential privacy (DP). Our results suggest that both PD and DP produced practical privacy-utility trade-offs between re-identification and activity classification accuracy, while k-anonymity performed best at retaining utility for gaze prediction.",,Session/Server 2,
P1344,"Junhua Liu: The chinese university of Hong Kong,Shenzhen; Boxiang Zhu: he Chinese University of Hong Kong, Shenzhen; Fangxin Wang: The Chinese University of Hong Kong, Shenzhen; Yili Jin: The Chinese University of Hong Kong, Shenzhen; Wenyi Zhang: The Chinese University of Hong Kong, Shenzhen; zihan xu: The Chinese University of Hong Kong, Shenzhen; Shuguang Cui: The Chinese University of Hong Kong",CaV3: Cache-assisted Viewport Adaptive Volumetric Video Streaming,"Volumetric video (VV) recently emerges as a new form of video application providing a photorealistic immersive 3D viewing experience. Existing works mostly focused on predicting the viewport for a tiling-based adaptive VV streaming, which however only has quite a limited effect on resource saving.  We argue that the content repeatability in the viewport can be further leveraged, and for the first time, propose a client-side cache-assisted strategy that aims to buffer the repeatedly appearing VV tiles in the near future to reduce the redundant content transmission. The extensive evaluation of the dataset confirms the superiority of CaV3, which outperforms the SOTA algorithm by 15.6%-43% in viewport prediction and 13%-40% in system utility.",,Session/Server 2,
P1355,Kosuke Hiratani: Osaka University; Daisuke Iwai: Osaka University; Yuta Kageyama: Osaka University; Parinya Punpongsanon: Osaka University; Takefumi Hiraki: Osaka University; Kosuke Sato: Osaka University,Shadowless Projection Mapping using Retrotransmissive Optics,"This paper presents a shadowless projection mapping system for interactive applications in which a target surface is frequently occluded from a projector with a user's body. We propose a delay-free optical solution for this critical problem. Specifically, as the primary technical contribution, we apply a large format retrotransmissive plate to project images onto the target surface from wide viewing angles. We also tackle technical issues unique to the proposed shadowless principle such as stray light and touch detection. We implement a proof-of-concept prototype and validate the proposed techniques through experiments.",,Session/Server 2,
P1357,Karl Eisenträger: Humboldt University of Berlin; Judith Haubner: Chemnitz University of Technology; Jennifer Brade: Institute for Machine Tools and Production Processes (IWP); Wolfgang Einhäuser: Chemnitz University of Technology; Alexandra Bendixen: Chemnitz University of Technology; Sven Winkler: Professorship of Production Systems and Processes; Philipp Klimant: Institute for Machine Tools and Production Processes; Georg Jahn: Chemnitz University of Technology,Evaluating the Effects of Virtual Reality Environment Learning on Subsequent Robot Teleoperation in an Unfamiliar Building,"We compared three methods to prepare for tasks performed by teleoperating a robot in a building. One group studied a floorplan, the second explored a VR reconstruction of the building from a normal-sized avatar’s perspective and a third explored the VR from a giant-sized avatar’s perspective. Giant VR and floorplan took less learning time than normal VR. Both VR methods significantly outperformed the floorplan in a orientation task. Navigation was quicker in the giant compared to the normal perspective and the floorplan. We conclude that normal and giant perspective in VR are viable for preparation of teleoperation in unfamiliar environments.",,Session/Server 2,
P1373,Sai-Keung Wong: National Yang Ming Chiao Tung University; Matias Volonte: Northeastern University; Kuan-yu Liu: Multimedia Engineering at National Chiao Tung University; Elham Ebrahimi: UNC Wilmington; Sabarish V. Babu: Clemson University,Comparing Visual Attention with Leading and Following Virtual Agents in a Collaborative Perception-Action Task in VR,"This paper presents a within-subject study to investigate the effects of leading and following behaviors on user visual attention behaviors when collaborating with a virtual agent (VA) during performing transportation tasks. There were two conditions, namely leader VA (LVA) and follower VA (FVA). The leader gave instructions to the follower to perform actions. In the FVA condition, the users played the leader role, while they played the follower role in the LVA condition. The preliminary results revealed significant differences in the user visual attention behaviors between the follower and leader VA conditions during the transportation tasks.",,Session/Server 2,
P1379,Miki Matsumuro: Ritsumeikan University; Shohei Mori: Graz University of Technology; Yuta Kataoka: Ritsumeikan University; Fumiaki Igarashi: Kusatsu; Fumihisa Shibata: Ritsumeikan University; Asako Kimura: Ritsumeikan Univ.,Modified Egocentric Viewpoint for Softer Seated Experience in Virtual Reality,"We aimed to change the perceived haptic features of a chair by shifting the position and angle of the users' viewpoints in virtual reality. To enhance the seat softness, we shifted the virtual viewpoint using an exponential formula soon after a user's bottom contacted the seat surface. We also manipulated the viewpoint to change the flexibility of the virtual backrest. Subjective evaluations confirmed that participants perceived the seat as softer and the backrest more flexible than the actual ones, though significant changes resulted in discomfort.",,Session/Server 2,
P1384,Manshul Belani: IIIT-Delhi; Harsh Vardhan Singh: Indraprastha Institute of Information Technology Delhi; Aman Parnami: IIIT-Delhi; Pushpendra Singh: IIIT-Delhi,Investigating Spatial Representation of Learning Content in Virtual Reality Learning Environments,"We discuss spatial representation of learning content in VR. The 1st study discusses the effect of 4 different placements of learning content in VR (learning laser cutting process) with 42 participants: world-anchored (TV screen in the environment), user-anchored (panel anchored to the controller or HMD of the user), and object-anchored (panel anchored to the object of interest). While knowledge gain, transfer, and cognitive load were not significantly different, the object-anchored placement scored significantly better than the TV screen and HMD conditions on 3 user experience scales. In the 2nd study, 22 participants chose from these 4 placements in the VR environment followed by semi-structured interviews to understand their preferences.",,Session/Server 2,
P1390,Wei Liang: Beijing Institute of Technology; Luhui Wang: Beijing Institute of Technology; Xinzhe Yu: Beijing Institute of Technology; Changyang Li: George Mason University; Rawan Alghofaili: George Mason University; Yining Lang: Alibaba Group; Lap-Fai Yu: George Mason University,Optimizing Product Placement for Virtual Stores,"The recent popularity of consumer-grade virtual reality devices has enabled users to experience immersive shopping in virtual environments. As in a real-world store, the placement of products in a virtual store should appeal to shoppers, which could be time-consuming, tedious, and non-trivial to create manually. Thus, this work introduces a novel approach for automatically optimizing product placement in virtual stores. Our approach considers product exposure and spatial constraints, applying an optimizer to search for optimal product placement solutions. We conducted qualitative scene rationality and quantitative product exposure experiments to validate our approach with users.",,Session/Server 2,
P1406,Yang Xu: Northwest University; Yuanfa Jiang: Northwest University; Shibo Wang: Northwest University; Kang Li: Northwest University; Guohua Geng: Northwest University,Delta Path Tracing for Real-Time Global Illumination in Mixed Reality,"Visual coherence between real and virtual objects is important in mixed reality. However, the illumination change produced by the inserted virtual objects is difficult to compute in real-time due to the heavy computation demands. In this work, we propose delta path tracing (DPT), which only computes the radiance blocked by the virtual objects from the light sources at the primary hit points of path tracing. DPT can reduce the number of direct illumination queries and avoid rendering scenes twice to improve performance. We implement DPT using hardware-accelerated ray tracing on modern GPUs, and the results demonstrate that our method can produce plausible visual coherence between real and virtual objects at real-time frame rates.",,Session/Server 2,
P1407,"Abby Wysopal: University of California, Santa Barbara; Vivian Ross: University of California, Santa Barbara; Joyce E Passananti: University of California, Santa Barbara; Kangyou Yu: University of California, Santa Barbara; Brandon Huynh: University of California, Santa Barbara; Tobias Höllerer: University of California, Santa Barbara",Level-of-Detail AR: Dynamically Adjusting Augmented Reality Level of Detail Based on Visual Angle,"We present a Level-of-Detail AR mechanism to dynamically render textual and interactable content based on the visual angle that an application subtends, taking into account legibility, interactability, and viewability. When tested, our mechanism functioned as intended out-of-the-box on 44 of the 45 standard user interface Unity prefabs in Microsoft's Mixed Reality Tool Kit. We additionally evaluated the mechanism's impact on task performance, user distance, and subjective satisfaction through a mixed-design user study with 45 participants. Statistical analysis of our results revealed significant task-dependent differences in user performance between the modes. User satisfaction was consistently higher for the Level-of-Detail AR condition.",,Session/Server 2,
P1411,Mallesham Dasari: Carnegie Mellon University; Edward Lu: Carnegie Mellon University; Michael W Farb: Carnegie Mellon University; Nuno Pereira: Carnegie Mellon University; Ivan Liang: Carnegie Mellon University; Anthony Rowe: Carnegie Mellon University,Scaling VR Video Conferencing,"Virtual reality platforms are being challenged to support live performances, sporting events, and conferences with thousands of users across seamless virtual worlds. Current systems struggle to meet these demands which has led to high-profile events with groups of users isolated in parallel sessions. To this end, we present an architecture that supports hundreds of users in a single virtual environment. We leverage the property of spatial locality with two key optimizations: 1) a Quality of Service scheme to prioritize traffic based on users’ locality, 2) a resource manager that allocates client connections across multiple servers based on user proximity. Through extensive evaluations, we demonstrate the scalability of our platform.",,Session/Server 2,
P1425,Yukang Yan: Tsinghua University; Haohua Liu: Cornell University; Yingtian Shi: Tsinghua University; Jingying Wang: University of Michigan; Ruici Guo: Beijing University of Post and Telecommunication; Zisu Li: The Hong Kong University of Science and Technology; Xuhai Xu: University of Washington; Chun Yu: Tsinghua University; Yuntao Wang: Tsinghua University; Yuanchun Shi: Tsinghua University,ConeSpeech: Exploring Directional Speech Interaction for Multi-Person Remote Communication in Virtual Reality,"We present ConeSpeech, a virtual reality (VR) based multi-user remote communication technique, which enables users to selectively speak to target listeners without distracting bystanders. With ConeSpeech, the user looks at the target listener and only in a cone-shaped area in the direction can the listeners hear the speech. We conducted a user study to determine the modality to control the cone-shaped delivery area. Then we implemented the technique and evaluated its performance in three typical multi-user communication tasks by comparing it to two baseline methods. Results show that ConeSpeech balanced the convenience and flexibility of voice communication.",,Session/Server 2,
P1438,Sunyoung Bang: Korea Advanced Institute of Science and Technology; Woontack Woo: KAIST ,Enhancing the Reading Experience on AR HMDs by Using Smartphones as Assistive Displays,"The reading experience on current augmented reality head mounted displays is often impeded by the devices’ low perceived resolution, translucency, and small field of view. To resolve this issue, we explore the use of smartphones as assistive displays to AR HMDs. To validate the feasibility of our approach, we conducted a user study in which we compared a smartphone-assisted hybrid interface against using the HMD only for two different text lengths. The results demonstrate that the hybrid interface yields a lower task load regardless of the text length, although it does not improve task performance. Furthermore, the hybrid interface provides a better experience regarding user comfort, visual fatigue, and perceived readability.",,Session/Server 2,
P1440,Riku Otono: Nara Institute of Science and Technology; Adélaïde Genay: Inria; Monica Perusquia-Hernandez: Nara Institute of Science and Technolgy; Naoya Isoyama: Nara Institute of Science and Technology; Hideaki Uchiyama: Nara Institute of Science and Technology; Martin Hachet: Inria; Anatole Lécuyer: Inria; Kiyoshi Kiyokawa: Nara Institute of Science and Technology,I'm Transforming! Effects of Visual Transitions to Change of Avatar on the Sense of Embodiment in AR,"We explore how applying smooth visual transitions at the moment of the change can help to maintain the SoE and benefit the general user experience. To address this, we implemented an AR system allowing users to embody a regular-shaped avatar that can be transformed into a muscular one through a visual effect. The avatar's transformation can be triggered either by the user through physical action (``active'' transition), or automatically launched by the system (``passive'' transition). The results showed that visual effects controlled by the user when changing their avatar's appearance can benefit their experience by preserving the SoE and intensifying the Proteus effects.",,Session/Server 2,
P1447,"Camille Truong-Allié: Mines Paris - PSL; Martin Herbeth: Spectral TMS; Alexis Paljic: MINES ParisTech, PSL-Research University","A study of the influence of AR on the perception, comprehension and projection levels of situation awareness","We examine how Augmented Reality (AR) impacts user's situation awareness (SA) on elements secondary to an AR-assisted main task. These elements can still provide relevant information. A good understanding of user's awareness about them is therefore interesting. 
In this regard, we measured SA about secondary elements in an industrial workshop in the context of an AR-assisted pedestrian navigation. 
We compared SA between three guidance conditions: a paper map, a virtual path, and a virtual path with virtual cues about secondary elements. We adapted an existing SA measure to a real-world environment and found that, in our settings, the use of AR decreased user's SA about secondary elements, mainly at the perception level.",,Session/Server 2,
P1449,Yann Moullec: Univ Rennes; Justine Saint-Aubert: Inria Bretagne-Atlantique; Mélanie Cogne: CHU Pontchaillou; Anatole Lécuyer: Inria,Assisted walking-in-place: Introducing assisted motion to walking-by-cycling in embodied Virtual Reality,"We investigated the use of a motorized bike to support the walk of an avatar in Virtual Reality. Our approach consists in assisting a walking-in-place technique called walking-by-cycling with a motorized bike in order to provide participants with a compelling walking experience while reducing their perceived effort. We conducted a study which showed that ""assisted walking-by-cycling"" induced more ownership, agency, and walking sensation than a static simulation. It also induced levels of ownership and walking sensation similar to that of active walking-by-cycling, but it induced less perceived effort, which promotes the use of our approach in situations where users cannot or do not want to exert much effort while walking in embodied VR.",,Session/Server 2,
P1452,Wai Tong: The Hong Kong University of Science and Technology; Meng Xia: Carnegie Mellon University; Kam Kwai Wong: The Hong Kong University of Science and Technology; Doug Bowman: Virginia Tech; Ting-Chuen Pong: Hong Kong University of Science and Technology; Huamin Qu: The Hong Kong University of Science and Technology; Yalong Yang: Virginia Tech,Towards an Understanding of Distributed Asymmetric Collaborative Visualization on Problem-solving,"With the ability to access various computing devices, such as Virtual Reality (VR) head-mounted displays, we aimed to provide an understanding of user experience in using collaborative visualization in a distributed asymmetric setting (i.e., PC-VR in different locations). To inform designs, we first conducted a formative study with 12 pairs of participants. We then improved our asymmetric design based on the key findings from the first study. Ten pairs of participants experienced enhanced PC-VR and PC-PC conditions in a follow-up study. We found that a well-designed asymmetric collaboration system could be as effective as a symmetric system. Participants who used the PC perceived less mental demand and effort in the PC-VR than in the PC-PC.",,Session/Server 2,
P1480,James F Mullen Jr: University of Maryland; Dinesh Manocha: University of Maryland ,PACE: Data-Driven Virtual Agent Interaction in Dense and Cluttered Environments,"We present PACE, a novel method for modifying motion-captured virtual agents to interact with and move throughout dense, cluttered 3D scenes. Our approach changes a given motion sequence of a virtual agent as needed to adjust to the obstacles and objects in the environment. We compare our method with prior motion generating techniques and highlight the benefits of our method with a perceptual study, where human raters preferred our method, and physical plausibility metrics, where our method performed. We have integrated our system with Microsoft HoloLens and demonstrate its benefits in real-world scenes. Our project website is available at https://gamma.umd.edu/pace/.",,Session/Server 3,
P1483,"Franziska Westermeier: Human-Computer Interaction Group, University of Würzburg; Larissa Brübach: University of Würzburg; Marc Erich Latoschik: University of Würzburg; Carolin Wienrich: University of Würzburg",Exploring Plausibility and Presence in Mixed Reality Experiences,"Our study investigates the impact of incongruencies on different information processing layers (i.e., sensation/perception and cognition layer) in Mixed Reality (MR), and its effects on plausibility, spatial and overall presence. In a simulated maintenance application participants performed operations in a randomized 2x2 design, experiencing either VR (congruent sensation/perception) or AR (incongruent sensation/perception). By inducing cognitive incongruence through the absence of traceable power outages, we aimed to explore the relationship between perceived cause and effect. Our results indicate that the effects of the power outages differ significantly in the perceived plausibility and spatial presence ratings between VR and AR.",,Session/Server 3,
P1491,"Martin Feick: DFKI, Saarland Informatics Campus; Kora Persephone Regitz: Saarland Informatics Campus; Anthony Tang: Singapore Management University; Tobias Jungbluth: DFKI, Saarland Informatics Campus; Maurice Rekrut: DFKI, Saarland Informatics Campus; Antonio Krüger: DFKI, Saarland Informatics Campus",Investigating Noticeable Hand Redirection in Virtual Reality using Physiological and Interaction Data,"Hand redirection is effective so long as the introduced offsets are not noticeably disruptive to users. We investigate the use of physiological and interaction data to detect movement discrepancies between a user's real and virtual hand. We ran a study with 22 participants, collecting EEG, ECG, EDA, RSP, and interaction data. Our results suggest that EEG and interaction data can be used to detect visuo-motor discrepancies, whereas ECG and RSP seem to suffer from inconsistencies. Our findings show that participants quickly adapt to large discrepancies, and suggest that there is no absolute threshold for possible non-detectable discrepancies.",,Session/Server 3,
P1492,Alexander Haley: University of Minnesota; Don Thorpe: University of Minnesota; Alex Pelletier: University of Minnesota; Svetlana Yarosh: University of Minnesota; Daniel F. Keefe: University of Minnesota,Inward VR: Toward a Qualitative Method for Investigating Interoceptive Awareness in VR,"VR can produce powerful illusions of being in another place or inhabiting another body, and theories of presence and embodiment provide valuable guidance to VR designers. However, VR can also be used to develop an awareness of one’s own body (i.e., interoceptive awareness); here, design guidelines and evaluative techniques are less clear. To address this, we present a qualitative methodology, including a reusable codebook, for adapting the Multidimensional Assessment of Interoceptive Awareness conceptual framework to explore interoceptive awareness in VR. We report results from an exploratory study (n=21) applying this method to understand the interoceptive awareness experiences of VR users.",,Session/Server 3,
P1502,Gang Li: University of Glasgow; Katharina Margareta Theresa Pöhlmann: University of Glasgow; Mark McGill: University of Glasgow; Chao Ping Chen: Shanghai Jiao Tong University; Stephen Anthony Brewster: University of Glasgow; Frank Pollick: University of Glasgow,Exploring Neural Biomarkers in Young Adults Resistant to VR Motion Sickness: A Pilot Study of EEG ,"VR motion sickness (VRMS) is seriously hampering the adoption of VR-based livelihood services, like VR healthcare and education. Based on existing datasets from a previous study, this paper investigated the differences in brainwaves between young adults who are relatively resistant and susceptible to VRMS. We found enhanced theta activity in the left parietal cortex in VRMS-resistant individuals (N=10) compared to VRMS-susceptible individuals (N=10). This finding offers new hypotheses regarding how to reduce VRMS by the enhancement of brain functions per se (e.g., via non-invasive transcranial electrostimulation techniques) without the need to redesign the existing VR content.",,Session/Server 3,
P1503,Xue Teng: York University; Robert Allison: York University; Laurie M Wilcox: York University,Manipulation of Motion Parallax Gain Distorts Perceived Distance and Object Depth in Virtual Reality,"Virtual reality (VR) is distinguished by the rich, multimodal, immersive sensory information and affordances provided to the user. However, when moving about an immersive virtual world the visual display often conflicts with other sensory cues due to design, the nature of the simulation, or to system limitations (for example impoverished vestibular motion cues during acceleration in racing games). Given that conflicts between sensory cues have been associated with disorientation or discomfort, and theoretically could distort spatial perception, it is important that we understand how and when they are manifested in the user experience.",,Session/Server 3,
P1504,Roshan Venkatakrishnan: Clemson University; Rohith Venkatakrishnan: Clemson University; Balagopal Raveendranath: Clemson University; Christopher Pagano: Clemson University; Andrew Robb: Clemson University; Wen-Chieh Lin: National Yang Ming Chiao Tung University; Sabarish V. Babu: Clemson University,Give Me a Hand: Improving the Effectiveness of Near-field Augmented Reality Interactions By Avatarizing Users' End Effectors,"We investigated whether avatarizing users' end-effectors (hands) improved their interaction performance on a near-field, obstacle avoidance, object retrieval task. We employed a 3 (Augmented hand representation) X 2 (density of obstacles) X 2 (size of obstacles) X 2 (virtual light intensity) multi-factorial design, manipulating the presence/absence and anthropomorphic fidelity of augmented self-avatars, across three experimental conditions: (1) No-Augmented Avatar; (2) Iconic-Augmented Avatar; (3) Realistic Augmented Avatar. Our findings seem to indicate that interaction performance may improve when users are provided with a visual representation of the AR system's interacting layer in the form of an augmented self-avatar.",,Session/Server 3,
P1505,Roshan Venkatakrishnan: Clemson University; Rohith Venkatakrishnan: Clemson University; Balagopal Raveendranath: Clemson University; Christopher Pagano: Clemson University; Andrew Robb: Clemson University; Wen-Chieh Lin: National Yang Ming Chiao Tung University; Sabarish V. Babu: Clemson University,How Virtual Hand Representations Affect the Perceptions of Dynamic Affordances in Virtual Reality,"We investigated how different virtual hand representations affect users’ perceptions of dynamic affordances using a collision-avoidance object retrieval task. We employed a 3 (virtual end-effector representation) X 13 (frequency of moving doors) X 2 (target object size) multi-factorial design, manipulating the input modality and its concomitant virtual end-effector representation across three experimental conditions: (1) Controller ; (2) Controller-hand ; (3) Glove. We find that representing the end-effector as hands tends to increase embodiment but can also come at the cost of performance, or an increased workload due to a discordant mapping between the virtual representation and the input modality used.",,Session/Server 3,
P1511,Hyungki Son: ETRI; Haokun Wang: University of Texas at Dallas; Yatharth Singhal: University of Texas at Dallas; Jin Ryong Kim: The University of Texas at Dallas,Upper Body Thermal Referral and Tactile Masking for Localized Feedback,This paper investigates the effects of thermal referral and tactile masking illusions to achieve localized thermal feedback. The first experiment uses sixteen vibrotactile actuators with four thermal actuators to explore the thermal distribution on the user's back. The result confirms that localized thermal feedback can be achieved through cross-modal thermo-tactile interaction on the user's back of the body. The second experiment is conducted to validate our approach in VR. The results show that our thermal referral with a tactile masking approach with a lesser number of thermal actuators achieves greater response time and better location accuracy.,,Session/Server 3,
P1519,Atsushi Ishihara: Sony Group Corporation; Hiroyuki Aga: Sony Group Corporation; Yasuko Ishihara: Sony Group Corporation; Hirotake Ichikawa: Sony Group Corporation; Hidetaka Kaji: Sony Group Corporation; Koichi Kawasaki: Sony Group Corporation; Daita Kobayashi: Sony Group Corporation; Toshimi Kobayashi: Sony Group Corporation; Ken Nishida: Sony Group Corporation; Takumi Hamasaki: Sony Group Corporation; Hideto Mori: Sony Group Corporation; Yuki Morikubo: Sony Group Corporation,Integrating Both Parallax and Latency Compensation into Video See-through Head-mounted Display,"This study incorporates both parallax and latency compensation methods into a video see-through head-mounted display, to realize edge-preserving occlusion. To reconstruct captured images, we reproject the images captured by the color camera to the user’s eye position, using depth maps. 
We fill the disocclusion areas using cached depth maps estimated in previous frames, instead of relying upon computationally heavy inpainting procedures. For occlusion, we refine the edges of the depth maps using both infrared masks and color-guided filters. For latency compensation, we propose a two-phase temporal warping method. It is found to be not only fast but also spatially correct for static scenes.",,Session/Server 3,
P1523,Yiming Ren: Shanghaitech; Chengfeng Zhao: Shanghaitech; Yannan He: Shanghaitech; Peishan Cong: Shanghaitech; Han Liang: Shanghaitech; Jingyi Yu: ShanghaiTech University; Lan XU: ShanghaiTech University; Yuexin Ma: ShanghaiTech University,LiDAR-aid Inertial Poser: Large-scale Human Motion Capture by Sparse Inertial and LiDAR Sensors,"We propose a multi-sensor fusion method for capturing challenging 3D human motions with accurate consecutive local poses and global trajectories in large-scale scenarios, only using single LiDAR and 4 IMUs, which are set up conveniently and worn lightly. Moreover, we collect a LiDAR-IMU multi-modal mocap dataset, LIPD, with diverse human actions in long-range scenarios. Extensive quantitative and qualitative experiments on LIPD and other open datasets all demonstrate the capability of our approach for compelling motion capture in large-scale scenarios, which outperforms other methods by an obvious margin. We will release our code and captured dataset to stimulate future research.",,Session/Server 3,
P1525,Yu Zhao: Vanderbilt University; Jeanine Stefanucci: University of Utah; Sarah Creem-Regehr: University of Utah; Bobby Bodenheimer: Vanderbilt University,Evaluating Augmented Reality Landmark Cues and Frame of Reference Displays with Virtual Reality,"Head-mounted augmented reality (AR) displays provide a preview of future navigation systems across various application domains for walking travel, such as search and rescue or commuting, but designing them is still an open problem. Here, we investigate two options for navigation that such AR systems can make: 1) whether to use AR cues to indicate landmarks; 2) how to convey navigation instructions and the effects on spatial knowledge acquisition. We found that the world-fixed frame of reference resulted in better spatial learning when there were no landmarks cued; adding AR landmark cues marginally improved spatial learning in the screen-fixed condition. Our findings have implications for future cognition-driven navigation systems design.",,Session/Server 3,
P1550,Marc Bastian Rieger: RPTU Kaiserslautern-Landau; Björn Risch: RPTU Kaiserslautern-Landau,How to Maximise Spatial Presence: Design Guidelines for a Virtual Learning Environment for School Use,"Research on learning with and in immersive virtual reality (VR) continues to grow, yielding more insights into how immersive learning works. A major hurdle that hinders the use of immersive digital media in schools is the lack of guidelines for designing VR learning environments for practical use in schools. Using a design-based research approach, we explored the guidelines for creating VR learning content for tenth-grade students in a German secondary school and recreated a real-world, out-of-school VR learning space which can be used for hands-on instruction. This presentation investigated how to maximise the experience of spatial presence by creating a VR learning environment in several microcycles.",,Session/Server 3,
P1562,Giorgos Ganias: National and Kapodistrian University of Athens; Christos Lougiakis: National and Kapodistrian University of Athens; Akrivi Katifori: University of Athens; Maria Roussou: National and Kapodistrian University of Athens; Yannis Ioannidis: University of Athens and Athena Research Center; Ioannis Panagiotis Ioannidis: National and Kapodistrian University of Athens,Comparing Different Grasping Visualizations for Object Manipulation in VR using Controllers,"Visualizing grasping when users interact with virtual objects using handheld controllers in VR is underexplored. We present an experiment with 38 participants, comparing three different grasping visualizations: the Auto-Pose, where the hand is automatically adjusted to the object upon grasping; the Simple-Pose, where the hand closes fully when selecting the object; and the Disappearing-Hand, where the hand becomes invisible after selecting an object, and turns visible after positioning it on the target. Μeasuring the effect on user performance, embodiment and preference showed that the perceived sense of embodiment is stronger with the Auto-Pose, and is generally preferred by the users.",,Session/Server 3,
P1563,Huayuan Tian: University of south Australia; Gun A. Lee: University of South Australia; Huidong Bai: The University of Auckland; Mark Billinghurst: University of South Australia,Using Virtual Replicas to Improve Mixed Reality Remote Collaboration,"In this paper, we explore how virtual replicas can enhance MR remote collaboration with a 3D reconstruction of the task space and study how they can work as a spatial cue to improve MR remote collaboration. Our approach segments the foreground manipulable objects in the local environment and creates virtual replicas of them. The remote user can manipulate them to explain the task and guide the partner who can rapidly and accurately understand the remote expert's intentions and instructions. Our user study found using virtual replica manipulation was more efficient than using 3D annotation drawing in the MR remote collaboration. We report and discuss the findings and limitations of our system and study, and directions for future research.",,Session/Server 3,
P1571,"Mohamed Benmahdjoub: Erasmus MC; Abdullah Thabit: Erasmus MC; Marie-Lise C. van Veelen: Erasmus MC; Wiro J. Niessen: Erasmus MC; Eppo B. Wolvius: Erasmus MC, University Medical Centre; Theo van Walsum: Erasmus MC",Evaluation of AR visualization approaches for catheter insertion into the ventricle cavity,"The way how virtual data is presented in AR guided surgical navigation plays an important role for correct spatial perception of the virtual overlay. This study compares various visualization modalities for catheter insertion in external ventricular drain and ventricular shunt procedures. We investigate (1) 2D approaches (smartphone, 2D window), and (2) 3D approaches (fully aligned patient model, and a model that is adjacent to the patient and is rotationally aligned) using an OST. 32 participants performed 20 AR guided insertions per approach. The results show more accurate insertions using 3D approaches with a higher preference compared to 2D approaches.",,Session/Server 3,
P1590,Colin Groth: TU Braunschweig; Sascha Fricke: TU Braunschweig; Susana Castillo: TU Braunschweig; Marcus Magnor: TU Braunschweig,Wavelet-Based Fast Decoding of 360° Videos,"In this paper, we propose a wavelet-based video codec that enables real-time playback of high-resolution 360° videos. Our codec streams the relevant content directly from the drive and decodes the video viewport-dependently. Due to the specific design and the exploitation of the wavelet transform for intra- and inter-frame transform, our codec's decoding performance is up to 272% faster than state-of-the-art video codecs. Finally, we demonstrate how our wavelet-based codec can also directly be used in conjunction with foveation for further performance increases.",,Session/Server 3,
P1591,Brian Pugh: Geomagical Labs; Davin Chernak: Geomagical Labs; Salma Jiddi: Geomagical Labs,GeoSynth: A Photorealistic Synthetic Indoor Dataset for Scene Understanding,"Deep learning has revolutionized many scene perception tasks over the past decade. Some of these improvements can be attributed to the development of large labeled datasets. The creation of such datasets can be an expensive, time-consuming, and imperfect process. To address these issues, we introduce GeoSynth, a diverse photorealistic synthetic dataset for indoor scene understanding tasks. Each GeoSynth exemplar contains rich labels including segmentation, geometry, camera parameters, surface material, lighting, and more. We demonstrate that supplementing real training data with GeoSynth can significantly improve network performance on perception tasks, like semantic segmentation.",,Session/Server 3,
P1607,"Yiwei Bao: State Key Laboratory of VR Technology and Systems, School of Computer Science and Engineering; Jiaxi Wang: Beihang University; Zhimin Wang: Beihang University; Feng Lu: Beihang University",Exploring 3D Interaction with Gaze Guidance in Augmented Reality,"To explore the potential of hand-eye coordination techniques in AR, we investigate whether gaze could help object selection and translation with 3D occlusions. Therefore, we develop new methods with proper gaze guidance for 3D interaction in AR, and also an implicit online calibration method. The user study we conducted shows that our methods not only improve the effectiveness of occluded objects selection but also alleviate the arm fatigue problem significantly in the depth translation task. To reduce the burden of gaze calibration, we also propose an implicit online calibration method, which achieves better accuracy than standard 9 points calibration without interfering with the users.",,Session/Server 3,
P1610,Ayush Bhargava: Clemson University; Rohith Venkatakrishnan: Clemson University; Roshan Venkatakrishnan: Clemson University; Kathryn Lucaites: Clemson University; Hannah Solini: Clemson University; Andrew Robb: Clemson University; Christopher Pagano: Clemson University; Sabarish V. Babu: Clemson University,Can I Squeeze Through? Effects of Self-Avatars and Calibration in a Person-Plus-Virtual-Object System on Perceived Lateral Passability in VR,"Self-avatars and virtual object interactions give rise to affordance based challenges as dynamic surface information like compression and stickiness is absent in VR. This effect is amplified when interacting with virtual objects as the weight and inertial feedback associated with them is often mismatched. As such, we investigated how the absence of dynamic surface properties affect lateral passability judgments with virtual handheld objects in the presence or absence of self-avatars. Results show that participants can account for the missing dynamic information with self-avatars, but rely on their internal body schema of a compressed body depth in the absence of self-avatars.",,Session/Server 3,
P1612,Ayush Bhargava: Clemson University; Roshan Venkatakrishnan: Clemson University; Rohith Venkatakrishnan: Clemson University; Hannah Solini: Clemson University; Kathryn Lucaites: Clemson University; Andrew Robb: Clemson University; Christopher Pagano: Clemson University; Sabarish V. Babu: Clemson University,Empirically Evaluating the Effects of Eye Height and Self-Avatars on Dynamic Passability Affordances in Virtual Reality,"Self-avatars have been shown to affect the perception of oneself and environmental spatial properties. However, most virtual experiences have a generic self-avatar that does not fit the proportions of the users’ body. This can negatively affect affordance judgments relative to the size of the user like reachability and maneuverability. This is prevalent when the task requires the user to maneuver around moving objects in games. Therefore, it is necessary to understand how different sized self-avatars affect affordances judgments in dynamic virtual environments. As such, we investigated how a shorter, taller or matched self-avatar affects judgments when passing through dynamic gaps.",,Session/Server 3,
P1630,Florian Kern: University of Würzburg; Florian Niebling: Hochschule Fulda; Marc Erich Latoschik: University of Würzburg,Text Input for Non-Stationary XR Workspaces: Investigating Tap and Word-Gesture Keyboards in Virtual and Augmented Reality,"We evaluated two text input techniques for non-stationary virtual reality (VR) and video see-through augmented reality (VST AR) XR displays. Our study with 64 participants showed that XR displays and input techniques have a strong impact on text entry performance. We found that tap keyboards had higher usability, better user experience, and lower task load compared to swipe keyboards in VR and VST AR. Both input techniques were faster in VR than in VST AR, and the tap keyboard was the fastest in VR. Participants showed a significant learning effect. Our reference implementation is publicly available for replication and reuse.",,Session/Server 3,
P1646,Yanan Liu: Yunnan university; Hao Zhang: Yunnan university; Yanqiu Li: Yunnan University; Kangjian He: Yunnan university; Dan Xu: Yunnan university,Skeleton-based Human Action Recognition via Large-kernel Attention Graph Convolutional Network ,"The skeleton-based human action recognition has broad application prospects in the field of virtual reality. Notably, recent works learns the spatio-temporal pattern via graph convolution operators. Still, the stacked graph convolution plays a marginal role in modeling long-range dependences. In this work, we introduce a skeleton large kernel attention operator (SLKA), which can enlarge the receptive field and improve channel adaptability without increasing too much computational burden. Further, we have designed a novel  recognition network architecture called the spatiotemporal large-kernel attention graph convolution network (LKA-GCN).  Ultimately, on three action datasets, our LKA-GCN has achieved a state-of-the-art level.",,Session/Server 3,
P1647,Qilei Sun: Xi'an Jiaotong Liverpool University; Jiayou Huang: Xi'an Jiaotong-Liverpool University; Haodong Zhang: Xi'an Jiaotong-Liverpool University; Paul Craig: Xian Jiaotong Liverpool University; Lingyun Yu: Xi'an Jiaotong-Liverpool University; Eng Gee LIM: Xian jiaotong-Liverpool University ,Design and Development of a Mixed Reality Acupuncture Training System,"This paper examines the use of mixed reality in enhancing Chinese acupuncture practice through a virtual acupuncture training simulator. The simulator was developed for the study which allows practitioners to practice needling with virtual acupuncture content using bare hands. The system provides a safe and natural environment for the development of acupuncture skills, muscle memory, and memory of acupuncture points. The study also presents the results of a comparative user evaluation assessing the system's viability as a training tool, revealing improved spatial understanding, learning and dexterity in acupuncture practice. The results demonstrate the potential of mixed reality for improving therapeutic medicine.",,Session/Server 3,
P1648,"Fabian Unruh: HCI Group; David H.V. Vogel: Cognitive Neuroscience (INM-3), Research Center Juelich; Maximilian Landeck: University of Würzburg; Jean-Luc Lugrin: Department of Computer Science, HCI Group; Marc Erich Latoschik: Department of Computer Science, HCI Group",Body and Time: Virtual Embodiment and its effect on Time Perception,"This article explores the relation between one’s own body and the perception of time in a novel Virtual Reality (VR) experiment explicitly fostering user activity. Forty-Eight participants randomly experienced different degrees of embodiment: i) without an avatar (low), ii) with hands (medium), and iii) with a high-quality avatar (high). Participants had to repeatedly activate a virtual lamp and estimate the duration of time intervals as well as judge the passage of time. Our results show a significant effect of embodiment on time perception: time passes slower in the low embodiment condition compared to the medium and high conditions.",,Session/Server 3,
P1652,Xinchi Xu: Nanjing University; Yang Zhou: Nanjing University; Bingchan Shao: Nanjing University; Guihuan Feng: Nanjing University; Chun Yu: Tsinghua University,GestureSurface: VR Sketching through Assembling Scaffold Surface with Non-Dominant Hand,"3D sketching provides an immersive drawing experience for designs. However, the lack of depth perception cues in VR makes it difficult to draw accurate strokes. To handle this, we introduce gesture-based scaffolding to guide strokes. We conduct a gesture-design study and propose GestureSurface, a bi-manual interface that uses non-dominant hand performing gestures to create scaffolding and the other hand drawing with controller. When the dominant hand is occupied, reducing the idleness of the non-dominant hand thourgh gestural input increases efficiency and fluency. We evaluated GestureSurface using a 20-person user study that found it had high efficiency and low fatigue.",,Session/Server 3,
P1655,Ou Li: Hangzhou Normal University; Han Qiu: Hangzhou Normal University,"Virtual reality in supporting charitable giving: The role of vicarious experience, existential guilt, and need for stimulation","Although a growing number of charities have used virtual reality (VR) for fundraising activities, there is relatively little academic research in this area. The purpose of this study is to investigate the underlying mechanism of VR in supporting charitable giving. We found that VR charitable appeals increase actual money donations when compared to the traditional two-dimensional (2D) format and that this effect is achieved through a serial mediating effect of vicarious experience and existential guilt. Findings also identify the need for stimulation as a boundary condition, indicating that those with a higher (vs. lower) need for stimulation were more (vs. less) affected by the mediating mechanism of VR charitable appeals on donations.",,Session/Server 3,
P1667,Yusuke Yamazaki: Tokyo Institute of Technology; Shoichi Hasegawa: Tokyo Institute of Technology,Providing 3D Guidance and Improving the Music-Listening Experience in Virtual Reality Shooting Games Using Musical Vibrotactile Feedback,We aim to improve the experience of virtual reality (VR) shooting games by employing a 3D haptic guidance method using necklace-type and belt-type haptic devices. Such devices help to modulate the vibrations generated by and synchronized with musical signals according to the azimuth and height of a target in 3D space. We evaluated the method's potential by conducting a task that participants were asked to shoot a randomly spawned target moving in 3D VR space. The results suggest the proposed method can guide players toward the target's location using only tactile stimuli. Modulated musical vibrations also enhanced the music-listening experience.,,Session/Server 3,
P1678,Hyunjin Lee: KAIST; Woontack Woo: KAIST ,Exploring the Effects of Augmented Reality Notification Type and Placement in AR HMD while Walking,"Augmented reality helps users easily accept information when walking by providing virtual information in front of their eyes. However, it remains unclear how to present AR notifications considering the expected user reaction to interruption. Therefore, we investigated the appropriate placement methods by dividing notification types into high or low. We found that using a display-fixed coordinate system responded faster for high notification types, whereas using a body-fixed coordinate system resulted in quick walking speed for low ones. Furthermore, the high types had higher notification performance at the bottom position, but the low had enhanced walking performance at the right.",,Session/Server 3,
P1680,David Mal: University of Würzburg; Erik Wolf: University of Würzburg; Nina Döllinger: University of Würzburg; Carolin Wienrich: University of Würzburg; Marc Erich Latoschik: University of Würzburg,"The Impact of Avatar and Environment Congruence on Plausibility, Embodiment, Presence, and the Proteus Effect in Virtual Reality","We investigated the impact of avatar and environment types on VR-related qualia and the Proteus effect. Participants embodied either an avatar in sports- or business wear in a semantic congruent or incongruent environment while performing exercises in virtual reality. The avatar-environment congruence significantly affected the avatar’s plausibility but not the sense of embodiment or spatial presence. A significant Proteus effect emerged only for participants who reported a high feeling of (virtual) body ownership, indicating that a strong sense of having and owning a virtual body is key to facilitating the Proteus effect.",,Session/Server 3,
P1695,Ignatius Alex Wijayanto: National Yang Ming Chiao Tung University; Sabarish V. Babu: Clemson University; Christopher Pagano: Clemson University; Jung-Hong Chuang: National Yang Ming Chiao Tung University,Comparing the Effects of Visual Realism on Size Perception in VR versus Real World Viewing through Physical and Verbal Judgments,"Virtual Reality (VR) is well-known for its use in interdisciplinary applications and research. The visual representation of these applications could vary and in those situations could require an accurate perception of size for task performance. However, the relationship between size perception and visual realism in VR has not yet been explored. In this contribution, we conducted an empirical evaluation using a between-subject design over four conditions of visual realism on size perception of target objects in the same virtual environment. Our result showed participants' size perception was accurate in both realistic and non-photorealistic conditions suggesting that invariant provides meaningful information in the environment.",,Session/Server 3,
P1701,Michael Nitsche: Georgia Institute of Technology; Blaire Bosley: Georgia Institute of Technology; Susan A. Primo: Emory University School of Medicine; Jisu Park: Georgia Institute of Technology; Daniel Carr: Georgia Institute of Technology,Remapping Control in VR for Patients with AMD,"Age-related Macular Degeneration (AMD) is the leading cause of vision loss among persons over 50. We present a two-part interface consisting of a VR-based visualization for AMD patients and an interconnected doctor interface to optimize this VR view. It focuses on remapping imagery to provide customized image optimizations. The system allows doctors to generate a tailored, patient-specific VR visualization. We pilot tested the doctor interface (n=10) with eye care professionals. The results indicate the potential of VR-based eye care for doctors to help visually-impaired patients, but also show a necessary training phase to establish new technologies in vision rehabilitation.",,Session/Server 3,
P1708,Haonan Cheng: Communication University of China; Shiguang Liu: Tianjin University; Jiawan Zhang: Tianjin University,Lightweight Scene-aware Rain Sound Simulation for Interactive Virtual Environments,"This paper proposes a lightweight sound synthesis method for generating scene-aware rain sound at interactive rates while reducing memory requirement. First, an exponential moving average based frequency domain additive synthesis method is designed to extend and modify the pre-computed basic rain sounds. Second, an efficient binaural rendering method is proposed to simulate the 3D perception that coheres with the visual scene based on a set of Near-Field Transfer Functions. Various results demonstrate that the proposed method dramatically improves the performance of rain sound generation synchronized with the visual scene in terms of memory and speed.",,Session/Server 3,
P1729,Danny Schott: Faculty of Computer Science; Matthias Kunz: Clinic for Cardiology and Angiology; Tom Wunderling: Faculty of Computer Science; Florian Heinrich: Human-Computer Interaction (HCI) Group; Rüdiger Braun-Dullaeus: Clinic for Cardiology and Angiology; Christian Hansen: Faculty of Computer Science,CardioGenesis4D: Interactive Morphological Transitions of Embryonic Heart Development in a Virtual Learning Environment,"In the embryonic human heart, complex dynamic shape changes take place in a short period, making this development difficult to visualize. An immersive learning environment is presented that enables the understanding of morphological transitions through hand interactions. In a user study, we examined usability, perceived task load, and sense of presence. We also assessed knowledge gain, and obtained feedback from domain experts. Students and professionals rated the application as usable, and our results show that interactive learning content should consider features for different learning styles. Our work previews, how VR can be integrated into a cardiac embryology education curriculum.",,Session/Server 3,
P1737,Daniel Bambusek: Brno University of Technology; Zdenek Materna: Brno University of Technology; Michal Kapinus: Brno University of Technology; Vitezslav Beran: Brno University of Technology; Pavel Smrž: Brno University of Technology,How Do I Get There? Overcoming Reachability Limitations of Constrained Industrial Environments in Augmented Reality Applications,"The paper presents an approach for handheld AR in constrained industrial environments, where it might be hard or even impossible to reach certain poses within a workspace in order to see or interact with digital content in applications like visual robot programming, robotic program visualizations, or workspace annotation. To overcome this limitation, we propose a temporal switching to a non-immersive VR that allows the user to see the virtual counterpart of the workspace from any angle and distance, where the viewpoint is controlled using a unique combination of on-screen controls complemented by the physical motion of the handheld device.",,Session/Server 3,
P1740,Yuxi Wang: Hangzhou Dianzi University; Haibin Ling: Stony Brook University; Bingyao Huang: Southwest University,CompenHR: Efficient Full Compensation for High-resolution Projector,"Full compensation aiming to find a projector input image for canceling the geometric and photometric distortions is a practical task of projector-camera systems. To address the issue that learning-based compensation methods for high-resolution setups are impractical due to the long training time and high memory cost, this paper proposes a practical full compensation solution. We design an attention-based grid refinement network to improve geometric correction quality and integrate a novel sampling scheme into an end-to-end compensation network to alleviate computation. Furthermore, we construct a benchmark dataset for high-resolution projector full compensation. The experiments demonstrate clear advantages in both efficiency and quality.",,Session/Server 3,
P1746,Yuqi Li: Ningbo University; Qiang Fu: King Abdullah University of Science and Technology; Wolfgang Heidrich: King Abdullah University of Science and Technology,Extended Depth-of-Field Projector using Learned Diffractive Optics,"We jointly design a DOE for light phase modulation and a convolutional neural network for projector compensation. The designed extended depth of field (EDOF) computational projector can achieve high light throughput and real-time performance. We demonstrate that this learned optics compares favorably to baselines with conventional projectors, and the learned compensation network outperforms previous state-of-the-art compensation methods in terms of both computational efficiency and compensation quality. We implement a laboratory prototype of the computational EDOF projector equipped with the learned DOE, and evaluate it with real display experiments on depth-varying and tilted projection surfaces.",,Session/Server 3,
P1757,Zubin Choudhary: University of Central Florida; Nahal Norouzi: University of Central Florida; Austin Erickson: University of Central Florida; Ryan Schubert: University of Central Florida; Gerd Bruder: University of Central Florida; Greg Welch: University of Central Florida,Exploring the Social Influence of Virtual Humans Unintentionally Conveying Conflicting Emotions,"In this paper, we present a human-subjects study aimed at understanding the impact of conflicting facial and vocal emotional expressions. Specifically we explored three levels of emotional valence (unhappy, neutral, and happy) expressed in both visual (facial) and aural (vocal) forms. We also investigate three levels of head scales (down-scaled, accurate, and up-scaled) to evaluate whether head scale affects user interpretation of the conveyed emotion. We find significant effects of different multimodal expressions on happiness and trust perception, while no significant effect was observed for head scales. We discuss the relationships, implications, and guidelines for social applications that aim to leverage multimodal social cues.",,Session/Server 3,
P1761,Ye Pan: Shanghai Jiaotong University ; Ruisi Zhang: UC San Diego; Shengran Cheng: Shanghai Jiaotong University; Shuai Tan: Shanghai Jiao Tong University; Yu Ding: Netease; Kenny Mitchell: Roblox; Xubo Yang: SHANGHAI JIAO TONG UNIVERSITY,Emotional Voice Puppetry,"The paper presents emotional voice puppetry, an audio-based facial animation approach to portray characters with vivid emotional changes. The lips motion and the surrounding facial areas are controlled by the contents of the audio, and the facial dynamics are established by category of the emotion and the intensity. Our approach is exclusive because it takes account of perceptual validity and geometry instead of pure geometric processes. Another highlight of our approach is the generalizability to multiple characters. User studies demonstrate the effectiveness of our approach both qualitatively and quantitatively.",,Session/Server 3,
P1770,Theophilus Teo: Keio University; Kuniharu Sakurada: Keio University; Maki Sugimoto: Keio University,Exploring Enhancements towards Gaze Oriented Parallel Views in Immersive Tasks,"We explore enhancements on a singular or asynchronous task by utilizing parallel views. Three prototypes were developed, comprises of fixed, symmetric and gaze-oriented parallel view. We conducted a user study comparing each prototype, against traditional VR in three tasks: object search and interaction tasks in a 1) simple environment and 2) complex environment, and 3) object distances estimation task. We found parallel views improved multi-embodiment while each technique helped different tasks. Traditional VR provided a clean interface, thus improving spatial presence, mental effort, and user performance. However, participants' feedback highlighted usefulness and a lower physical effort of using parallel views to solve complicated tasks.",,Session/Server 3,
P1777,Tongyu Nie: University of Minnesota; Isayas Berhe Adhanom: University of Minnesota; Evan Suma Rosenberg: University of Minnesota,Like a Rolling Stone: Effects of Space Deformation During Linear Acceleration on Slope Perception and Cybersickness,"The decoupled relationship between the optical and inertial information in VR is commonly acknowledged as a major factor contributing to cybersickness. We noticed that a slope naturally affords acceleration, and the gravito-inertial force we experience when we are accelerating freely on a slope has the same relative direction and approximately the same magnitude as the gravity we experience when standing on the ground. In this paper, we present a novel space deformation technique that deforms the virtual environment to replicate the structure of a slope when the user accelerates virtually to restore the relationship between the optical and inertial information.",,Session/Server 3,
P1792,Ripan Kumar Kundu: University of Missouri; Rifatul Islam: University of Texas at San Antonio; John Quarles: University of Texas at San Antonio; Khaza Anuarul Hoque: University of Missouri,LiteVR: Interpretable and Lightweight Cybersickness Detection using Explainable AI,"Cybersickness is a common ailment associated with virtual reality (VR) user experiences. In recent years, a plethora of research has proposed several automated methods based on machine learning (ML) and deep learning (DL) to detect cybersickness. However, most of these cybersickness detection methods are perceived as computationally intensive and black-box methods. Thus, those techniques are not well understood and impractical for deploying on standalone energy-constrained VR head-mounted devices (HMDs). In this work, we present an explainable artificial intelligence (XAI)-based framework LiteVR for cybersickness detection, explaining the model's outcome and reducing the feature dimensions and overall computational costs.",,Session/Server 3,
P1801,Catarina Gonçalves Fidalgo: Instituto Superior Técnico; Mauricio Sousa: University of Toronto; Daniel Mendes: INESC TEC; Rafael Kuffner dos Anjos: University of Leeds; Daniel Medeiros: University of Glasgow; Karan Singh: University of Toronto; Joaquim Jorge: Universidade de Lisboa,MAGIC: Manipulating Avatars and Gestures to Improve Remote Collaboration,"Remote collaboration in virtual environments has become pervasive in many fields. Within this context, users often collaboratively interact with virtual 3D models. However, discussing shared 3D content face-to-face can be challenging due to ambiguities, occlusions, and different viewpoints. To address this challenge, we introduce MAGIC, a novel approach for understanding pointing gestures in a face-to-face shared 3D space. MAGIC distorts the remote user’s gestures to correctly reflect them in the local user's reference space when face-to-face. Results suggest that MAGIC significantly improves pointing agreement in face-to-face collaboration settings, improving co-presence and awareness of interactions performed in the shared space.",,Session/Server 3,
P1804,Niluthpol Chowdhury Mithun: SRI International; Kshitij Minhas: SRI International; Han-Pang Chiu: SRI International; Taragay Oskiper: SRI International; Mikhail Sizintsev: SRI International; Supun Samarasekera: SRI International; Rakesh Kumar: SRI International,Cross-View Visual Geo-Localization for Outdoor Augmented Reality,"Precise estimation of global orientation and location is critical to ensure a compelling outdoor Augmented Reality (AR) experience. We address the problem by cross-view matching of query ground images to a geo-referenced satellite image database, proposing a transformer neural network model and a modified ranking loss. Experiments on benchmark cross-view geo-localization datasets show that our model achieves state-of-the-art performance. We also present an approach to extend the single image query-based localization approach utilizing temporal information from a navigation pipeline for continuous geo-localization. Experiments on several real-world video sequences demonstrate that our approach enables high-precision and stable AR insertion.",,Session/Server 3,
P1805,Sixuan Wu: University of Toronto; Jiannan Li: University of Toronto; Mauricio Sousa: University of Toronto; Tovi Grossman: University of Toronto,Investigating Guardian Awareness Techniques to Promote Safety in Virtual Reality,"Virtual Reality (VR) can immerse users in a virtual world and provide little awareness of the physical environment. Current VR technologies use predefined guardians to set safety boundaries. However, bystanders cannot perceive these boundaries and may collide with VR users if they enter guardians. We investigate four techniques to help bystanders avoid invading guardians. These techniques include augmented reality overlays and visual, auditory, and haptic alerts indicating bystanders' distance from guardians. Our findings suggest the techniques effectively keep participants clear of the safety boundaries. Using augmented reality overlays, participants could avoid guardians with less time, and haptic alerts caused less distractions.",,Session/Server 3,
P1812,Gareth Rendle: Bauhaus-Universität Weimar; Adrian Kreskowski: Bauhaus-Universität Weimar; Bernd Froehlich: Bauhaus-Universität Weimar,Volumetric Avatar Reconstruction with Spatio-Temporally Offset RGBD Cameras,"RGBD cameras can capture users’ actions for reconstruction of volumetric avatars that allow rich interaction between telepresence parties in VR. This work presents a system design enabling volumetric avatar reconstruction at increased frame rates. We overcome the limited frame rate of commodity RGBD cameras by dividing cameras into two spatio-temporally offset groups and implementing a real-time reconstruction pipeline to fuse the temporally offset RGBD streams. Comparisons against capture configurations possible with the same number of cameras indicate that using spatially and temporally offset RGBD cameras is beneficial, allowing increased reconstruction frame rates and scene coverage while producing temporally consistent avatars.",,Session/Server 3,
P1820,Jacob Young: Victoria University of Wellington; Nadia Pantidi: Victoria University of Wellington; Matthew Wood: Victoria University of Wellington,I Can't See That! Considering the Readability of Small Objects in Virtual Environments,"Interacting with and interpreting small objects in virtual reality has remained an issue, particularly in the replication of real-world tasks. We propose three techniques for improving the usability and readability of small objects: i) expanding them in place, ii) expanding a separate replica, and iii) showing a large readout of the object's state. We conducted a user study comparing each technique's usability, induced presence, and effect on knowledge retention and conclude that scaling the area of interest may not be enough to improve the usability of information-bearing objects, while text readouts can aid task completion while reducing knowledge retention.",,Session/Server 3,
P1821,Samuel Ang: University of Texas San Antonio; Amanda Fernandez: University of Texas at San Antonio; Michael Rushforth: University of Texas at San Antonio; John Quarles: University of Texas at San Antonio,"You Make Me Sick! The Effect of Stairs on Presence, Cybersickness, and Perception of Embodied Conversational Agents","Virtual reality (VR) has many applications involving an embodied conversational agent (ECA). VR remains inaccessible due to cybersickness: a collection of negative symptoms such as nausea and headache. Many factors are believed to affect cybersickness, but little is known regarding how factors may influence user opinion of ECAs. Participants completed a navigation task and conversation with a virtual airport customs agent in Spanish. Participants first traversed either hallways or staircases. We collected ratings of cybersickness, presence, and the ECA along with heart rate and galvanic skin response. Results indicate that staircases increased cybersickness and reduced perceived realism, but increased presence.",,Session/Server 3,
P1826,Rahul Singh: University of Illinois Urbana-Champaign; Muhammad Huzaifa: University of Illinois Urbana-Champaign; Jeffrey Liu: University of Illinois Urbana-Champaign; Anjul Patney: NVIDIA; Hashim Sharif: University of Illinois Urbana-Champaign; Yifan Zhao: University of Illinois Urbana-Champaign; Sarita Adve: University of Illinois Urbana-Champaign,"Power, Performance, and Image Quality Tradeoffs in Foveated Rendering","In this paper, we study the tradeoff between fixed foveated rendering (FFR), gaze-tracked
foveated rendering (TFR), and conventional rendering. We provide the first comprehensive study of their relative feasibility in practical systems with limited battery life and computational budget. We show that TFR with the added cost of the gaze-tracker can often be more expensive than FFR. Thus, we co-design a gaze-tracked foveated renderer. We describe approximations for eye tracking which provide up to 9× speedup in runtime with about 20× improvement in energy efficiency on a mobile GPU. Overall, with our technique TFR is feasible compared to FFR, resulting in up to 1.25× faster frame times while also reducing total energy consumption by over 40%",,Session/Server 3,
P1833,Takato Mizuho: The University of Tokyo; Takuji Narumi: the University of Tokyo; Hideaki Kuzuoka: The University of Tokyo,"Effects of the Visual Fidelity of Virtual Environments on Presence, Context-dependent Forgetting, and Source-monitoring Error","The present study examined two effects caused by alternating VE and RE experiences: ""context-dependent forgetting'' and ""source-monitoring errors.'' The former effect is that memories learned in VEs are more easily recalled in VEs than in REs, and vice versa. The source-monitoring error is that memories learned in VEs and REs are easily confused, making it difficult to identify the source of the memory. We hypothesized that the visual fidelity of VEs is responsible for these effects. We found that the level of visual fidelity significantly affected the sense of presence, but not context-dependent forgetting or source-monitoring errors.",,Session/Server 3,
P1874,Zhenxiao Luo: Sun Yat-sen University; Baili Chai: Sun Yat-sen University; Zelong Wang: Sun Yat-sen University; Miao Hu: Sun Yat-sen University; Di Wu: Sun Yat-sen University,Masked360: Enabling Robust 360-degree Video Streaming with Ultra Low Bandwidth Consumption,"We propose a practical neural-enhanced 360-degree video streaming framework called Masked360, which can significantly reduce bandwidth consumption and achieve robustness against packet loss. In Masked360, instead of transmitting the complete video frame, the video server only transmits a masked low-resolution version of each video frame to reduce bandwidth significantly. Besides, the client can reconstruct the original 360-degree video frames with a lightweight neural network model. To further improve the quality of video streaming, we also propose a set of optimization techniques, such as complexity-based patch selection, quarter masking strategy, redundant patch transmission and enhanced model training methods.",,Session/Server 3,
P1900,Christoph Ebner: Graz University of Technology; Peter Mohr: Graz University of Technology; Tobias Langlotz: University of Otago; Yifan (Evan) Peng: The University of Hong Kong; Dieter Schmalstieg: Graz University of Technology; Gordon Wetzstein: Stanford University; Denis Kalkofen: Graz University of Technology,Off-Axis Layered Displays: Hybrid Direct-View/Near-Eye Mixed Reality with Focus Cues,"This work introduces off-axis layered displays, the first approach to stereoscopic direct-view displays with support for focus cues. Off-axis layered displays combine a head-mounted display with a direct-view display to provide focus cues. We present a pipeline for the real-time rendering of off-axis display patterns to explore the novel display architecture. Additionally, we build two prototypes using a head-mounted display in combination with a stereoscopic, and a monoscopic direct-view display. Furthermore, we show how extending off-axis layered displays with an attenuation layer and with eye-tracking improves image quality. We thoroughly analyze each component and present examples captured through our prototypes.",,Session/Server 3,
P1901,Zimu Yi: Shenzhen University; Ke Xie: Shenzhen University; Jiahui Lyu: Shenzhen University; Minglun Gong: University of Guelph; Hui Huang: Shenzhen University,Where to Render: Studying Renderability for IBR of Large-Scale Scenes,"In this work, we introduce the concept of Renderability, which predicts the quality of image-based rendering (IBR) results at any given viewpoint and view direction. Consequently, the renderability values evaluated for the 5D camera parameter space form a field, which effectively guides viewpoint/trajectory selection for IBR, especially for challenging large-scale 3D scenes.",,Session/Server 3,
P1926,Justine Saint-Aubert: Inria Bretagne-Atlantique; Ferran Argelaguet Sanz: Inria; Claudio Pacchierotti: CNRS; Marc J-M Macé: CNRS / Rennes 1; Amir Amedi: Interdisciplinary Center; Anatole Lécuyer: Inria,"Persuasive Vibrations: Effects of Speech-Based Vibrations on  Persuasion, Leadership, and Co-Presence During Verbal Communication in VR","Our paper aims to investigate how tactile feedback consisting in vibrations synchronized with speech could influence persuasion, co-presence and  leadership in VR. In a first experiment, participants were listening to two speaking virtual agents and the speech of one agent was augmented with vibrotactile feedback. In a second experiment, the participants were talking to two agents, and their own speech was augmented or not with vibrotactile feedback. Interestingly, the results show that vibrotactile feedback improve the co-presence, persuasiveness and leadership of agents when listening to them.  It also improve co-presence, and participants perceive their speech as more persuasive when speaking.",,Session/Server 3,
P1937,"João Guerreiro: Universidade de Lisboa; Yujin Kim: Ewha Womans University; Rodrigo Nogueira: Faculdade de Ciências, Universidade de Lisboa; SeungA Chung: Ewha Womans University; André Rodrigues: Universidade de Lisboa; Uran Oh: Ewha Womans University",The Design Space of the Auditory Representation of Objects and their Behaviours in Virtual Reality for Blind People,"VR is typically designed in terms of visual experience, posing major challenges for blind people to understand and interact with the environment. We propose a design space to augment objects and their behaviours in VR with an audio representation. It intends to support designers in creating accessible experiences by explicitly considering alternatives to visual feedback. We recruited 16 blind users and explored the design space under two scenarios in the context of boxing (defend and attack). This exploration resulted in multiple engaging approaches and depicted shared preferences but no one-size-fits-all solution, suggesting the need to understand the consequences of each design choice and their impact on the individual user experience.",,Session/Server 3,
P1938,Martin Bellgardt: RWTH Aachen University; Sebastian Pape: RWTH; David Gilbert: RWTH Aachen; Marcel Prochnau: RWTH Aachen University; Georg König: RWTH Aachen; Torsten Wolfgang Kuhlen: RWTH Aachen University,Virtual Optical Bench: Teaching Spherical Lens Layout in VR with Real-Time Ray Tracing,"We present the virtual optical bench, an application that lets users explore spherical lens layouts in virtual reality (VR). We implemented a numerically accurate simulation of optical systems using Nvidia OptiX, as well as a prototypical VR application, which we then evaluated in an expert review with 6 optics experts. Based on their feedback, we re-implemented our VR application in Unreal Engine 4. The re-implementation has since been actively used for teaching optical layouts, where we performed a qualitative evaluation with 18 students. We show that our virtual optical bench achieves good usability and is perceived to enhance the understanding of course contents.",,Session/Server 3,
P1951,Cheng-Wei Fan: Tsinghua University; Sen-Zhe Xu: Tsinghua University; Peng Yu: Tsinghua University; Fang-Lue Zhang: Victoria University of Wellingtong; Song-Hai Zhang: Tsinghua University,Redirected Walking Based on Historical User Walking Data,"This paper proposes a novel Redirected Walking (RDW) method that improves the effect of real-time unrestricted RDW by analyzing and utilizing the user's historical walking data. Using the weighted directed graph obtained from the user's historical walking data, we update the scores of different reachable poses and guide the user to the optimal target pose. Since simulation experiments have been shown to be effective in many previous RDW studies, we also provide a method to simulate user walking trajectories and generate a dataset. Experiments show that our method outperforms multiple state-of-the-art methods in various environment layouts.",,Session/Server 3,
P1978,Jan Niklas Hombeck: University of Jena; Henrik Voigt: Friedrich-Schiller-University; Timo Heggemann: Universitätskrankenhaus Köln; Rabi R. Datta: University Hospital Cologne; Kai Lawonn: University of Jena,Tell Me Where To Go: Voice Controlled Hands-Free Locomotion for Virtual Reality Systems,"As locomotion is an important factor in improving Virtual Reality (VR) immersion and usability, research in this area has been and continues to be a crucial aspect for the success of VR applications. In recent years, a variety of techniques have been developed and evaluated, ranging from abstract control, vehicle, and teleportation techniques to more realistic techniques such as motion, gestures, and gaze. However, when it comes to hands-free scenarios, for example to increase the overall accessibility of an application or in medical scenarios under sterile conditions, most of the announced techniques cannot be applied. This is where the use of speech as an intuitive means of navigation comes in handy.",,Session/Server 3,
P1982,Alissa Vermast: Utrecht University; Wolfgang Hürst: Utrecht University,Introducing 3D Thumbnails to Access 360-Degree Videos in Virtual Reality,"Interfaces to access datasets of 360-degree videos in VR almost always use 2D thumbnails to represent them, even though the data is inherently three-dimensional. In a comparative study, we verified if using spherical and cube-shaped 3D thumbnails provides a better user experience and is more effective at conveying the high-level subject matter of a video or when searching for a specific item in it. Results show that traditional 2D equirectangular projections still performed better for high-level classification tasks but were outperformed by spherical thumbnails when participants had to search for details within the videos.",,Session/Server 3,
P1987,"Soroosh Mortezapoor: Institute of Visual Computing and Human-Centered Technology, TU Wien; Khrystyna Vasylevska: Institute of Visual Computing and Human-Centered Technology, TU Wien; Emanuel Vonach: Institute of Visual Computing and Human-Centered Technology, TU Wien; Hannes Kaufmann: Institute of Visual Computing and Human-Centered Technology, TU Wien",CoboDeck: A Large-Scale Haptic VR System Using a Collaborative Mobile Robot,"We present CoboDeck - our proof-of-concept immersive virtual reality haptic system with free walking support. It provides prop-based encounter-type haptic feedback with a mobile robotic platform. Intended for use as a design tool for architects, it enables the user to directly and intuitively interact with virtual objects like walls, doors, or furniture. A collaborative robotic arm mounted on an omnidirectional mobile platform can present a physical prop that matches the position and orientation of a virtual counterpart anywhere in large virtual and real environments. Thus, the user can naturally interact with a virtual object with bare hands or any body part and simultaneously encounter it in real physical space.",,Session/Server 3,
P2008,"Catarina Gonçalves Fidalgo: Carnegie Mellon University; Yukang Yan: CMU; Hyunsung Cho: Carnegie Mellon University; Mauricio Sousa: University of Toronto; David Lindlbauer: Carnegie Mellon University; Joaquim Jorge: Instituto Superior Técnico, Universidade de Lisboa",A survey on remote assistance and training in Mixed Reality environments,"The recent pandemic, war, and oil crises have caused many to reconsider their need to travel for education, training, and meetings. Mixed Reality offers opportunities to improve remote assistance and training, as it opens the way to increased spatial clarity and large interaction space. We contribute a survey of remote assistance and training in MR environments through a systematic literature review to provide a deeper understanding of current approaches, benefits and challenges. We analyze 62 articles and contextualize our findings into a taxonomy,  identifying the main gaps and opportunities in this research area.",,Session/Server 3,
P2014,Jingying Wang: Shanghai Jiao Tong University; Yilin Qiu: Shanghai Jiao Tong University; Keyu Chen: University of Science and Technology  of China; Yu Ding: Netease; Ye Pan: Shanghai Jiaotong University ,Fully Automatic Blendshapes Generation for Stylized Characters,"We adopt the essence of deep learning and feature transfer to realize deformation transfer, thereby generating blendshapes for target avatars based on the given sources. We proposed a Variational Autoencoder (VAE) to extract the latent space of the avatars and then use a Multilayer Perceptron (MLP) model to realize the translation between the latent spaces of the source avatar and target avatars. By decoding the latent code of different blendshapes, we can obtain the blendshapes for the target avatars with the same semantics as that of the source. We also demonstrated that our method can be applied to identity and expression transfer for stylized characters with different topologies.",,Session/Server 3,
P2020,Alberto Cannavò: Politecnico di Torino; Filippo Gabriele Pratticò: Politecnico di Torino; Alberto Bruno: Politecnico di Torino; Fabrizio Lamberti: Politecnico di Torino,AR-MoCap: Using Augmented Reality to Support Motion Capture Acting,"This paper aims to demonstrate how Augmented Reality (AR) can be helpful for actors when shooting mocap scenes. To this purpose, we devised a system named AR-MoCap that can be used by actors for rehearsing the scene in AR on the real set before actually shooting it. Through an Optical See-Through Head-Mounted Display, an actor can see, e.g., the digital characters of other actors wearing mocap suits overlapped in realtime to their bodies. Experimental results showed that, compared to the traditional approach based on physical props and other cues, the devised system can help the actors to position themselves and direct their gaze while shooting the scene, while also improving spatial and social presence, as well as perceived effectiveness.",,Session/Server 3,
P2104,Xin Yi: Tsinghua University; Xueyang Wang: Tsinghua University; Jiaqi Li: Tsinghua University; Hewu Li: Tsinghua University,Examining the Fine Motor Control Ability of Linear Hand Movement in Virtual Reality,"We conducted three user studies to progressively examine users' ability of fine motor control in 3D linear hand movement tasks. In Study 1, we examined participants' behavioural patterns when drawing straight lines using both the controller and the hand. Results showed that the exhibited stroke length tended to be longer than perceived. In Study 2, we further tested the effect of different visual references and found that providing only a virtual table yielded higher input precision and user preference. In Study 3, we repeated Study 2 in real dragging and scaling tasks and verified the generalizability of the above findings.",,Session/Server 3,
