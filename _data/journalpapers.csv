id,Title,Contact Name,Contact Email,abstract,authors,url
1425,ConeSpeech: Exploring Directional Speech Interaction for Multi-Person Remote Communication in Virtual Reality,"Yan, Yukang",yanyukanglwy@gmail.com,"We present ConeSpeech, a virtual reality (VR) based multi-user remote communication technique, which enables users to selectively speak to target listeners without distracting bystanders. With ConeSpeech, the user looks at the target listener and only in a cone-shaped area in the direction can the listeners hear the speech. We conducted a user study to determine the modality to control the cone-shaped delivery area. Then we implemented the technique and evaluated its performance in three typical multi-user communication tasks by comparing it to two baseline methods. Results show that ConeSpeech balanced the convenience and flexibility of voice communication.","Yukang Yan: Department of Computer Science and Technology, Tsinghua University, Beijing, China HCII, CMU, Pittsburgh, Pennsylvania, United States; Haohua Liu: Cornell Tech, Cornell University, New York City, New York, United States, hl766@cornell.edu; Yingtian Shi: Department of Computer Science and Technology, Tsinghua University, Beijing, China; Jingying Wang: University of Michigan, Ann Arbor, Michigan, United States; Ruici Guo: International School, Beijing University of Post and Telecommunication, Beijing, China; Zisu Li: IIP (Computational Media and Arts), The Hong Kong University of Science and Technology, Hong Kong SAR, Hong Kong, China, zlihe@connect.ust.hk; Xuhai Xu: Information School, University of Washington, Seattle, Washington, United States; Chun Yu: Department of Computer science and Technology, Tsinghua University, Beijing, China; Yuntao Wang: Department of Computer Science and Technology, Tsinghua University, Beijing, China; Yuanchun Shi: Department of Computer science and Technology, Tsinghua University, Beijing, China",
1937,The Design Space of the Auditory Representation of Objects and their Behaviours in Virtual Reality for Blind People,"Guerreiro, João",jpguerreiro@fc.ul.pt,"VR is typically designed in terms of visual experience, posing major challenges for blind people to understand and interact with the environment. We propose a design space to augment objects and their behaviours in VR with an audio representation. It intends to support designers in creating accessible experiences by explicitly considering alternatives to visual feedback. We recruited 16 blind users and explored the design space under two scenarios in the context of boxing (defend and attack). This exploration resulted in multiple engaging approaches and depicted shared preferences but no one-size-fits-all solution, suggesting the need to understand the consequences of each design choice and their impact on the individual user experience.","João Guerreiro: LASIGE, Faculdade de Ciências, Universidade de Lisboa, Lisbon, Portugal;Yujin Kim: Ewha Womans University, Seoul, Korea, Republic of;Rodrigo Nogueira: LASIGE, Faculdade de Ciências, Universidade de Lisboa, Lisboa, Portugal;SeungA Chung: Computer Science and Engineering, Ewha Womans University, Seoul, Korea, Republic of;André Rodrigues: LASIGE, Universidade de Lisboa, Lisboa, Portugal;Uran Oh: Computer Science and Engineering, Ewha Womans University, Seoul, Korea, Republic of;",
1761,Emotional Voice Puppetry,"Pan, Ye",whitneypanye@sjtu.edu.cn,"The paper presents emotional voice puppetry, an audio-based facial animation approach to portray characters with vivid emotional changes. The lips motion and the surrounding facial areas are controlled by the contents of the audio, and the facial dynamics are established by category of the emotion and the intensity. Our approach is exclusive because it takes account of perceptual validity and geometry instead of pure geometric processes. Another highlight of our approach is the generalizability to multiple characters. User studies demonstrate the effectiveness of our approach both qualitatively and quantitatively.","Ye Pan: Shanghai Jiaotong University , Shanghai , China;Ruisi Zhang: UC San Diego, La Jolla, California, United States, ruz032@ucsd.edu;Shengran Cheng: School of Electronic Information and Electrical Engineering, Shanghai Jiaotong University, Shanghai, China, sr-cheng@sjtu.edu.cn;Shuai Tan: Shanghai Jiao Tong University, Shanghai, China;Yu Ding: Fuxi AI Lab in Netease, Netease, Hang Zhou, China;Kenny Mitchell: Roblox, San Mateo, California, United States;Xubo Yang: SHANGHAI JIAO TONG UNIVERSITY, SHANGHAI, China",
1206,Effects of Collaborative Training Using Virtual Co-embodiment on Motor Skill Learning,"Kodama, Daiki",d_kodama@cyber.t.u-tokyo.ac.jp,"Many VR systems, which enable users to observe and follow a teacher's movements from a first-person perspective, reported their usefulness for motor skill learning. However, learners using these methods feel weak agency because they need to be aware of following the teacher's movements, preventing motor skill retention. To address this problem, we propose applying virtual co-embodiment, in which two users are immersed in the same virtual avatar, as a method that arises strong agency in motor skill learning. The experiment showed that learning in virtual co-embodiment with the teacher improves learning efficiency compared with sharing the teacher's perspective or alone.","Daiki Kodama: The University of Tokyo, Kuzuoka Amemiya Narumi Lab, Tokyo, Japan;Takato Mizuho: The University of Tokyo, Tokyo, Japan;Yuji Hatada: The University of Tokyo, Tokyo, Japan;Takuji Narumi: the University of Tokyo, Tokyo, Japan;Michitaka Hirose: Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
1563,Using Virtual Replicas to Improve Mixed Reality Remote Collaboration,"Tian, Huayuan",tiahy004@mymail.unisa.edu.au,"In this paper, we explore how virtual replicas can enhance MR remote collaboration with a 3D reconstruction of the task space and study how they can work as a spatial cue to improve MR remote collaboration. Our approach segments the foreground manipulable objects in the local environment and creates virtual replicas of them. The remote user can manipulate them to explain the task and guide the partner who can rapidly and accurately understand the remote expert's intentions and instructions. Our user study found using virtual replica manipulation was more efficient than using 3D annotation drawing in the MR remote collaboration. We report and discuss the findings and limitations of our system and study, and directions for future research.","Huayuan Tian: STEM, University of south Australia, Adelaide, South Australia, Australia, tiahy004@mymail.unisa.edu.au; Gun A. Lee: IVE STEM, University of South Australia, Adelaide, SA, Australia; Huidong Bai: Auckland Bioengineering Institute, The University of Auckland, Auckland, New Zealand; Mark Billinghurst: ITMS, University of South Australia, Mawson Lakes, Australia",
1039,Gaining the High Ground: Teleportation to Mid-Air Targets in Immersive Virtual Environments,"Weissker, Tim",me@tim-weissker.de,"We present three teleportation techniques that enable the user to travel not only to ground-based but also to mid-air targets. The techniques differ in the extent to which elevation changes are integrated into the conventional target selection process. Elevation can be specified either simultaneously, as a connected second step, or separately from horizontal movements. A user study indicated a trade-off between the simultaneous method with the highest accuracy and the two-step method with the lowest task load. The separate method was least suitable on its own. Based on our findings, we define initial design guidelines for mid-air navigation techniques.","Tim Weissker: Visual Computing Institute, RWTH Aachen University, Aachen, Germany, weissker@vr.rwth-aachen.de;Pauline Bimberg: Human Computer Interaction, University of Trier, Trier, Germany, bimberg@uni-trier.de;Aalok Shashidhar Gokhale: Virtual Reality and Visualization Research Group, Bauhaus-Universität Weimar, Weimar, Germany, aaloksg@gmail.com;Torsten Wolfgang Kuhlen: RWTH Aachen University, Aachen, Germany;Bernd Froehlich: Virtual Reality and Visualization Research Group, Bauhaus-Universität Weimar, Weimar, Germany",
1297,FREE-RDW: A Multiuser Redirected Walking Method for Supporting Nonforward Steps,"Gao, Tieqi",phylioras@foxmail.com,"Redirected walking (RDW) algorithms for non-forward steps can enrich the movement direction of users' virtual roaming. In addition, the non-forward motions have a greater curvature gain, which can be used to reduce resets in RDW. This paper presents a new method of multi-user RDW for supporting non-forward steps, which adds the options of sideward and backward steps to extend the virtual reality (VR) locomotion. Our method adopts a user collision avoidance strategy based on optimal reciprocal collision avoidance (ORCA) and optimizes it into a linear programming problem to obtain the optimal velocity for users. The experiments show that our method performs well in virtual scenes with? forward and non-forward steps.","Tianyang Dong: College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China;Tieqi Gao: College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China;Yinyan Dong: College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China;Liming Wang: College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China;Kefan Hu: College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China;Jing Fan: College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China;",
1449,Assisted walking-in-place: Introducing assisted motion to walking-by-cycling in embodied Virtual Reality,"Moullec, Yann",yann.moullec@inria.fr,"We investigated the use of a motorized bike to support the walk of an avatar in Virtual Reality. Our approach consists in assisting a walking-in-place technique called walking-by-cycling with a motorized bike in order to provide participants with a compelling walking experience while reducing their perceived effort. We conducted a study which showed that ""assisted walking-by-cycling"" induced more ownership, agency, and walking sensation than a static simulation. It also induced levels of ownership and walking sensation similar to that of active walking-by-cycling, but it induced less perceived effort, which promotes the use of our approach in situations where users cannot or do not want to exert much effort while walking in embodied VR.","Yann Moullec: Univ Rennes, Rennes, France;Justine Saint-Aubert: Inria Bretagne-Atlantique, Rennes, France;Mélanie Cogne: CHU Pontchaillou, Rennes, France Inria Bretagne-Atlantique, Rennes, France;Anatole Lécuyer: Inria, Rennes, France",
1109,Monte-Carlo Redirected Walking: Gain Selection Through Simulated Walks,"Congdon, Ben",ben.congdon.11@ucl.ac.uk,"We present Monte-Carlo Redirected Walking (MCRDW), a gain selection algorithm for redirected walking. MCRDW applies the Monte-Carlo method to redirected walking by simulating a large number of simple virtual walks, then inversely applying redirection to the virtual paths. Different gain levels and directions are applied, producing differing physical paths. Each physical path is scored and the results used to select the best gain level and direction. We provide a simple example implementation and a simulation-based study for validation. In our study, when compared with the next best technique, MCRDW reduced incidence of boundary collisions by over 50% while reducing total rotation and position gain.","Ben J. Congdon: Department of Computer Science, University College London, London, United Kingdom; Anthony Steed: Department of Computer Science, University College London, London, United Kingdom",
1265,LFACon: Introducing Anglewise Attentions to Light Field Space in No-reference Quality Assessment,"Qu, Qiang",vincent.qu@sydney.edu.au,"Compared to 2D image assessment, light field image quality assessment (LFIQA) needs to consider not only the image quality in spatial domain but also the quality consistency in angular domain. In this paper, we propose a novel concept of 'anglewise attention' by introducing a multihead self-attention mechanism to the angular domain of a light field image (LFI). This mechanism better reflects the LFI quality. Based on the proposed anglewise attention, we further propose our light field attentional convolutional neural network (LFACon) as an LFIQA metric. Our experimental results show that the proposed LFACon metric significantly outperforms the state-of-the-art LFIQA metrics.","Qiang Qu: School of Computer Science, The University of Sydney, Sydney, NSW, Australia, vincent.qu@sydney.edu.au;Xiaoming Chen: School of Computer Science and Engineering, Beijing Technology and Business University, Beijing, China, xiaoming.chen@btbu.edu.cn;Yuk Ying Chung: School of Computer Science, The University of Sydney, Sydney, Australia;Weidong Cai: School of Computer Science, The University of Sydney, Sydney, NSW, Australia, tom.cai@sydney.edu.au;",
1037,ShadowMover: Automatically Projecting Real Shadows onto Virtual Object,"Yu, Piaopiao",dz1833033@smail.nju.edu.cn,"Inserting 3D virtual objects into real-world images has many applications in photo editing and augmented reality. We present the first end-to-end solution to fully automatically project real shadows onto virtual objects for outdoor scenes. In our method, we introduce the Shifted Shadow Map, a new shadow representation that encodes the binary mask of shifted real shadows after inserting virtual objects in an image. Based on the shifted shadow map, we propose a CNN-based shadow generation model named ShadowMover which first predicts the shifted shadow map for an input image and then automatically generates plausible shadows on any inserted virtual object.","Piaopiao Yu: Nanjing University, Department of Computer Science and Technology, Nanjing, Jiangsu Province, China, DZ1833033@smail.nju.edu.cn;Jie Guo: Nanjing University, Nanjing, China;Fan Huang: Nanjing University, Department of Computer Science and Technology, Nanjing, China;Zhenyu Chen: Nanjing Univetsity, Nanjing, China;Chen Wang: Nanjing University, Department of Computer Science and Technology, Nanjing, Jiangsu Province, China, 502022330045@smail.nju.edu.cn;Yan Zhang: State Key Lab for Novel Software Technology, Nanjing University, Nanjing, China;Yanwen Guo: Dept. Computer Science and Technology, Nanjing University, Nanjing, China, ywguo@nju.edu.cn;",
1014,Add-on Occlusion: Turning Off-the-Shelf Optical See-through Head-mounted Displays Occlusion-capable,"Zhang, Yan",yan-zh@sjtu.edu.cn,"The occlusion-capable optical see-through head-mounted display (OC-OSTHMD) is actively developed in recent years. Virtual contents are demonstrated to have a higher quality when displayed with occlusion patterns. However, implementing occlusion with the specific type of OSTHMDs prevents the appealing feature from the wide application. In this paper, a novel approach of realizing occlusion for common OSTHMDs is proposed. A wearable device with per-pixel occlusion capability is designed. OSTHMDs are upgraded to be occlusion-capable by attaching the device before optical combiners. A prototype with HoloLens 1 is built. The proposed system is expected to realize a universal implementation of the occlusion function in augmented reality (AR).","Yan Zhang: Shanghai Jiao Tong University, Shanghai, Shanghai, China;Xiaodan Hu: NAIST, Ikoma, Nara, Japan;Kiyoshi Kiyokawa: Cybernetics and Reality Engineering Laboratory, Nara Institute of Science and Technology, Ikoma, Nara, Japan;Xubo Yang: SHANGHAI JIAO TONG UNIVERSITY, SHANGHAI, China;",
1022,NeRFPlayer: A Streamable Dynamic Scene Representation with Decomposed Neural Radiance Fields,"Song, Liangchen",lsong8@buffalo.edu,"An efficient framework, named NeRFPlayer, has been developed for fast reconstruction, compact modeling, and streamable rendering of 4D spatiotemporal space in VR. The framework decomposes the 4D space into three categories: static, deforming, and new areas, each represented by a separate neural field. A hybrid representations based feature streaming scheme is used for efficiently modeling the neural fields. Our method is evaluated on dynamic scenes captured by single hand-held cameras and multi-camera arrays, achieving comparable or superior rendering performance in terms of quality and speed, with reconstruction taking 10 seconds per frame.","Liangchen Song: University at Buffalo, Buffalo, New York, United States;Anpei Chen: ETH Zürich, Zürich, Switzerland University of Tübingen, Tübingen, Germany;Zhong Li: InnoPeak Technology, Palo Alto, California, United States;Zhang Chen: InnoPeak Technology, Palo Alto, California, United States;Lele Chen: OPPO US Research Center, InnoPeak Technology, Inc., Palo Alto, California, United States;Junsong Yuan: University at Buffalo, Buffalo, New York, United States;Yi Xu: OPPO US Research Center, InnoPeak Technology, Inc., Palo Alto, California, United States;Andreas Geiger: Department of Computer Science, University of Tübingen, Tübingen, Germany;",
1519,Integrating Both Parallax and Latency Compensation into Video See-Through Head-Mounted Display,"Ishihara, Atsushi",atsushi.a.ishihara@sony.com,"This study incorporates both parallax and latency compensation methods into a video see-through head-mounted display, to realize edge-preserving occlusion. To reconstruct captured images, we reproject the images captured by the color camera to the user's eye position, using depth maps. We fill the disocclusion areas using cached depth maps estimated in previous frames, instead of relying upon computationally heavy inpainting procedures. For occlusion, we refine the edges of the depth maps using both infrared masks and color-guided filters. For latency compensation, we propose a two-phase temporal warping method. It is found to be not only fast but also spatially correct for static scenes.","Atsushi Ishihara: Sony Group Corporation, Tokyo, Japan;Hiroyuki Aga: Sony Group Corporation, Tokyo, Japan, hiroyuki.aga@sony.com;Yasuko Ishihara: Sony Group Corporation, Tokyo, Japan;Hirotake Ichikawa: Sony Group Corporation, Tokyo, Japan;Hidetaka Kaji: Sony Group Corporation, Tokyo, Japan;Koichi Kawasaki: Sony Group Corporation, Tokyo, Japan;Daita Kobayashi: Sony Group Corporation, Tokyo, Japan;Toshimi Kobayashi: Sony Group Corporation, Tokyo, Japan;Senior Enginner Ken Nishida: Sony Group Corporation, Tokyo, Japan, ken.nishida@sony.com;Takumi Hamasaki: Sony Group Corporation, Tokyo, Japan;Hideto Mori: Sony Group Corporation, Tokyo, Japan;Yuki Morikubo: Sony Group Corporation, Tokyo, Japan;",
1591,GeoSynth: A Photorealistic Synthetic Indoor Dataset for Scene Understanding,"Pugh, Brian",bpugh@geomagical.com,"Deep learning has revolutionized many scene perception tasks over the past decade. Some of these improvements can be attributed to the development of large labeled datasets. The creation of such datasets can be an expensive, time-consuming, and imperfect process. To address these issues, we introduce GeoSynth, a diverse photorealistic synthetic dataset for indoor scene understanding tasks. Each GeoSynth exemplar contains rich labels including segmentation, geometry, camera parameters, surface material, lighting, and more. We demonstrate that supplementing real training data with GeoSynth can significantly improve network performance on perception tasks, like semantic segmentation.","Brian Pugh: Geomagical Labs, Mountain View, California, United States, bpugh@geomagical.com;Davin Chernak: Geomagical Labs, Mountain View, California, United States, davin@geomagical.com;Salma Jiddi: Geomagical Labs, Geomagical Labs, Mountain View, California, United States, salma@geomagical.com;",
1523,LiDAR-aid Inertial Poser: Large-scale Human Motion Capture by Sparse Inertial and LiDAR Sensors,"Ren, Yiming",renym2022@shanghaitech.edu.cn,"We propose a multi-sensor fusion method for capturing challenging 3D human motions with accurate consecutive local poses and global trajectories in large-scale scenarios, only using single LiDAR and 4 IMUs, which are set up conveniently and worn lightly. Moreover, we collect a LiDAR-IMU multi-modal mocap dataset, LIPD, with diverse human actions in long-range scenarios. Extensive quantitative and qualitative experiments on LIPD and other open datasets all demonstrate the capability of our approach for compelling motion capture in large-scale scenarios, which outperforms other methods by an obvious margin. We will release our code and captured dataset to stimulate future research.","Yiming Ren: Shanghaitech, Shanghai, Shanghai, China, renym2022@shanghaitech.edu.cn;Chengfeng Zhao: Shanghaitech, Shanghai, China ;Yannan He: Shanghaitech, Shanghai, China ;Peishan Cong: Shanghaitech, Shanghai, China;Han Liang: Shanghaitech, Shanghai, China ;Jingyi Yu: School of Information Science and Technology (SIST) , ShanghaiTech University, Shanghai, China, xulan1@shanghaitech.edu.cn; Lan XU: ShanghaiTech University, Shanghai, China ;Yuexin Ma: ShanghaiTech University, Shanghai, China;",
1982,Introducing 3D Thumbnails to Access 360-Degree Videos in Virtual Reality,"Hürst, Wolfgang",huerst@uu.nl,"Interfaces to access datasets of 360-degree videos in VR almost always use 2D thumbnails to represent them, even though the data is inherently three-dimensional. In a comparative study, we verified if using spherical and cube-shaped 3D thumbnails provides a better user experience and is more effective at conveying the high-level subject matter of a video or when searching for a specific item in it. Results show that traditional 2D equirectangular projections still performed better for high-level classification tasks but were outperformed by spherical thumbnails when participants had to search for details within the videos.","ir. Alissa Vermast: Department of Information and Computing Sciences, Utrecht University, Utrecht, Netherlands;Wolfgang Hürst: Department of Information and Computing Sciences, Utrecht University, Utrecht, Netherlands",
1874,Masked360: Enabling Robust 360-degree Video Streaming with Ultra Low Bandwidth Consumption,"Luo, Zhenxiao",luozhx6@mail2.sysu.edu.cn,"We propose a practical neural-enhanced 360-degree video streaming framework called Masked360, which can significantly reduce bandwidth consumption and achieve robustness against packet loss. In Masked360, instead of transmitting the complete video frame, the video server only transmits a masked low-resolution version of each video frame to reduce bandwidth significantly. Besides, the client can reconstruct the original 360-degree video frames with a lightweight neural network model. To further improve the quality of video streaming, we also propose a set of optimization techniques, such as complexity-based patch selection, quarter masking strategy, redundant patch transmission and enhanced model training meth","Zhenxiao Luo: School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China;Baili Chai: School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China;Zelong Wang: School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China;Miao Hu: School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China;Di Wu: School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China;",
1590,Wavelet-Based Fast Decoding of 360 Videos,"Groth, Colin",groth@cg.cs.tu-bs.de,"In this paper, we propose a wavelet-based video codec that enables real-time playback of high-resolution 360-degree videos. Our codec streams the relevant content directly from the drive and decodes the video viewport-dependently. Due to the specific design and the exploitation of the wavelet transform for intra- and inter-frame transform, our codec's decoding performance is up to 272% faster than state-of-the-art video codecs. Finally, we demonstrate how our wavelet-based codec can also directly be used in conjunction with foveation for further performance increases.","Colin Groth: Institute for Computer Graphics, TU Braunschweig, Braunschweig, Germany, groth@cg.cs.tu-bs.de;Sascha Fricke: Institute for Computer Graphics, TU Braunschweig, Braunschweig, Germany, fricke@cg.cs.tu-bs.de;Ing. Susana Castillo: Institute for Computer Graphics, TU Braunschweig, Braunschweig, Germany, castillo@cg.cs.tu-bs.de;Marcus Magnor: Institute for Computer Graphics, TU Braunschweig, Braunschweig, Germany, reviews@cg.cs.tu-bs.de;",
1480,PACE: Data-Driven Virtual Agent Interaction in Dense and Cluttered Environments,"Mullen Jr, James",mullenj@umd.edu,"We present PACE, a novel method for modifying motion-captured virtual agents to interact with and move throughout dense, cluttered 3D scenes. Our approach changes a given motion sequence of a virtual agent as needed to adjust to the obstacles and objects in the environment. We compare our method with prior motion generating techniques and highlight the benefits of our method with a perceptual study, where human raters preferred our method, and physical plausibility metrics, where our method performed. We have integrated our system with Microsoft HoloLens and demonstrate its benefits in real-world scenes. Our project website is available at https://gamma.umd.edu/pace/.","James F Mullen Jr: Department of Computer Science, University of Maryland, College Park, Maryland, United States, mullenj@umd.edu;Dinesh Manocha: Computer Science and Electrical & Computer Engineering, University of Maryland , College Park, Maryland, United States Computer Science and Electrical & Computer Engineering, University of Maryland , College Park, Maryland, United States",
2008,A survey on remote assistance and training in Mixed Reality environments,"Fidalgo, Catarina",catarina.gf0305@gmail.com,"The recent pandemic, war, and oil crises have caused many to reconsider their need to travel for education, training, and meetings. Mixed Reality offers opportunities to improve remote assistance and training, as it opens the way to increased spatial clarity and large interaction space. We contribute a survey of remote assistance and training in MR environments through a systematic literature review to provide a deeper understanding of current approaches, benefits and challenges. We analyze 62 articles and contextualize our findings into a taxonomy, identifying the main gaps and opportunities in this research area.","Catarina Gonçalves Fidalgo: HCII/ Augmented Perception Lab, Carnegie Mellon University, Pittsburgh, Pennsylvania, United States, cfidalgo@andrew.cmu.edu INESC-ID, Instituto Superior Técnico, Lisbon, Lisbon, Portugal, catarina.fidalgo@tecnico.ulisboa.pt;Yukang Yan: HCII, CMU, Pittsburgh, Pennsylvania, United States;Hyunsung Cho: Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, Pennsylvania, United States, hyunsung@cs.cmu.edu;Mauricio Sousa: Department of Computer Science , University of Toronto, Toronto, Ontario, Canada, mauricio@dgp.toronto.edu;David Lindlbauer: Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, Pennsylvania, United States;Joaquim Jorge: INESC-ID, Instituto Superior Técnico, Universidade de Lisboa, Lisboa, Portugal, jaj@inesc-id.pt;",
1357,Evaluating the Effects of Virtual Reality Environment Learning on Subsequent Robot Teleoperation in an Unfamiliar Building,"Eisenträger, Karl",karl.eisentraeger@protonmail.com,"We compared three methods to prepare for tasks performed by teleoperating a robot in a building. One group studied a floorplan, the second explored a VR reconstruction of the building from a normal-sized avatar's perspective and a third explored the VR from a giant-sized avatar's perspective. Giant VR and floorplan took less learning time than normal VR. Both VR methods significantly outperformed the floorplan in a orientation task. Navigation was quicker in the giant compared to the normal perspective and the floorplan. We conclude that normal and giant perspective in VR are viable for preparation of teleoperation in unfamiliar environments.","Karl Eisenträger: Humboldt University of Berlin, Berlin, Berlin, Germany, karl.eisentraeger@protonmail.com;Judith Haubner: Institute for Psychology, Chemnitz University of Technology, Chemnitz, Germany, judith.haubner@psychologie.tu-chemnitz.de;Jennifer Brade: Chemnitz University of Technology, Institute for Machine Tools and Production Processes (IWP), Chemnitz, Germany, jennifer.brade@mb.tu-chemnitz.de;Wolfgang Einhäuser: Physics of Cognition Group, Chemnitz University of Technology, Chemnitz, Germany;Alexandra Bendixen: Cognitive Systems Lab, Chemnitz University of Technology, Chemnitz, Germany;Sven Winkler Chemnitz: University of Technology, Professorship of Production Systems and Processes, Chemnitz, Germany, sven.winkler@mb.tu-chemnitz.de;Philipp Klimant Chemnitz: University of Technology, Institute for Machine Tools and Production Processes, Chemnitz, Saxony, Germany;Georg Jahn: Professorship of Applied Geropsychology and Cognition, Chemnitz University of Technology, Chemnitz, Germany",
1213,"Cybersickness, Cognition, & Motor Skills: The Effects of Music, Gender, and Gaming Experience","Kourtesis, Panagiotis",dr.panagiotis.kourtesis@gmail.com,"This paper examines the effects of cybersickness on the cognitive, motor, and reading performance in VR, as well as evaluates the mitigating effects of music on cybersickness, the role of gender, and the computing, VR, and gaming experience of the user. Joyful and Calming music substantially decreased the intensity of nausea-related symptoms. Only Joyful music significantly reduced the overall cybersickness intensity. Cybersickness decreased verbal working memory performance and pupil size, decelerating reaction time, and reading speed. The gaming experience was negatively correlated with cybersickness. Cybersickness's intensity was not different between female and male participants with comparable gaming experience.","Panagiotis Kourtesis: Inria, Rennes, France Univ Rennes, Rennes, France;Rayaan Amir: Psychology, University of Edinburgh, Edinburgh, United Kingdom;Josie Linnell: Psychology, University of Edinburgh, Edinburgh, Please select, United Kingdom;Ferran Argelaguet: Sanz Inria, Rennes, France;Sarah MacPherson: Psychology, University of Edinburgh, Edinburgh, Please select, United Kingdom, sarah.macpherson@ed.ac.uk;",
1122,"Effect of Frame Rate on User Experience, Performance, and Simulator Sickness in Virtual Reality","Liang, Hai-Ning",haining.liang@xjtlu.edu.cn,"This work fills a gap in the effect of the frame rate of virtual reality (VR) head-mounted displays (HMDs) on users' experience, performance, and simulator sickness (SS) symptoms. We report the findings of a study with two VR applications that compared four specific frame rates (60, 90, 120, and 180 frames per second (fps)). Our results show that 120fps is an important threshold. After 120fps, users tend to feel lower SS symptoms without a significant negative effect on their experience and performance. Higher frame rates (e.g., 120 and 180fps) can ensure better user performance than lower rates.","Jialin Wang: Computer Science and Software Engineering, Xi'an Jiaotong-Liverpool University, Suzhou, Jiangsu, China;Rongkai Shi: Department of Computing, Xi'an Jiaotong-Liverpool University, Suzhou, Jiangsu, China, rongkai.shi19@student.xjtlu.edu.cn;Wenxuan Zheng: Department of Computing, Xi'an Jiaotong-Liverpool University, Suzhou, China, wenxuan.zheng19@student.xjtlu.edu.cn;Weijie Xie: Department of Computing, Xi'an Jiaotong-Liverpool University, Suzhou, China, wenxuan.zheng19@student.xjtlu.edu.cn;Dominic Kao: Purdue University, West Lafayette, Indiana, United States;Hai-Ning Liang: Department of Computing, Xi'an Jiaotong-Liverpool University, Suzhou, Jiangsu, China, haining.liang@xjtlu.edu.cn;",
1355,Shadowless Projection Mapping using Retrotransmissive Optics,"Iwai, Daisuke",daisuke.iwai.es@osaka-u.ac.jp,"This paper presents a shadowless projection mapping system for interactive applications in which a target surface is frequently occluded from a projector with a user's body. We propose a delay-free optical solution for this critical problem. Specifically, as the primary technical contribution, we apply a large format retrotransmissive plate to project images onto the target surface from wide viewing angles. We also tackle technical issues unique to the proposed shadowless principle such as stray light and touch detection. We implement a proof-of-concept prototype and validate the proposed techniques through experiments.","Kosuke Hiratani: Osaka University, Toyonaka, Japan;Daisuke Iwai: Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan;Yuta Kageyama: Graduate School of Enginerring Science, Osaka University, Toyonaka, Osaka, Japan, kageyama@sens.sys.es.osaka-u.ac.jp;Parinya Punpongsanon: Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan;Takefumi Hiraki: Osaka University, Toyonaka, Japan;Kosuke Sato: Graduate School of Engineering Science, Osaka University, Toyonaka, Japan",
1900,Off-Axis Layered Displays: Hybrid Direct-View/Near-Eye Mixed Reality with Focus Cues,"Ebner, Christoph",christoph.ebner@icg.tugraz.at,"This work introduces off-axis layered displays, the first approach to stereoscopic direct-view displays with support for focus cues. Off-axis layered displays combine a head-mounted display with a direct-view display to provide focus cues. We present a pipeline for the real-time rendering of off-axis display patterns to explore the novel display architecture. Additionally, we build two prototypes using a head-mounted display in combination with a stereoscopic, and a monoscopic direct-view display. Furthermore, we show how extending off-axis layered displays with an attenuation layer and with eye-tracking improves image quality. We thoroughly analyze each component and present examples captured through our prototypes.","Christoph Ebner: Graz University of Technology, Graz, Austria;Peter Mohr: Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria;Tobias Langlotz: University of Otago, Dunedin, New Zealand;Yifan (Evan) Peng: The University of Hong Kong, Hong Kong, China;Dieter Schmalstieg: Graz University of Technology, Graz, Austria;Gordon Wetzstein: Electrical Engineering, Stanford University, Stanford, California, United States;Denis Kalkofen Graz: University of Technology, Graz, Austria Flinders University, Adelaide, Australia",
1026,Perceptually-guided dual-mode virtual reality system for motion-adaptive display,"zeng, hui",zeng-h20@mails.tsinghua.edu.cn,"The development of high-quality virtual reality (VR) devices brings great challenges for display panel fabrication, real-time rendering, and data transfer. To address this issue, we introduce a dual-mode virtual reality system based on the spatio-temporal perception characteristics of human vision. The proposed VR system has a novel optical architecture. It can switch display modes according to the user's perceptual requirements for different display scenes to adaptively adjust the display spatial and temporal resolution based on a given display budget, thus providing users with the optimal visual perception quality.","hui zeng: Center for Brain-Inspired Computing Research (CBICR), Beijing Advanced Innovation Center for Integrated Circuits, Optical Memory National Engineering Research Center, & Department of Precision Instrument, Tsinghua University, 100084, Beijing, China;rong zhao: Center for Brain-Inspired Computing Research (CBICR), Beijing Advanced Innovation Center for Integrated Circuits, Optical Memory National Engineering Research Center, & Department of Precision Instrument, Tsinghua University, 100084, Beijing, China IDG/McGovern Institute for Brain Research at Tsinghua University, 100084, Beijing, China",
1032,Dynamic Redirection for VR Haptics with a Handheld Stick,"Zhou, Yuqi",zhou1168@purdue.edu,"This paper proposes a general handheld stick haptic redirection method that allows the user to experience complex shapes with haptic feedback through both tapping and extended contact, such as in contour tracing. As the user extends the stick to make contact with a virtual object, the contact point with the virtual object and the targeted contact point with the physical object are continually updated, and the virtual stick is redirected to synchronize the virtual and real contacts. Redirection is applied either just to the virtual stick, or to both the virtual stick and hand. A user study (N = 26) confirms the effectiveness of the proposed redirection method.","Yuqi Zhou: Department of Computer Science, Purdue University, West Lafayette, Indiana, United States;Voicu Popescu: Department of Computer Science, Purdue University, West Lafayette, Indiana, United States",
1270,Leveling the Playing Field: A Comparative Reevaluation of Unmodified Eye-Tracking as an Input and Interaction Modality for VR,"Proulx, Michael",michaelproulx@fb.com,"Here we establish a much-needed baseline for evaluating eye tracking interactions for AR/VR targeting and selecting tasks, including both traditional standards and those more aligned with AR/VR interactions today. In a targeting and button press selection task, we compare completely unadjusted, cursor-less, eye tracking to controller and head tracking, which both had cursors. Unmodified eye tracking, without any form of a cursor, or feedback, outperformed the head and performed comparably to the controller in throughput and in subjective ratings. Eye tracking, with even minor sensible interaction design modifications, has tremendous potential in reshaping interactions in next-generation AR/VR head mounted displays.","Ajoy Savio Fernandes: Reality Labs Research, Meta, Redmond, Washington, United States;T. Scott Murdison: Reality Labs, Meta, Redmond, Washington, United States;Michael J Proulx: Reality Labs Research, Redmond, Washington, United States, michaelproulx@fb.com;",
1525,Evaluating Augmented Reality Landmark Cues and Frame of Reference Displays with Virtual Reality,"Zhao, Yu",yu.zhao@vanderbilt.edu,"Head-mounted augmented reality (AR) displays provide a preview of future navigation systems across various application domains for walking travel, such as search and rescue or commuting, but designing them is still an open problem. Here, we investigate two options for navigation that such AR systems can make: 1) whether to use AR cues to indicate landmarks; 2) how to convey navigation instructions and the effects on spatial knowledge acquisition. We found that the world-fixed frame of reference resulted in better spatial learning when there were no landmarks cued; adding AR landmark cues marginally improved spatial learning in the screen-fixed condition. Our findings have implications for future cognition-driven navigation systems design.","Yu Zhao: Vanderbilt University, Nashville, Tennessee, United States;Jeanine Stefanucci: University of Utah, Salt Lake City, Utah, United States;Sarah Creem-Regehr: Psychology, University of Utah, Salt Lake City, Utah, United States;Bobby Bodenheimer: Department of Computer Science, Vanderbilt University, Nashville, Tennessee, United States",
1238,A Lack of Restraint: Comparing Virtual Reality Interaction Techniques for Constrained Transport Seating,"Wilson, Graham",graham.wilson@glasgow.ac.uk,"Standalone Virtual Reality (VR) headsets can now be used in cars, trains and planes. However, the spaces around transport seating are constrained by other seats, walls and passengers, leaving users with little space in which to interact safely and acceptably. Therefore, they cannot use most commercial VR applications, as they are designed for unobstructed 1-2m2 home environments. In this paper, we conducted a gamified user study to test whether three at-a-distance interaction techniques from the literature could be adapted to support common VR movement inputs identified from commercial games, and so equalise the interaction capabilities of at-home and constrained users.","Graham Wilson: School of Computing Science, University of Glasgow, Glasgow, United Kingdom;Mark McGill: School of Computing Science, University of Glasgow, Glasgow, Lanarkshire, United Kingdom, mark.mcgill@glasgow.ac.uk;Daniel Medeiros: School of Computing Science, University of Glasgow, Glasgow, United Kingdom, daniel.piresdesamedeiros@glasgow.ac.uk;Stephen Anthony Brewster: School of Computing Science, University of Glasgow, Glasgow, United Kingdom, stephen.brewster@glasgow.ac.uk",
1504,Give Me a Hand: Improving the Effectiveness of Near-field Augmented Reality Interactions By Avatarizing Users' End Effectors,"Venkatakrishnan, Roshan",rvenkat@g.clemson.edu,"We investigated whether avatarizing users' end-effectors (hands) improved their interaction performance on a near-field, obstacle avoidance, object retrieval task. We employed a 3 (Augmented hand representation) X 2 (density of obstacles) X 2 (size of obstacles) X 2 (virtual light intensity) multi-factorial design, manipulating the presence/absence and anthropomorphic fidelity of augmented self-avatars, across three experimental conditions: (1) No-Augmented Avatar; (2) Iconic-Augmented Avatar; (3) Realistic Augmented Avatar. Our findings seem to indicate that interaction performance may improve when users are provided with a visual representation of the AR system's interacting layer in the form of an augmented self-avatar.","Roshan Venkatakrishnan: School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States;Rohith Venkatakrishnan: School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States;Balagopal Raveendranath: Clemson University, Clemson, South Carolina, United States Clemson University, Clemson, South Carolina, United States;Christopher Pagano: Department of Psychology, Clemson University, Clemson, South Carolina, United States Department of Psychology, Clemson University, Clemson, South Carolina, United States;Andrew Robb: School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States;Wen-Chieh Lin: Dept of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan Dept of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan;Sabarish V. Babu: School of Computing, Clemson University, Clemson, South Carolina, United States School of Computing, Clemson University, Clemson, South Carolina, United States",
1646,Skeleton-based Human Action Recognition via Large-kernel Attention Graph Convolutional Network,"Liu, Yanan",731696785@qq.com,"The skeleton-based human action recognition has broad application prospects in the field of virtual reality. Notably, recent works learns the spatio-temporal pattern via graph convolution operators. Still, the stacked graph convolution plays a marginal role in modeling long-range dependences. In this work, we introduce a skeleton large kernel attention operator (SLKA), which can enlarge the receptive field and improve channel adaptability without increasing too much computational burden. Further, we have designed a novel recognition network architecture called the spatiotemporal large-kernel attention graph convolution network (LKA-GCN). Ultimately, on three action datasets, our LKA-GCN has achieved a state-of-the-art level.","Yanan Liu: School of Information Science and Engineering, Yunnan university, Kunming, China, liuyanan@mail.ynu.edu.cn;Hao Zhang: School of Information Science and Engineering, Yunnan university, Kunming, China;Yanqiu Li: School of Information Science & Engineering, Yunnan University, Kunming, China;Kangjian He: School of Information Science and Engineering, Yunnan university, Kunming, China;Dan Xu: School of Information Science and Engineering, Yunnan university, Kunming, China, danxu@ynu.edu.cn",
1652,GestureSurface: VR sketching through assembling scaffold surface with non dominant hand,"Feng, Guihuan",fenggh@nju.edu.cn,"3D sketching provides an immersive drawing experience for designs. However, the lack of depth perception cues in VR makes it difficult to draw accurate strokes. To handle this, we introduce gesture-based scaffolding to guide strokes. We conduct a gesture-design study and propose GestureSurface, a bi-manual interface that uses non-dominant hand performing gestures to create scaffolding and the other hand drawing with controller. When the dominant hand is occupied, reducing the idleness of the non-dominant hand thourgh gestural input increases efficiency and fluency. We evaluated GestureSurface using a 20-person user study that found it had high efficiency and low fatigue.","Xinchi Xu: State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China, xinchi@smail.nju.edu.cn Software Institute, Nanjing University, Nanjing, China, xinchi@smail.nju.edu.cn;Yang Zhou: State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China, zhouyang1997@smail.nju.edu.cn Software Institute, Nanjing University, Nanjing, China;Bingchan Shao: State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China, bingchanshao@smail.nju.edu.cn Software Institute, Nanjing University, Nanjing, China;Guihuan Feng: State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China, fenggh@nju.edu.cn Software Institute, Nanjing University, Nanjing, China, fenggh@nju.edu.cn;Chun Yu: Department of Computer science and Technology, Tsinghua University, Beijing, China",
1562,Comparing Different Grasping Visualizations for Object Manipulation in VR using Controllers,"Ganias, Giorgos",sdi1500028@di.uoa.gr,"Visualizing grasping when users interact with virtual objects using handheld controllers in VR is underexplored. We present an experiment with 38 participants, comparing three different grasping visualizations: the Auto-Pose, where the hand is automatically adjusted to the object upon grasping; the Simple-Pose, where the hand closes fully when selecting the object; and the Disappearing-Hand, where the hand becomes invisible after selecting an object, and turns visible after positioning it on the target. Measuring the effect on user performance, embodiment and preference showed that the perceived sense of embodiment is stronger with the Auto-Pose, and is generally preferred by the users.","Giorgos Ganias: National and Kapodistrian University of Athens, Athens, Greece, sdi1500028@di.uoa.gr;Christos Lougiakis: Department of Informatics and Telecommunications/School of Science, National and Kapodistrian University of Athens, Athens, Greece;Akrivi Katifori: Department of Informatics and Telecommunications, University of Athens, Athens, Greece Athena Research Center, Athens, Greece;Maria Roussou: Department of Informatics and Telecommunications, National and Kapodistrian University of Athens, Athens, Greece, mariar@di.uoa.gr;Yannis Ioannidis: University of Athens and Athena Research Center, Athens, Greece;Ioannis Panagiotis: Ioannidis National and Kapodistrian University of Athens, Athens, Greece",
1571,Evaluation of AR visualization approaches for catheter insertion into the ventricle cavity,"Benmahdjoub, Mohamed",m.benmahdjoub@erasmusmc.nl,"The way how virtual data is presented in AR guided surgical navigation plays an important role for correct spatial perception of the virtual overlay. This study compares various visualization modalities for catheter insertion in external ventricular drain and ventricular shunt procedures. We investigate (1) 2D approaches (smartphone, 2D window), and (2) 3D approaches (fully aligned patient model, and a model that is adjacent to the patient and is rotationally aligned) using an OST. 32 participants performed 20 AR guided insertions per approach. The results show more accurate insertions using 3D approaches with a higher preference compared to 2D approaches.","Mohamed Benmahdjoub: Biomedical Imaging Group Rotterdam, Erasmus MC, Rotterdam, Netherlands Department of Oral and Maxillofacial Surgery, Erasmus MC, University Medical Centre, Rotterdam, Netherlands;Abdullah Thabit: Biomedical Imaging Group Rotterdam, Erasmus MC, Rotterdam, Netherlands, a.thabit@erasmusmc.nl Department of Oral and Maxillofacial Surgery, Erasmus MC, University Medical Centre, Rotterdam, Netherlands, a.thabit@erasmusmc.nl;Marie-Lise C. van Veelen: Department of Neurosurgery, Erasmus MC, Rotterdam, Netherlands, m.l.c.vanveelen@erasmusmc.nl;Wiro J. Niessen: Biomedical Imaging Group Rotterdam, Erasmus MC, Rotterdam, Netherlands, w.niessen@erasmusmc.nl Department of Imaging Physics, Delft University of Technology, Delft, Netherlands, w.niessen@erasmusmc.nl;Eppo B. Wolvius: Department of Oral and Maxillofacial Surgery, Erasmus MC, University Medical Centre, Rotterdam, Netherlands;Theo van Walsum: Biomedical Imaging Group Rotterdam, Erasmus MC, Rotterdam, Netherlands",
1286,A Video-Based Augmented Reality System for Human-in-the-Loop Muscle Strength Assessment of Juvenile Dermatomyositis,"Zhou, Kanglei",zhoukanglei@163.com,"JDM is characterized by skin rashes and muscle weakness. The CMAS is commonly used to measure the degree of muscle involvement for diagnosis. However, humans are subject to personal bias, and automatic AQA algorithms cannot guarantee 100% accuracy. Therefore, we propose a video-based augmented reality system for human-in-the-loop muscle strength assessment of children with JDM. Our core insight is to visualize the AQA results as a virtual character facilitated by a 3D animation dataset, so that users can compare the real-world patient and the virtual character to verify the AQA results. The experimental results verify the effectiveness of our system.","Kanglei Zhou: Beihang University, Beijing, China;Ruizhi Cai: Beihang University, Beijing, China;Yue Ma: Beihang University, Beijing, China, super_mayue@buaa.edu.cn;Qingqing Tan: Capital Institute of Pediatrics, Beijing, China;Xinning Wang: Capital Institute of Pediatrics, Beijing, China;Jianguo Li: Capital Institute of Pediatrics, Beijing, China;Hubert P. H. Shum: Durham University, Durham, United Kingdom;Frederick W. B. Li: University of Durham, Durham, United Kingdom;Song Jin: Beijing Weilai high tech technology Co., Ltd, beijing, China;Xiaohui Liang: School of Computer Science and Engineering, Beihang University, Beijing, China",
1729,CardioGenesis4D: Interactive Morphological Transitions of Embryonic Heart Development in a Virtual Learning Environment,"Schott, Danny",danny.schott@ovgu.de,"In the embryonic human heart, complex dynamic shape changes take place in a short period, making this development difficult to visualize. An immersive learning environment is presented that enables the understanding of morphological transitions through hand interactions. In a user study, we examined usability, perceived task load, and sense of presence. We also assessed knowledge gain, and obtained feedback from domain experts. Students and professionals rated the application as usable, and our results show that interactive learning content should consider features for different learning styles. Our work previews, how VR can be integrated into a cardiac embryology education curriculum.","Danny Schott: University of Magdeburg, Faculty of Computer Science, Magdeburg, Saxony-Anhalt, Germany, danny.schott@ovgu.de;Matthias Kunz: University of Magdeburg, Clinic for Cardiology and Angiology, Magdeburg, Saxony-Anhalt, Germany, matthias.kunz@med.ovgu.de;Tom Wunderling: University of Magdeburg, Faculty of Computer Science, Magdeburg, Saxony-Anhalt, Germany, tom.wunderling@ovgu.de;Florian Heinrich: University of Würzburg, Human-Computer Interaction (HCI) Group, Würzburg, Germany, florian.heinrich@uni-wuerzburg.de;Rüdiger Braun-Dullaeus: University of Magdeburg, Clinic for Cardiology and Angiology, Magdeburg, Saxony-Anhalt, Germany, r.braun-dullaeus@med.ovgu.de;Christian Hansen: University of Magdeburg, Faculty of Computer Science, Magdeburg, Saxony-Anhalt, Germany, hansen@isg.cs.uni-magdeburg.de",
1505,How End-effector Representations Affect the Perceptions of Dynamic Affordances in Virtual Reality,"Venkatakrishnan, Rohith",rohithv@g.clemson.edu,"We investigated how different virtual hand representations affect users' perceptions of dynamic affordances using a collision-avoidance object retrieval task. We employed a 3 (virtual end-effector representation) X 13 (frequency of moving doors) X 2 (target object size) multi-factorial design, manipulating the input modality and its concomitant virtual end-effector representation across three experimental conditions: (1) Controller ; (2) Controller-hand ; (3) Glove. We find that representing the end-effector as hands tends to increase embodiment but can also come at the cost of performance, or an increased workload due to a discordant mapping between the virtual representation and the input modality used.","Roshan Venkatakrishnan: School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States;Rohith Venkatakrishnan: School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States;Balagopal Raveendranath: Clemson University, Clemson, South Carolina, United States Clemson University, Clemson, South Carolina, United States;Christopher Pagano: Department of Psychology, Clemson University, Clemson, South Carolina, United States Department of Psychology, Clemson University, Clemson, South Carolina, United States;Andrew Robb: School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States School of Computing, Human Centered Computing, Clemson University, Clemson, South Carolina, United States;Wen-Chieh Lin: Dept of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan Dept of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan;Sabarish V. Babu: School of Computing, Clemson University, Clemson, South Carolina, United States School of Computing, Clemson University, Clemson, South Carolina, United States",
1492,Inward VR: Toward a Qualitative Method for Investigating Interoceptive Awareness in VR,"Haley, Alexander",haley045@umn.edu,"VR can produce powerful illusions of being in another place or inhabiting another body, and theories of presence and embodiment provide valuable guidance to VR designers. However, VR can also be used to develop an awareness of one's own body (i.e., interoceptive awareness); here, design guidelines and evaluative techniques are less clear. To address this, we present a qualitative methodology, including a reusable codebook, for adapting the Multidimensional Assessment of Interoceptive Awareness conceptual framework to explore interoceptive awareness in VR. We report results from an exploratory study (n=21) applying this method to understand the interoceptive awareness experiences of VR users.","Alexander Haley: University of Minnesota, Minneapolis, Minnesota, United States, haley045@umn.edu;Don Thorpe: University of Minnesota, Minneapolis, Minnesota, United States, thorp167@umn.edu;Alex Pelletier: University of Minnesota, Minneapolis, Minnesota, United States, pelle213@umn.edu;Svetlana Yarosh: University of Minnesota, Minneapolis, Minnesota, United States;Daniel F. Keefe: Department of Computer Science and Engineering, University of Minnesota, Minneapolis, Minnesota, United States",
1648,Body and Time: Virtual Embodiment and its effect on Time Perception,"Unruh, Fabian",fabian.unruh@uni-wuerzburg.de,"This article explores the relation between one's own body and the perception of time in a novel Virtual Reality (VR) experiment explicitly fostering user activity. Forty-Eight participants randomly experienced different degrees of embodiment: i) without an avatar (low), ii) with hands (medium), and iii) with a high-quality avatar (high). Participants had to repeatedly activate a virtual lamp and estimate the duration of time intervals as well as judge the passage of time. Our results show a significant effect of embodiment on time perception: time passes slower in the low embodiment condition compared to the medium and high conditions.","Fabian Unruh: University of Würzburg, Department of Computer Science, HCI Group, Würzburg, Germany;David H.V. Vogel: Cognitive Neuroscience (INM-3), Research Center Juelich, Jülich, Germany;Maximilian Landeck: Department of Computer Science, HCI Group, University of Würzburg, Würzburg, Germany;Jean-Luc Lugrin: University of Würzburg, Department of Computer Science, HCI Group, Würzburg, Germany;Marc Erich Latoschik: University of Würzburg, Department of Computer Science, HCI Group, Würzburg, Germany",
1695,Comparing the Effects of Visual Realism on Size Perception in VR versus Real World Viewing through Physical and Verbal Judgments,"Wijayanto, Ignatius",alex.eic07g@nctu.edu.tw,"Virtual Reality (VR) is well-known for its use in interdisciplinary applications and research. The visual representation of these applications could vary and in those situations could require an accurate perception of size for task performance. However, the relationship between size perception and visual realism in VR has not yet been explored. In this contribution, we conducted an empirical evaluation using a between-subject design over four conditions of visual realism on size perception of target objects in the same virtual environment. Our result showed participants' size perception was accurate in both realistic and non-photorealistic conditions suggesting that invariant provides meaningful information in the environment.","Ignatius Alex Wijayanto: National Yang Ming Chiao Tung University; Sabarish V. Babu: Clemson University; Christopher Pagano: Department of Psychology, Clemson University; Jung-Hong Chuang: National Yang Ming Chiao Tung University",
1610,Can I Squeeze Through? Effects of Self-Avatars and Calibration in a Person-Plus-Virtual-Object System on Perceived Lateral Passability in VR,"Bhargava, Ayush",ayush.bhargava92@gmail.com,"Self-avatars and virtual object interactions give rise to affordance based challenges as dynamic surface information like compression and stickiness is absent in VR. This effect is amplified when interacting with virtual objects as the weight and inertial feedback associated with them is often mismatched. As such, we investigated how the absence of dynamic surface properties affect lateral passability judgments with virtual handheld objects in the presence or absence of self-avatars. Results show that participants can account for the missing dynamic information with self-avatars, but rely on their internal body schema of a compressed body depth in the absence of self-avatars.","Ayush Bhargava: School of Computing, Clemson University; Rohith Venkatakrishnan: School of Computing, Human Centered Computing, Clemson University; Roshan Venkatakrishnan: School of Computing, Human Centered Computing, Clemson University; Kathryn Lucaites: Department of Psychology, Clemson University; Hannah Solini: Department of Psychology, Clemson University; Andrew Robb: School of Computing, Human Centered Computing, Clemson University; Christopher Pagano: Department of Psychology, Clemson University; Sabarish V. Babu: School of Computing, Clemson University",
1053,A Study of Change Blindness in Immersive Environments,"Martin, Daniel",danims@unizar.es,"Human performance is poor at detecting certain changes in a scene, a phenomenon known as change blindness. Although the exact reasons of this effect are not yet completely understood, there is a consensus that it is due to our constrained attention and memory capacity. In this work, we present a study of change blindness using immersive 3D environments. We devise two experiments; first, we focus on analyzing how different change properties may affect change blindness. We then further explore its relation with the capacity of our visual working memory and analyze the influence of the number of changes.","Daniel Martin: Graphics and Imaging Lab, Universidad de Zaragoza; Xin Sun: Adobe Research; Diego Gutierrez: Universidad de Zaragoza; Belen Masia: Universidad de Zaragoza",
1483,Exploring Plausibility and Presence in Mixed Reality Experiences,"Westermeier, Franziska",franziska.westermeier@uni-wuerzburg.de,"Our study investigates the impact of incongruencies on different information processing layers (i.e., sensation/perception and cognition layer) in Mixed Reality (MR), and its effects on plausibility, spatial and overall presence. In a simulated maintenance application participants performed operations in a randomized 2x2 design, experiencing either VR (congruent sensation/perception) or AR (incongruent sensation/perception). By inducing cognitive incongruence through the absence of traceable power outages, we aimed to explore the relationship between perceived cause and effect. Our results indicate that the effects of the power outages differ significantly in the perceived plausibility and spatial presence ratings between VR and AR.","Franziska Westermeier: Human-Computer Interaction Group, University of Würzburg; Larissa Brübach: Human-Computer Interaction Group, University of Würzburg; Marc Erich Latoschik: Human-Computer Interaction Group, University of Würzburg; Carolin Wienrich: Psychology of Intelligent Interactive Systems, University of Würzburg",
1255,Measuring Interpersonal Trust towards Virtual Humans with a Virtual Maze Paradigm,"Lin, Jinghuai",jinghuai.lin@uni-wuerzburg.de,"This work proposes a validated behavioural tool to measure interpersonal trust towards a specific virtual social interaction partner in social VR. The task of the users (the trustors) is to navigate through a maze in virtual reality, where they can interact with a virtual human (the trustee). In the validation study, participants interacting with a trustworthy avatar asked for advice more often than those interacting with an untrustworthy avatar, indicating that the paradigm is sensitive to the differences in interpersonal trust and can be used to measure trust towards virtual humans.","Jinghuai Lin: Human-Computer Interaction (HCI) Group, University of Würzburg; Johrine Cronjé: Department of Psychology I, Biological Psychology, Clinical Psychology and Psychotherapy, University of Würzburg; Ivo Käthner: Department of Psychology I, Biological Psychology, Clinical Psychology and Psychotherapy, University of Würzburg; Paul Pauli: Department of Psychology I, Biological Psychology, Clinical Psychology and Psychotherapy, University of Würzburg; Marc Erich Latoschik: Human-Computer Interaction (HCI) Group, University of Würzburg",
1164,The Dating Metaverse: Why We Need to Design for Consent in Social VR,"Zytko, Douglas",zytko@oakland.edu,We present a participatory design study about how consent to interpersonal behavior can be designed in social VR to prevent harm. VR dating applications are used as the context of study. Through design workshops with potential VR daters (n=18) we elucidate nonconsensual experiences that should be prevented and designs for exchanging consent in VR. We position consent as a valuable lens for designing preventative solutions to harm in social VR by reframing harm as unwanted experiences that happen because of the absence of mechanics to support users in giving and denying agreement to a virtual experience before it occurs.,Douglas Zytko: Oakland University; Jonathan Chan: Oakland University,
1550,How to Maximise Spatial Presence: Design Guidelines for a Virtual Learning Environment for School Use,"Rieger, Marc",rieger@uni-landau.de,"Research on learning with and in immersive virtual reality (VR) continues to grow, yielding more insights into how immersive learning works. A major hurdle that hinders the use of immersive digital media in schools is the lack of guidelines for designing VR learning environments for practical use in schools. Using a design-based research approach, we explored the guidelines for creating VR learning content for tenth-grade students in a German secondary school and recreated a real-world, out-of-school VR learning space which can be used for hands-on instruction. This presentation investigated how to maximise the experience of spatial presence by creating a VR learning environment in several microcycles.",Marc Bastian Rieger: RPTU Kaiserslautern-Landau; Björn Risch: RPTU Kaiserslautern-Landau,
1066,ImTooth: Neural Implicit Tooth for Dental Augmented Reality,"Li, Hai",garyli@zju.edu.cn,"We propose a simple and accurate neural-implicit model-driven dental AR system, named ImTooth, and adapted for HoloLens 2. Based on the modeling capabilities and differentiable optimization properties of state-of-the-art neural implicit representations, our system fuses reconstruction and registration in a single network, greatly simplifying existing dental AR solutions and enabling reconstruction, registration, and interaction. Experiments show that our method can reconstruct high-precision models and accomplish accurate registration. It is also robust to weak, repeating, and inconsistent textures.We also show that our system can be easily integrated into dental diagnostic and therapeutic procedures, such as bracket placement guidance. ","Hai Li: State Key Lab of CAD&CG, Zhejiang University; Hongjia Zhai: State Key Lab of CAD&CG, Zhejiang University; Xingrui Yang: Visual Information Lab, University of Bristol; Zhirong Wu: Zhejiang University; Yihao Zheng: Zhejiang University; Haofan Wang: Zhejiang University; Jianchao Wu: Taizhou stamotology hospital; Hujun Bao: State Key Lab of CAD&CG, Zhejiang University; Guofeng Zhang: State Key Lab of CAD&CG, Zhejiang University",
1016,GroundFlow: Liquid-based Haptics for Simulating Fluid on the Ground in Virtual Reality,"Han, Ping-Hsuan",pinghsuan.han@gmail.com,"Most haptic devices simulate feedback in dry environments such as the living room, prairie, or city. However, water-related environments are thus less explored, for example, rivers, beaches, and swimming pools. In this paper, we present GroundFlow, a liquid-based haptic floor system for simulating fluid on the ground in VR. We discuss design considerations and propose a system architecture and interaction design. We conduct two user studies to assist in designing a multiple-flow feedback mechanism, develop three applications to explore the potential uses of the mechanism, and consider the limitations and challenges thereof to inform VR developers and haptic practitioners.","Ping-Hsuan Han: Department of Interaction Design, National Taipei University of Technology; Tzu-Hua Wang: Dept. Interaction Design, National Taipei University of Technology; Chien-Hsing Chou: Department of Mathematics and Information Education, National Taipei University of Education",
1289,"Eat, Smell, See: Investigating Cross-Modal Correspondence when Eating in VR","Weidner, Florian",florian.weidner@tu-ilmenau.de,"Integrating taste in AR/VR applications has various promising use cases - from social eating to the treatment of disorders. We present the results of a user study in which participants were confronted with congruent and incongruent visual and olfactory stimuli while eating a tasteless food product in VR. With our results, we highlight challenges that arise when trying to influence perception, show that vision does not always dominate or guide perception, and emphasize that tri-modal incongruency hampers perception enormously. We discuss our data within the context of multisensory integration, AR/VR human-food interaction, and basic human perception.","Florian Weidner: Virtual Worlds and Digital Games Group, Ilmenau University of Technology; Frau Jana Elena Maier janamaier: Virtual Worlds and Digital Games Group, Ilmenau University of Technology; Wolfgang Broll: Virtual Worlds and Digital Games Group, Ilmenau University of Technology",
1379,Modified Egocentric Viewpoint for Softer Seated Experience in Virtual Reality,"Matsumuro, Miki",matumuro@rm2c.ise.ritsumei.ac.jp,"We aimed to change the perceived haptic features of a chair by shifting the position and angle of the users' viewpoints in virtual reality. To enhance the seat softness, we shifted the virtual viewpoint using an exponential formula soon after a user's bottom contacted the seat surface. We also manipulated the viewpoint to change the flexibility of the virtual backrest. Subjective evaluations confirmed that participants perceived the seat as softer and the backrest more flexible than the actual ones, though significant changes resulted in discomfort.","Miki Matsumuro: Ritsumeikan University; Shohei Mori: Institute of Computer Graphics and Vision, Graz University of Technology; Yuta Kataoka: Reality Media Lab. Ritsumeikan University; Fumiaki Igarashi: Kusatsu, Shiga, Japan; Fumihisa Shibata: College of Information Science and Engineering, Ritsumeikan University; Asako Kimura: Ritsumeikan Univ.",
1511,Upper Body Thermal Referral and Tactile Masking for Localized Feedback,"Kim, Jin Ryong",jinryongkim@gmail.com,This paper investigates the effects of thermal referral and tactile masking illusions to achieve localized thermal feedback. The first experiment uses sixteen vibrotactile actuators with four thermal actuators to explore the thermal distribution on the user's back. The result confirms that localized thermal feedback can be achieved through cross-modal thermo-tactile interaction on the user's back of the body. The second experiment is conducted to validate our approach in VR. The results show that our thermal referral with a tactile masking approach with a lesser number of thermal actuators achieves greater response time and better location accuracy.,"Hyungki Son: ETRI; Haokun Wang: University of Texas at Dallas; Yatharth Singhal: Erik Jonsson School of Engineering and Computer Science, University of Texas at Dallas; Jin Ryong Kim: Computer Science, The University of Texas at Dallas",
1680,"The Impact of Avatar and Environment Congruence on Plausibility, Embodiment, Presence, and the Proteus Effect in Virtual Reality","Mal, David",david.mal@uni-wuerzburg.de,"We investigated the impact of avatar and environment types on VR-related qualia and the Proteus effect. Participants embodied either an avatar in sports- or business wear in a semantic congruent or incongruent environment while performing exercises in virtual reality. The avatar-environment congruence significantly affected the avatar's plausibility but not the sense of embodiment or spatial presence. A significant Proteus effect emerged only for participants who reported a high feeling of (virtual) body ownership, indicating that a strong sense of having and owning a virtual body is key to facilitating the Proteus effect.","David Mal: Human-Computer Interaction Group, University of Würzburg; Erik Wolf: Human-Computer Interaction Group, University of Würzburg; Nina Döllinger: Psychology of Intelligent Interactive Systems Group, University of Würzburg; Carolin Wienrich: Psychology of Intelligent Interactive Systems Group, University of Würzburg; Marc Erich Latoschik: Human-Computer Interaction Group, University of Würzburg",
1079,A Systematic Review on the Visualization of Avatars and Agents in AR & VR displayed using Head-Mounted Displays,"Weidner, Florian",florian.weidner@tu-ilmenau.de,"Augmented Reality (AR) and Virtual Reality (VR) are pushing from the labs towards consumers, especially with social applications. These applications require visual representations of humans and intelligent entities. Our work investigates the effects of rendering style and visible body parts in AR and VR by adopting a systematic literature review. We analyzed 72 papers that compare various avatar representations. We discuss and synthesize our results within the context of today's AR and VR ecosystem, provide guidelines for practitioners, and finally identify and present promising research opportunities to encourage future research of avatars and agents in AR/VR environments. ","Florian Weidner: Virtual Worlds and Digital Games Group, Ilmenau University of Technology; Gerd Boettcher: Virtual Worlds and Digital Games Group, Ilmenau University of Technology; Chenyao Dao: TU Ilmenau; Luljeta Sinani: Ilmenau University of Technology; Stephanie Arevalo Arboleda: TU Ilmenau; Christian Kunert: Virtual Worlds and Digital Games Group, Ilmenau University of Technology; Christoph Gerhardt: Virtual Worlds and Digital Games Group, Ilmenau University of Technology; Wolfgang Broll: Virtual Worlds and Digital Games Group, Ilmenau University of Technology; Alexander Raake: TU Ilmenau",
1833,"Effects of the Visual Fidelity of Virtual Environments on Presence, Context-dependent Forgetting, and Source-monitoring Error","Mizuho, Takato",takato@cyber.t.u-tokyo.ac.jp,"The present study examined two effects caused by alternating VE and RE experiences: ""context-dependent forgetting'' and ""source-monitoring errors.'' The former effect is that memories learned in VEs are more easily recalled in VEs than in REs, and vice versa. The source-monitoring error is that memories learned in VEs and REs are easily confused, making it difficult to identify the source of the memory. We hypothesized that the visual fidelity of VEs is responsible for these effects. We found that the level of visual fidelity significantly affected the sense of presence, but not context-dependent forgetting or source-monitoring errors.","Takato Mizuho: The University of Tokyo; Takuji Narumi: the University of Tokyo; Hideaki Kuzuoka: Graduate School of Information Science and Technology, The University of Tokyo",
1322,Privacy-preserving datasets of eye-tracking samples with applications in XR,"David-John, Brendan",bmdj@vt.edu,"XR technology has advanced significantly in recent years and will enable the future of work, education, socialization, and entertainment. Eye-tracking data supports XR interaction, animating virtual avatars, and rendering optimizations. While eye tracking enables beneficial applications, it also introduces a privacy risk by enabling re-identification of users. We applied privacy definitions of k-anonymity and plausible deniability (PD) to eye-tracking sample datasets and evaluated them against differential privacy (DP). Our results suggest that both PD and DP produced practical privacy-utility trade-offs between re-identification and activity classification accuracy, while k-anonymity performed best at retaining utility for gaze prediction.","Brendan David-John: Department of Computer Science, Virginia Tech; Kevin Butler: Department of Computer & Information Science & Engineering, University of Florida; Eakta Jain: Department of Computer & Information Science & Engineering, University of Florida",
1057,When Tangibles become Deformable: Studying Pseudo-Stiffness Perceptual Thresholds in a VR Grasping Task,"Bouzbib, Elodie",elo.bouzbib@gmail.com,"Pseudo-Haptic techniques leverage user's visual dominance over haptics to alter users' perception, but are limited to perceptual thresholds. In this paper, we estimate thresholds for pseudo-stiffness in a VR grasping task. We conducted a user study (n = 15) to estimate if compliance can be induced on non-compressible objects and to what extent. Our results show that (1) compliance can be induced in rigid objects and that (2) pseudo-haptics can simulate beyond 24 N/cm stiffness (from gummy bears up to rigid objects). Pseudo-stiffness efficiency is (3) enhanced by objects' scales and (4) correlated to input force. Our results show novel opportunities to simplify the design of haptic interfaces, and extend the haptic properties of props in VR.","Elodie Bouzbib: INRIA, Université de Rennes; Claudio Pacchierotti: IRISA, CNRS; Anatole Lécuyer: Inria, Rennes, France",
1630,Text Input for Non-Stationary XR Workspaces: Investigating Tap and Word-Gesture Keyboards in Virtual and Augmented Reality,"Kern, Florian",florian.kern@uni-wuerzburg.de,"We evaluated two text input techniques for non-stationary virtual reality (VR) and video see-through augmented reality (VST AR) XR displays. Our study with 64 participants showed that XR displays and input techniques have a strong impact on text entry performance. We found that tap keyboards had higher usability, better user experience, and lower task load compared to swipe keyboards in VR and VST AR. Both input techniques were faster in VR than in VST AR, and the tap keyboard was the fastest in VR. Participants showed a significant learning effect. Our reference implementation is publicly available for replication and reuse.","Florian Kern: Human-Computer Interaction Group, University of Würzburg; Florian Niebling: Angewandte Informatik, Hochschule Fulda; Marc Erich Latoschik: Human-Computer Interaction Group, University of Würzburg",
1093,CrowbarLimbs: A Fatigue-Reducing Virtual Reality Text Entry Metaphor,"Abu Bakar, Muhammad",abubakar.nuaa@gmail.com,"We present 'CrowbarLimbs,' a novel virtual reality text entry metaphor with two deformable extended virtual limbs. CrowbarLimbs can assist a user in placing their hands and arms in a comfortable posture, thus effectively reducing the physical fatigue in the hands, wrists, and elbows. It can also achieve comparable text entry speed, accuracy, and system usability to those of previous selection-based methods. We found that the shapes of CrowbarLimbs have significant effects on fatigue ratings and text entry speed. Furthermore, placing the virtual keyboard near the user and at half their height significantly affects text entry speed.","Muhammad Abu Bakar: Department of Computer Science and Engineering, Innovation Center for Big Data and Digital Convergence, Yuan Ze University; Yu-Ting Tsai: Department of Computer Science and Engineering, Innovation Center for Big Data and Digital Convergence, Yuan Ze University; Hao-Han Hsueh: Department of Computer Science and Engineering, Yuan Ze University; Elena Carolina Li: Department of Visual Arts, University of Taipei",
1820,I Can't See That! Considering the Readability of Small Objects in Virtual Environments,"Young, Jacob",jacobyoung.research@gmail.com,"Interacting with and interpreting small objects in virtual reality has remained an issue, particularly in the replication of real-world tasks. We propose three techniques for improving the usability and readability of small objects: i) expanding them in place, ii) expanding a separate replica, and iii) showing a large readout of the object's state. We conducted a user study comparing each technique's usability, induced presence, and effect on knowledge retention and conclude that scaling the area of interest may not be enough to improve the usability of information-bearing objects, while text readouts can aid task completion while reducing knowledge retention.","Jacob Young: School of Engineering and Computer Science, Victoria University of Wellington; Nadia Pantidi: School of Design Innovation, Victoria University of Wellington; Matthew Wood: School of Geography, Environment and Earth Sciences, Victoria University of Wellington",
